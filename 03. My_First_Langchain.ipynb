{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36a57298-1745-4da8-bd92-fd98f41abc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# OpenAI 클라이언트 설정\n",
    "client = OpenAI(\n",
    "    api_key=os.environ['OPENAI_API_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7849305-0195-4839-8c79-0c76a737d195",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_16580\\2238586475.py:4: LangChainDeprecationWarning: The method `BaseLLM.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  llm.predict('미국의 제1대 대통령은?')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n조지 워싱턴입니다.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm=OpenAI(model_name='gpt-3.5-turbo-instruct')\n",
    "llm.predict('미국의 제1대 대통령은?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cedac02-18c2-43cd-8b0f-5b2b4e663290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n조지 워싱턴(George Washington)입니다.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm=OpenAI(model_name='gpt-3.5-turbo-instruct')\n",
    "llm.invoke('미국의 제1대 대통령은?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa58c863-1e8b-406e-a583-29ab274789fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\",\"조지 워싱턴\");\\n    return $default;\\n}'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm=OpenAI(model_name='gpt-3.5-turbo-instruct', temperature=1)\n",
    "llm.invoke('미국의 제1대 대통령은?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d8d80ce-7b8f-4b6d-9e36-ccf5799318b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "BTS (방탄소년단)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nBTS (방탄소년단)'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "llm=OpenAI(model_name='gpt-3.5-turbo-instruct', streaming=True,\n",
    "           callbacks=[StreamingStdOutCallbackHandler()], temperature=0)\n",
    "llm.invoke('서울에서 가장 유명한 K-POP 가수는?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14384add-1ba0-48e9-b677-12c2dc1e6ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 반복문은 주어진 시퀀스(리스트, 튜플, 문자열 등)나 이터러블 객체의 요소들을 순차적으로 반복하면서 해당 요소들에 대해 특정 작업을 수행할 때 사용됩니다. for 반복문은 시퀀스의 길이나 요소의 개수에 따라 자동으로 반복을 수행하며, 반복이 끝나면 자동으로 종료됩니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "chatgpt = ChatOpenAI(model_name='gpt-3.5-turbo')\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=\"당신은 파이썬 프로그래머입니다.\"\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=\"파이썬에서 for 반복문의 역할은?\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "result=chatgpt(messages)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b551443-795b-4063-8e5c-2eb0fbb41f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text='무스탕 자켓의 소재에 대해 알려줘'\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "llm_prompt = PromptTemplate.from_template(\"{goods}의 소재에 대해 알려줘\")\n",
    "llm_prompt_result=llm_prompt.format_prompt(goods=\"무스탕 자켓\")\n",
    "\n",
    "print(llm_prompt_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b351f50-4b1f-475b-a407-95e1578ef167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='당신은 스페인어 선생님입니다. 스페인어로 대답해 주세요.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='대한민국의 보물1호는?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "system_message = \"당신은 {language} 선생님입니다. {language}로 대답해 주세요.\"\n",
    "\n",
    "system_prompt = SystemMessagePromptTemplate.from_template(system_message)\n",
    "human_template = \"{text}\"\n",
    "human_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_prompt, human_prompt])\n",
    "\n",
    "chat_prompt.format_messages(language=\"스페인어\", text=\"대한민국의 보물1호는?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "31c7b342-3e06-42a8-bdd8-9c389aff7394",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niceq\\anaconda3\\envs\\ai_jun\\lib\\site-packages\\langchain_community\\llms\\openai.py:255: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain_community.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "C:\\Users\\niceq\\anaconda3\\envs\\ai_jun\\lib\\site-packages\\langchain_community\\llms\\openai.py:1086: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain_community.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m llm_prompt \u001b[38;5;241m=\u001b[39m PromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{goods}\u001b[39;00m\u001b[38;5;124m의 소재에 대해 알려줘\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m llm_prompt_result \u001b[38;5;241m=\u001b[39m llm_prompt\u001b[38;5;241m.\u001b[39mformat_prompt(goods \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m무스탕 자켓\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm_prompt_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai_jun\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:182\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    180\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    181\u001b[0m     emit_warning()\n\u001b[1;32m--> 182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai_jun\\lib\\site-packages\\langchain_core\\language_models\\llms.py:1327\u001b[0m, in \u001b[0;36mBaseLLM.predict_messages\u001b[1;34m(self, messages, stop, **kwargs)\u001b[0m\n\u001b[0;32m   1325\u001b[0m text \u001b[38;5;241m=\u001b[39m get_buffer_string(messages)\n\u001b[0;32m   1326\u001b[0m _stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m stop \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(stop)\n\u001b[1;32m-> 1327\u001b[0m content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(text, stop\u001b[38;5;241m=\u001b[39m_stop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1328\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m AIMessage(content\u001b[38;5;241m=\u001b[39mcontent)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai_jun\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:182\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    180\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    181\u001b[0m     emit_warning()\n\u001b[1;32m--> 182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai_jun\\lib\\site-packages\\langchain_core\\language_models\\llms.py:1277\u001b[0m, in \u001b[0;36mBaseLLM.__call__\u001b[1;34m(self, prompt, stop, callbacks, tags, metadata, **kwargs)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1271\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgument `prompt` is expected to be a string. Instead found \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1272\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(prompt)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. If you want to run the LLM on multiple prompts, use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1273\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`generate` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1274\u001b[0m     )\n\u001b[0;32m   1275\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1276\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m-> 1277\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[0;32m   1278\u001b[0m         [prompt],\n\u001b[0;32m   1279\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m   1280\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m   1281\u001b[0m         tags\u001b[38;5;241m=\u001b[39mtags,\n\u001b[0;32m   1282\u001b[0m         metadata\u001b[38;5;241m=\u001b[39mmetadata,\n\u001b[0;32m   1283\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1284\u001b[0m     )\n\u001b[0;32m   1285\u001b[0m     \u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1286\u001b[0m     \u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m   1287\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai_jun\\lib\\site-packages\\langchain_core\\language_models\\llms.py:950\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[1;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    935\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    936\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    937\u001b[0m         callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[0;32m    938\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialized,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    948\u001b[0m         )\n\u001b[0;32m    949\u001b[0m     ]\n\u001b[1;32m--> 950\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_helper(\n\u001b[0;32m    951\u001b[0m         prompts, stop, run_managers, \u001b[38;5;28mbool\u001b[39m(new_arg_supported), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    952\u001b[0m     )\n\u001b[0;32m    953\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[0;32m    954\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai_jun\\lib\\site-packages\\langchain_core\\language_models\\llms.py:792\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[1;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[0;32m    790\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n\u001b[0;32m    791\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[1;32m--> 792\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    793\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m    794\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m manager, flattened_output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(run_managers, flattened_outputs):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai_jun\\lib\\site-packages\\langchain_core\\language_models\\llms.py:779\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[1;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[0;32m    769\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate_helper\u001b[39m(\n\u001b[0;32m    770\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    771\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    775\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    776\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    778\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 779\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m    780\u001b[0m                 prompts,\n\u001b[0;32m    781\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    782\u001b[0m                 \u001b[38;5;66;03m# TODO: support multiple run managers\u001b[39;00m\n\u001b[0;32m    783\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    784\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    785\u001b[0m             )\n\u001b[0;32m    786\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    787\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[0;32m    788\u001b[0m         )\n\u001b[0;32m    789\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    790\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai_jun\\lib\\site-packages\\langchain_community\\llms\\openai.py:1175\u001b[0m, in \u001b[0;36mOpenAIChat._generate\u001b[1;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m   1173\u001b[0m messages, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_chat_params(prompts, stop)\n\u001b[0;32m   1174\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[1;32m-> 1175\u001b[0m full_response \u001b[38;5;241m=\u001b[39m completion_with_retry(\n\u001b[0;32m   1176\u001b[0m     \u001b[38;5;28mself\u001b[39m, messages\u001b[38;5;241m=\u001b[39mmessages, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m   1177\u001b[0m )\n\u001b[0;32m   1178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(full_response, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m   1179\u001b[0m     full_response \u001b[38;5;241m=\u001b[39m full_response\u001b[38;5;241m.\u001b[39mdict()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai_jun\\lib\\site-packages\\langchain_community\\llms\\openai.py:121\u001b[0m, in \u001b[0;36mcompletion_with_retry\u001b[1;34m(llm, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Use tenacity to retry the completion call.\"\"\"\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_openai_v1():\n\u001b[1;32m--> 121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m llm\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    123\u001b[0m retry_decorator \u001b[38;5;241m=\u001b[39m _create_retry_decorator(llm, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[0;32m    125\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_completion_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai_jun\\lib\\site-packages\\openai\\lib\\_old_api.py:39\u001b[0m, in \u001b[0;36mAPIRemovedInV1Proxy.__call__\u001b[1;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m_args: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIRemovedInV1(symbol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_symbol)\n",
      "\u001b[1;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm=OpenAI(model_name='gpt-3.5-turbo', temperature=0)\n",
    "\n",
    "llm_prompt = PromptTemplate.from_template(\"{goods}의 소재에 대해 알려줘\")\n",
    "llm_prompt_result = llm_prompt.format_prompt(goods = \"무스탕 자켓\")\n",
    "\n",
    "llm.predict_messages(llm_prompt_result.to_messages())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b53571c9-795e-4ca7-acd6-c6a7063f8f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "무스탕 자켓은 주로 나일론이나 폴리에스테르와 같은 인공 섬유 소재로 제작됩니다. 이러한 소재는 가벼우면서도 내구성이 뛰어나고 방수 기능이 있어서 추운 날씨나 비 오는 날에도 효과적으로 보온을 제공해줍니다. 또한 일반적으로 무스탕 자켓은 속에 충전재로 다운이나 인조 다운이 사용되어 보온성을 높여줍니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# ChatOpenAI 모델 인스턴스 생성 (최신 모델 사용)\n",
    "llm = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0)\n",
    "\n",
    "# 프롬프트 템플릿 생성\n",
    "prompt_template = PromptTemplate(template=\"{goods}의 소재에 대해 알려줘\")\n",
    "\n",
    "# LLM과 프롬프트 템플릿을 연결하는 체인 생성\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "# 실행할 데이터 설정\n",
    "goods = \"무스탕 자켓\"\n",
    "\n",
    "# 체인 실행 및 결과 출력\n",
    "result = chain.run(goods=goods)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "65cca2e7-39b5-40e8-a5b8-cd0bd48751e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대한민국의 보물 1호는 안압지입니다. 안압지는 고려시대에 만들어진 석탑으로, 대한민국의 국보 제 1호로 지정되어 있습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate\n",
    ")\n",
    "\n",
    "chatgpt = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0)\n",
    "\n",
    "system_message = \"당신은 {language} 선생님입니다. {language}로 대답해 주세요.\"\n",
    "system_prompt = SystemMessagePromptTemplate.from_template(system_message)\n",
    "human_template = \"{text}\"\n",
    "human_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_prompt, human_prompt])\n",
    "\n",
    "message = chat_prompt.format_messages(language=\"스페인어\", text=\"대한민국의 보물1호는?\")\n",
    "\n",
    "response = chatgpt.invoke(message)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b8341293-9132-4789-b776-60819be1c4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The national treasure of South Korea is the Tripitaka Koreana, a collection of Buddhist scriptures carved onto wooden blocks.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate\n",
    ")\n",
    "\n",
    "chatgpt = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0)\n",
    "\n",
    "system_message = \"당신은 {language} 선생님입니다. {language}로 대답해 주세요.\"\n",
    "system_prompt = SystemMessagePromptTemplate.from_template(system_message)\n",
    "human_template = \"{text}\"\n",
    "human_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_prompt, human_prompt])\n",
    "\n",
    "message = chat_prompt.format_messages(language=\"영어\", text=\"대한민국의 보물1호는?\")\n",
    "\n",
    "response = chatgpt.invoke(message)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cd846268-bc9f-467b-a137-0d6484571d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "ex_qa = [\n",
    "    {\n",
    "        \"question\": \"차은우에 대해 알려줘\",\n",
    "        \"answer\": \"나이: 29, 키: 183, 사는 곳: 대한민국\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"데이비드 베컴에 대해 알려줘\",\n",
    "        \"answer\": \"나이: 45, 키: 178, 사는 곳: 영국\"\n",
    "    }\n",
    "]\n",
    "\n",
    "ex_prompt=PromptTemplate(input_variables=[\"question\", \"answer\"],\n",
    "                         template=\"Question: {question}\\n{answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "27f435db-da71-4d95-b31d-5f2bd6f1b7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나이: 36, 키: 187, 사는 곳: 이탈리아\n"
     ]
    }
   ],
   "source": [
    "prompt=FewShotPromptTemplate(\n",
    "    examples=ex_qa,\n",
    "    example_prompt=ex_prompt,\n",
    "    suffix=\"Question: {input}\",\n",
    "    input_variables=[\"input\"]\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0)\n",
    "\n",
    "prompt_result=prompt.format(input=\"크리스티아누 호날두에 대해 알려줘\")\n",
    "response = llm.invoke(prompt_result)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9e1d5e82-8dce-4a22-884a-ea1b9db963d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "패딩, 울코트, 트렌치코트, 다운자켓, 더블코트\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"{subject} 5개를 추천해줘.\\n{format_instructions}\",\n",
    "    input_variables=[\"subject\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions}\n",
    ")\n",
    "\n",
    "llm=OpenAI(temperature=0)\n",
    "\n",
    "prompt_result = prompt.format(subject=\"겨울외투\")\n",
    "output = llm.invoke(prompt_result)\n",
    "print(output)                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "72e82482-0112-4608-82f7-7b1aeba0cad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['패딩', '울코트', '트렌치코트', '다운자켓', '더블코트']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parser.parse(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e201a8e6-51d6-4a09-a402-c426f8c89fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인생은 롤러코스터와 같아.\n",
      "둘다 오르막과 내리막이 있으니깐\n",
      "하지만 두려움에 떨거나 즐기는 것은\n",
      "너의 선택이야\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "# txt 파일 경로 지정\n",
    "file_path = \"C:/Users/niceq/Desktop/롤러코스터.txt\"\n",
    "\n",
    "loader = TextLoader(file_path, encoding = 'UTF-8')\n",
    "document= loader.load()\n",
    "\n",
    "print(document[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f08d3115-03f1-4c13-9584-b00a432c674a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'C:/Users/niceq/Documents/DataScience/Python_data_touch/data/01. CCTV_in_Seoul.csv', 'row': 0}, page_content='\\ufeff\"기관명\": 강남구\\n소계: 2780\\n2013년도 이전: 1292\\n2014년: 430\\n2015년: 584\\n2016년: 932'),\n",
       " Document(metadata={'source': 'C:/Users/niceq/Documents/DataScience/Python_data_touch/data/01. CCTV_in_Seoul.csv', 'row': 1}, page_content='\\ufeff\"기관명\": 강동구\\n소계: 773\\n2013년도 이전: 379\\n2014년: 99\\n2015년: 155\\n2016년: 377'),\n",
       " Document(metadata={'source': 'C:/Users/niceq/Documents/DataScience/Python_data_touch/data/01. CCTV_in_Seoul.csv', 'row': 2}, page_content='\\ufeff\"기관명\": 강북구\\n소계: 748\\n2013년도 이전: 369\\n2014년: 120\\n2015년: 138\\n2016년: 204'),\n",
       " Document(metadata={'source': 'C:/Users/niceq/Documents/DataScience/Python_data_touch/data/01. CCTV_in_Seoul.csv', 'row': 3}, page_content='\\ufeff\"기관명\": 강서구\\n소계: 884\\n2013년도 이전: 388\\n2014년: 258\\n2015년: 184\\n2016년: 81'),\n",
       " Document(metadata={'source': 'C:/Users/niceq/Documents/DataScience/Python_data_touch/data/01. CCTV_in_Seoul.csv', 'row': 4}, page_content='\\ufeff\"기관명\": 관악구\\n소계: 1496\\n2013년도 이전: 846\\n2014년: 260\\n2015년: 390\\n2016년: 613'),\n",
       " Document(metadata={'source': 'C:/Users/niceq/Documents/DataScience/Python_data_touch/data/01. CCTV_in_Seoul.csv', 'row': 5}, page_content='\\ufeff\"기관명\": 광진구\\n소계: 707\\n2013년도 이전: 573\\n2014년: 78\\n2015년: 53\\n2016년: 174'),\n",
       " Document(metadata={'source': 'C:/Users/niceq/Documents/DataScience/Python_data_touch/data/01. CCTV_in_Seoul.csv', 'row': 6}, page_content='\\ufeff\"기관명\": 구로구\\n소계: 1561\\n2013년도 이전: 1142\\n2014년: 173\\n2015년: 246\\n2016년: 323'),\n",
       " Document(metadata={'source': 'C:/Users/niceq/Documents/DataScience/Python_data_touch/data/01. CCTV_in_Seoul.csv', 'row': 7}, page_content='\\ufeff\"기관명\": 금천구\\n소계: 1015\\n2013년도 이전: 674\\n2014년: 51\\n2015년: 269\\n2016년: 354'),\n",
       " Document(metadata={'source': 'C:/Users/niceq/Documents/DataScience/Python_data_touch/data/01. CCTV_in_Seoul.csv', 'row': 8}, page_content='\\ufeff\"기관명\": 노원구\\n소계: 1265\\n2013년도 이전: 542\\n2014년: 57\\n2015년: 451\\n2016년: 516'),\n",
       " Document(metadata={'source': 'C:/Users/niceq/Documents/DataScience/Python_data_touch/data/01. CCTV_in_Seoul.csv', 'row': 9}, page_content='\\ufeff\"기관명\": 도봉구\\n소계: 485\\n2013년도 이전: 238\\n2014년: 159\\n2015년: 42\\n2016년: 386'),\n",
       " Document(metadata={'source': 'C:/Users/niceq/Documents/DataScience/Python_data_touch/data/01. CCTV_in_Seoul.csv', 'row': 10}, page_content='\\ufeff\"기관명\": 동대문구\\n소계: 1294\\n2013년도 이전: 1070\\n2014년: 23\\n2015년: 198\\n2016년: 579'),\n",
       " Document(metadata={'source': 'C:/Users/niceq/Documents/DataScience/Python_data_touch/data/01. CCTV_in_Seoul.csv', 'row': 11}, page_content='\\ufeff\"기관명\": 동작구\\n소계: 1091\\n2013년도 이전: 544\\n2014년: 341\\n2015년: 103\\n2016년: 314'),\n",
       " Document(metadata={'source': 'C:/Users/niceq/Documents/DataScience/Python_data_touch/data/01. CCTV_in_Seoul.csv', 'row': 12}, page_content='\\ufeff\"기관명\": 마포구\\n소계: 574\\n2013년도 이전: 314\\n2014년: 118\\n2015년: 169\\n2016년: 379'),\n",
       " Document(metadata={'source': 'C:/Users/niceq/Documents/DataScience/Python_data_touch/data/01. CCTV_in_Seoul.csv', 'row': 13}, page_content='\\ufeff\"기관명\": 서대문구\\n소계: 962\\n2013년도 이전: 844\\n2014년: 50\\n2015년: 68\\n2016년: 292'),\n",
       " Document(metadata={'source': 'C:/Users/niceq/Documents/DataScience/Python_data_touch/data/01. CCTV_in_Seoul.csv', 'row': 14}, page_content='\\ufeff\"기관명\": 서초구\\n소계: 1930\\n2013년도 이전: 1406\\n2014년: 157\\n2015년: 336\\n2016년: 398'),\n",
       " Document(metadata={'source': 'C:/Users/niceq/Documents/DataScience/Python_data_touch/data/01. CCTV_in_Seoul.csv', 'row': 15}, page_content='\\ufeff\"기관명\": 성동구\\n소계: 1062\\n2013년도 이전: 730\\n2014년: 91\\n2015년: 241\\n2016년: 265'),\n",
       " Document(metadata={'source': 'C:/Users/niceq/Documents/DataScience/Python_data_touch/data/01. CCTV_in_Seoul.csv', 'row': 16}, page_content='\\ufeff\"기관명\": 성북구\\n소계: 1464\\n2013년도 이전: 1009\\n2014년: 78\\n2015년: 360\\n2016년: 204'),\n",
       " Document(metadata={'source': 'C:/Users/niceq/Documents/DataScience/Python_data_touch/data/01. CCTV_in_Seoul.csv', 'row': 17}, page_content='\\ufeff\"기관명\": 송파구\\n소계: 618\\n2013년도 이전: 529\\n2014년: 21\\n2015년: 68\\n2016년: 463'),\n",
       " Document(metadata={'source': 'C:/Users/niceq/Documents/DataScience/Python_data_touch/data/01. CCTV_in_Seoul.csv', 'row': 18}, page_content='\\ufeff\"기관명\": 양천구\\n소계: 2034\\n2013년도 이전: 1843\\n2014년: 142\\n2015년: 30\\n2016년: 467'),\n",
       " Document(metadata={'source': 'C:/Users/niceq/Documents/DataScience/Python_data_touch/data/01. CCTV_in_Seoul.csv', 'row': 19}, page_content='\\ufeff\"기관명\": 영등포구\\n소계: 904\\n2013년도 이전: 495\\n2014년: 214\\n2015년: 195\\n2016년: 373'),\n",
       " Document(metadata={'source': 'C:/Users/niceq/Documents/DataScience/Python_data_touch/data/01. CCTV_in_Seoul.csv', 'row': 20}, page_content='\\ufeff\"기관명\": 용산구\\n소계: 1624\\n2013년도 이전: 1368\\n2014년: 218\\n2015년: 112\\n2016년: 398'),\n",
       " Document(metadata={'source': 'C:/Users/niceq/Documents/DataScience/Python_data_touch/data/01. CCTV_in_Seoul.csv', 'row': 21}, page_content='\\ufeff\"기관명\": 은평구\\n소계: 1873\\n2013년도 이전: 1138\\n2014년: 224\\n2015년: 278\\n2016년: 468'),\n",
       " Document(metadata={'source': 'C:/Users/niceq/Documents/DataScience/Python_data_touch/data/01. CCTV_in_Seoul.csv', 'row': 22}, page_content='\\ufeff\"기관명\": 종로구\\n소계: 1002\\n2013년도 이전: 464\\n2014년: 314\\n2015년: 211\\n2016년: 630'),\n",
       " Document(metadata={'source': 'C:/Users/niceq/Documents/DataScience/Python_data_touch/data/01. CCTV_in_Seoul.csv', 'row': 23}, page_content='\\ufeff\"기관명\": 중구\\n소계: 671\\n2013년도 이전: 413\\n2014년: 190\\n2015년: 72\\n2016년: 348'),\n",
       " Document(metadata={'source': 'C:/Users/niceq/Documents/DataScience/Python_data_touch/data/01. CCTV_in_Seoul.csv', 'row': 24}, page_content='\\ufeff\"기관명\": 중랑구\\n소계: 660\\n2013년도 이전: 509\\n2014년: 121\\n2015년: 177\\n2016년: 109')]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "file_path = \"C:/Users/niceq/Documents/DataScience/Python_data_touch/data/01. CCTV_in_Seoul.csv\"\n",
    "csv_loader = CSVLoader(file_path=file_path, encoding = 'UTF-8')\n",
    "document = csv_loader.load()\n",
    "document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "67ab8d65-5635-420e-844b-7268d117ddfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'C:/Users/niceq/Desktop/롤러코스터.pdf', 'page': 0}, page_content='인생은 롤러코스터와 같아. \\n둘다 오르막과 내리막이 있으니깐 \\n하지만 두려움에 떨거나 즐기는 것은 \\n너의 선택이야')]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "file_path = \"C:/Users/niceq/Desktop/롤러코스터.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "pages = loader.load_and_split()\n",
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f2c7bda8-9a2a-4c29-b380-be5a128c9ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "file_path = \"C:/Users/niceq/Desktop/차은우_비주얼_나무위키.txt\"\n",
    "text_loader = TextLoader(file_path, encoding = 'UTF-8')\n",
    "document = text_loader.load()\n",
    "document_content = document[0].page_content\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=0,\n",
    ")\n",
    "\n",
    "texts = text_splitter.create_documents([document_content])\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5517292c-e7ca-40e2-85a7-f348c22e9b7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='잘생김 대명사'),\n",
       " Document(metadata={}, page_content=\"- 아이돌/스포츠 팬덤에서는 최애를 '시대를 대표하는 미남'의 이름으로 부르는 주접 문화가 있는데 최근에는 차은우가 가장 많이 언급된다.\"),\n",
       " Document(metadata={}, page_content='( ex. 유튜브 아이콘 유튜브 아이콘 유튜브 아이콘 유튜브 아이콘 인스타그램 아이콘 X Corp 아이콘(블랙) X Corp 아이콘(블랙) X Corp 아이콘(블랙) X Corp'),\n",
       " Document(metadata={}, page_content='아이콘(블랙) 디시인사이드 아이콘 디시인사이드 아이콘 디시인사이드 아이콘 )'),\n",
       " Document(metadata={}, page_content='- 이 문화는 유행처럼 점점 다른 장르에까지 퍼져 투디/버츄얼/스트리머/게임/e스포츠/동물/정치 등 다양한 장르의 팬덤에서도 종종 볼 수 있다.'),\n",
       " Document(metadata={}, page_content=\"- 남초 커뮤니티에서 불특정 다수의 유저들에게 질문을 할 때 '차은우'라고 부르는 문화가 있다.\\n(ex. 이 신발 정보 아는 차은우 구함 # )\"),\n",
       " Document(metadata={}, page_content='- 수많은 VS 대결 밈의 대상으로 이용된다. 유튜브 아이콘 유튜브 아이콘 유튜브 아이콘 유튜브 아이콘 유튜브 아이콘 유튜브 아이콘 유튜브 아이콘'),\n",
       " Document(metadata={}, page_content='(ex. 100억부자 유병재 vs 무일푼 차은우 유튜브 아이콘 )\\n(ex. 다시 태어나면 오타니 vs 차은우 # )'),\n",
       " Document(metadata={}, page_content='(ex. 1000억 충주맨 VS 6급 차은우 유튜브 아이콘 유튜브 아이콘 )\\n성형/교정을 하지 않은 모태 자연미남이다.\\n- 방송에 언급한 내용 유튜브 아이콘'),\n",
       " Document(metadata={}, page_content='- 성장과정 유튜브 아이콘\\n- 쌍꺼풀에 관한 #\\n- 치아교정도 안함 #'),\n",
       " Document(metadata={}, page_content='강동원, 이나영을 만났을 때와 흡사한 느낌이 들었다. 아스트로의 차은우는 조막만한 얼굴에 꽉찬 눈, 코, 입. 훤칠한 키에 긴 팔다리의 소유자다. \"첫 콘서트 때 부모님이'),\n",
       " Document(metadata={}, page_content='오셨는데, 닮았대요.\" 옆에서 매니저는 \"어머니가 진짜 미인이세요\"라고 덧붙인다. 포토가 카메라를 누를 때마다, 그는 매우 다양한 눈빛과 표정을 드러냈다. A컷 고르기가 힘들'),\n",
       " Document(metadata={}, page_content='정도로.'),\n",
       " Document(metadata={}, page_content='- 2016년 인스타일 11월호 中 Editor 한지희 -'),\n",
       " Document(metadata={}, page_content='미용/뷰티와 관련해서는 큰 관심이 없는 편이다. 미를 위해 특별히 관리하는 것은 물 많이 마시기와 영양제 챙겨 먹기 정도이며 피부과도 주변에서 \"갈 때 됐다 가자!\"라고 해야'),\n",
       " Document(metadata={}, page_content='겨우 가는 정도. 유튜브 아이콘'),\n",
       " Document(metadata={}, page_content=\"특이한 점은 남초 커뮤니티에서도 '가장 잘생긴 남자', '압도적 1황' 등의 찬양을 많이 했다는 것이다. 남초 커뮤니티에서 남자 아이돌을 이렇게 잘생겼다고 칭찬해주는 것은 굉장히\"),\n",
       " Document(metadata={}, page_content='흔하지 않은 사례다. 여성에게만 어필되는 외모가 아니라 현대 젊은 남성들도 닮고 싶어하는 워너비의 외모를 갖고 있다. # #'),\n",
       " Document(metadata={}, page_content='독보적으로 뛰어난 비주얼로 아이돌 덕후들 사이에서 \"최애는 최애고 차은우는 차은우다\", \"최최차차\"라는 말도 생겼다.'),\n",
       " Document(metadata={}, page_content='오직 외모 하나로 신인이었던 ASTRO의 인지도를 높히는데 굉장히 큰 기여를 하였다.'),\n",
       " Document(metadata={}, page_content='2016년 중반 미니 2집 Summer Vibes 활동 때부터 여초 커뮤니티에서 아스트로 흰티남이라고 불렸으며, \"ASTRO라는 그룹에 잘생긴 애가 있다더라\" 라는 내용으로'),\n",
       " Document(metadata={}, page_content='언급되기 시작했고 남초 커뮤니티에서도 여자들이 좋아하는 얼굴로 자주 언급되면서 대중적인 인지도를 확보하였다.'),\n",
       " Document(metadata={}, page_content='16년 첫 단독 브이앱에서는 다량의 얼빡 샷을 선보이며 호평을 받기도 하였다.#'),\n",
       " Document(metadata={}, page_content='데뷔 초 미니 1집 Spring Up 활동을 할 당시에는 볼살이 올라 동글동글하고 귀여운 외모로, 지금과는 사뭇 다른 인상이었다. 그러다 다이어트를 하면서 얼굴선이 살아나고'),\n",
       " Document(metadata={}, page_content='나이가 듦에 따라 이목구비가 뚜렷해지면서 미니 2집 활동부터는 완전히 물이 오른 외모[1]로 본격적으로 이름을 알리기 시작했다. 얼굴천재[2]라고 불리기 시작한 것도 이 때이다.'),\n",
       " Document(metadata={}, page_content='이 말이 차은우에게 처음 사용된 말은 아니지만, 유행시킨 장본인이다.'),\n",
       " Document(metadata={}, page_content='18년 아는형님에서 잘생겨서 좋은 점으로는 데뷔 초 돈이 별로 없을 때 둘 중 어떤 메뉴를 고를까 고민하면 하나만 시켜도 서비스를 준다고 했다. 유튜브 아이콘'),\n",
       " Document(metadata={}, page_content='장두형이다. 다음 카페 아이콘 소두로 유명하지만 앞뒤로 긴 두상의 영향으로 머리둘레는 58cm이며, 한국 남성 평균 사이즈인 56~57cm보다 크다. 유튜브 아이콘 두상 특성상'),\n",
       " Document(metadata={}, page_content='아시안핏 선글라스의 다리 길이가 잘 맞지 않는다. #'),\n",
       " Document(metadata={}, page_content='또렷한 이목구비와 황금 비율인 얼굴을 가진 정석 미남이다. 오른쪽 쌍꺼풀은 아웃라인 쌍꺼풀, 왼쪽 쌍꺼풀은 인라인이며 눈꺼풀로 눈을 뜨면 무쌍인 것처럼 보이기도 한다. #'),\n",
       " Document(metadata={}, page_content='계란형에 가까운 얼굴형이고 갸름하며 턱은 일자턱이고 턱에 명암이 졌을 때 살짝 엉덩이턱이 보인다.'),\n",
       " Document(metadata={}, page_content=\"자신의 신체 부위 중 가장 마음에 드는 곳이 어디냐는 질문을 받으면 보통 '눈' 이라고 답한다. 짙고 컬링된 듯한 속눈썹의 영향으로 눈이 동화 속 왕자님같아서 부모님이나 팬들도\"),\n",
       " Document(metadata={}, page_content='정말 멋지고 잘생겼다는 말을 많이 해준다고 한다.'),\n",
       " Document(metadata={}, page_content='코는 살짝 매부리코이지만 얼굴과의 조화가 매우 잘 맞고 매부리도 그리 심하지 않아서 사람들도 차은우의 코가 살짝 매부리코인 것을 모르는 경우가 많다.'),\n",
       " Document(metadata={}, page_content='데뷔 초의 앳되고 귀여운 외모에서 굵직한 선의 남성미가 넘치는 외모로 나날이 리즈를 갱신 중이다.'),\n",
       " Document(metadata={}, page_content='퍼스널 컬러는 여름 쿨톤이라는 추측이 많지만, 퍼스널 컬러를 크게 타지 않아서 어떤 톤이든 다 잘 어울린다.')]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "55bb94b0-1df7-4e00-84bd-9c1fdd19fc17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_16580\\304455544.py:3: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  openai_embedding = OpenAIEmbeddings()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임베딩 수: 4\n",
      "임베딩 차원: 1536\n",
      "임베딩 차원: 1536\n",
      "embeddings[0]: [-0.01363905893128265, -0.009446358031268955, -0.005943919478104129, -0.02294480773314062, -0.012475839748973755, 0.018202455112672995, -0.019774717717347474, 0.005880006530671005, -0.01290405817315644, 0.008788053555120605, 0.012060404659335807, -0.0032292101440946344, -0.02400576489570482, -0.014495493917002743, -0.005608375572757586, -0.00717105160784615, 0.027226986387031634, -0.013421754351216444, 0.007886878761139214, -0.017435497880830222, -0.004291765689138248, -0.015876016748055204, 0.0029112423924244645, -0.012469449013024025, 1.494218680647895e-05, 0.00395302595015552, 0.00401374352961378, -0.023916287141827502, 0.014201493986281313, -0.02166654505918757, 0.002701926930787398, 0.006953747027779942, -0.01880323830866059, -0.005582810766313392, 0.010194142123939902, -0.012322448116340673, 0.0024031330167810336, -0.014802277182268907, 0.005307983974763789, -0.007439486732123384, 0.018125758830695136, -0.014738364234835783, 0.009280183995413775, -0.014252624530492341, -0.0010545664266144725, 0.016694105455431645, -0.0015530886505953408, -0.03144525209348952, 0.006985703501496504, 0.0498777960520961, 0.012635623048879205, 0.012054012992063438, -0.014674451287402657, -0.021040197056755784, 0.00299912292797567, -0.0016233931488855036, -0.012610057311112371, 0.02807063990085227, -0.012680361925817864, -0.036839517522833126, -0.004719983647659613, 0.017269323844975044, -0.006813137798368957, 0.022932026261241162, 0.0030422643537575574, 0.0016521540217965416, -0.002083567581123431, -0.0019221869464765382, -0.03175203349611041, 0.012852927628945411, 0.00023388205028318883, 0.033158122064929706, -0.013677406140948941, -0.01650236661313227, 0.015390277975034403, 0.006445637419305852, -0.009887358858673737, 0.008283139780282698, -0.03351603680572954, 0.001858273766212754, 0.03433412551310598, -0.03530560305914758, 0.007068790519424094, 0.01179836120233094, 0.019263412275237198, 0.028990987834005486, -0.024644896232681346, 0.00296876413824654, -0.019404021504648185, -0.023366635421373575, 0.011900622290752994, 0.020247675018468816, -0.015773757522278428, 0.021768806147609628, -0.02162819878084392, 0.0014428385601594753, 0.0053846797910803304, 0.027559334458741994, -0.006381724471872728, -0.013881928317793052, 0.0035791343694813664, -0.010475359651439232, -0.015786538994177885, 0.0027003290139693058, -0.028198465795718518, 0.0010106261588388695, -0.0013781265379019748, -0.0131916664366055, 0.01651514808503173, -0.0137668848261489, 0.019199499327804074, 0.023954635282816432, -0.01756332377569647, -0.04583848585339285, -0.004381243908676885, 0.03303029617006346, 0.007899661164361312, -0.011402099251864818, -0.007241355756890323, -0.01780619409352951, 0.006132463418089958, 0.0330814295082424, 0.017448279352729683, -0.009663662611335161, 0.002179437235103778, -0.015045147500101948, -0.01233523145088541, -0.02876090085071718, -0.0019829044095194684, 0.0031029817003851577, 0.06150998228724922, 0.015415842781478598, 0.018125758830695136, -0.0010106261588388695, -0.017320453457863434, 0.004895744718762024, -0.0015155397008461164, 0.02277863369728544, -0.03681395457903421, -0.007842138952877916, 0.008059443532944122, 0.01839419395497237, -0.014239842127270244, -0.02541185346452412, 0.0035375908605175714, 0.001003435882403445, 0.03504995126941508, -0.011651361236970225, 0.010232489333606192, -0.0045410267429210165, -0.00452824433969892, -0.003806025984794806, 0.030090295000203895, -0.005234483992083433, 0.008922271117259222, 0.02212672088840946, 0.004122395819646883, 0.01671967026187584, -0.017818975565428972, -0.009484706172257884, -0.0035088299876065336, -0.01438045042535859, 0.028172900989274323, -0.030908381844935055, -0.0031668948806489417, 0.03768317289929904, 0.002671568141058268, 0.0004545820144129303, 4.64618383729712e-05, -0.005979071785456876, -0.003972200020649986, -0.006442442051330987, -0.016310625908187618, -0.009555010786963377, -0.023162113244529464, -0.0013733330202783584, 0.002486220267539283, 0.0022353612969384217, -0.017013670192597266, -0.02323880766386205, -0.032212211187977575, 0.002660383421823603, 0.006615007288797215, 0.016412886996609675, 0.01633619257727709, 0.015045147500101948, 0.016770801737409507, 0.009350488610119268, 0.015262452080168154, -0.004048895836966527, 0.01003435882403445, 0.020707848985045425, 0.02720142158058744, -0.013306710859572291, -0.6409718242265591, -0.0212191544271557, 0.029681250646515674, 0.010878012337855084, 0.003914678274827909, 0.007669573715411688, -0.0015427027733543922, 0.027789421442030296, -0.009222662715253018, 0.04059760926271441, 0.011363752042198525, -0.007644008443306174, -0.017831758899973706, 0.011203968742293076, 0.010833272529593785, -0.014738364234835783, -0.0005244869752909051, -0.0008500444243933575, 0.0041383740565051645, 0.010398663369461372, -0.008979792397419977, 0.003352242754167927, -0.020490545336301857, -0.0073691821174178915, 0.018279151394650858, 0.013856363511348857, -0.0037293301684782646, 0.017320453457863434, -0.019646891822481225, 0.05000562194696235, -0.014303755074703368, 0.026664551332032972, 0.007081572922646192, -0.0030630361082394546, 0.05501640969170721, -0.0029559815021937834, 0.013651841334504748, 0.03625151766139027, 0.02224176344873097, 0.06053850101591706, -0.0035631561326230853, -0.021270284040044087, 0.012757057276473086, -0.035944736258769386, 0.016949757245164142, 0.0027115139660346304, -0.020247675018468816, 0.007759051934950326, -0.009408010821602662, -0.007969965779066805, -0.010846055864138521, -0.010705446634727537, 0.03586803997679153, 0.01179836120233094, -0.0029559815021937834, 0.0031876666351308394, 0.014278189336936534, -0.012143491677263396, 0.011568273287719996, 0.02077176193247855, 0.013587928387071622, 0.016566279560565396, -0.012194622221474423, -0.012974361856539293, -0.03392508115941776, 0.036839517522833126, -0.0217943728166991, -0.0016601431402256822, -0.030039163524670228, -0.01738436640529656, -0.005327158045258255, -0.016246712960754493, -0.011120881724365485, 0.014661668884180561, 0.009593358927952308, 0.01982584733023586, 0.0222801115897199, -0.01110170765387102, -0.011504360340286872, 0.0055444626253244615, 0.0037708736774420596, -0.0019381651833348195, -0.012763448943745455, 0.0012151481028523196, 0.007362790915806843, -0.008634661922487522, -0.03379725526455151, -0.02060558789662337, 0.0017528171934005046, -0.013076622944961348, 0.0421826570645789, 0.0172821053168745, 0.015530887204445388, -0.019404021504648185, -0.0013741319786874046, 0.013306710859572291, -0.014508277251547479, 0.012175448150979958, 0.007976356515016533, 0.0018247193756780996, 0.005736201933285155, 0.0037453084053365457, 0.01445714670733645, -0.007778226005444791, 0.016412886996609675, 0.0062059634007703155, -0.03200768901113347, -0.00876248781735377, 0.012558926766901344, -0.011894230623480627, 0.024274200019982057, -0.0056435278801103324, -0.011964535238186118, 0.006557485542975139, 0.013357841403783318, -0.02162819878084392, -0.005915158838023751, 0.015045147500101948, 0.01278262301423992, -0.005212114553614103, 0.02640889954230047, -0.017729497811551653, 0.027226986387031634, 0.02101463225031159, 0.00407446110907204, 0.01700088872069781, -0.018010716270373622, -0.009529445049196544, -0.01813854216523987, -0.010360316159795081, 0.0009794685271160234, -0.015671496433856374, -0.006940964158896526, -0.036839517522833126, 0.013293927525027555, -0.003706960730008935, 0.0341040366671724, -0.01871376055478327, 0.027457073370319936, 0.005419832098433077, -0.015185755798190294, 0.00998961994709579, 0.0004302151508171531, 0.016003844505566734, 0.008756097081404042, 0.0025181767412558453, -0.016936975773264685, -0.006052571768137232, 0.01703923686168674, 0.01261644897838474, -0.010194142123939902, 0.02187106723603168, -0.0040233305648610124, 0.0029144379932299885, 0.016566279560565396, 0.011977317641408216, 0.008685792466698549, -0.014533842057991672, -0.023047068821562676, -0.009919315332390299, 0.017230975703986115, 0.009433575628046857, -0.010986664162226868, -0.0035951126063396475, 0.02008150098261364, -0.06104980832067262, -0.026050984801500643, 0.007017659975213067, -0.010053532894528917, -0.017601671916685404, -0.010015184753539986, -0.006755616052546881, -0.00407446110907204, -0.0003285533685133801, 0.010219706930384095, -0.011542708481275803, 0.011319012233937227, -0.0016353768265292144, -0.004691222541917915, -0.02699689940374333, 0.006423267980836522, -0.020707848985045425, -0.01651514808503173, 0.01229049164262411, 0.030703859668090947, 0.02486220174407019, -0.0037804607126892924, 0.021653763587288113, -0.01811297735879568, 0.00889031464354266, 0.005921550039634799, 0.010871620670582716, -0.020822893408012216, -0.008781661887848236, -0.0047998748319510185, -0.031164035497312833, 0.003949830582180656, 0.01765280152957379, 0.01261644897838474, 0.021142458145177838, 0.027226986387031634, 0.012795405417462017, 0.025756984870779213, -0.01848367357149497, -0.009235445118475115, -0.008506835096298633, 0.012098752800324736, -0.02568028858880135, 0.026613421719144582, -0.0025069920220211804, 0.005160984009403075, 0.001163218716647576, 0.0015738604050772383, 0.014444364304114353, -0.00917792290699172, 0.02725255119347583, -0.017946803322940498, 0.011088925250648923, -0.02015819540194622, 0.0068514859393578875, 0.00020891599698445962, 0.011958143570913751, -0.026306638453878418, -0.007484225609062043, 0.0010377892313471453, 0.011517143674831608, 0.029885772823359785, 0.037759869181276905, 0.005426223300044126, -0.010513707792428164, -0.036123691766524024, 0.005298397405177876, 0.0032324057449001583, 0.014137581038848188, -0.0066469637625137775, -0.008142530550871713, 0.013779667229370997, -0.01999202136609104, 0.010903577144299278, -0.011018620635943431, 0.0036558301857979075, 0.006295441620308953, 0.012590883240617906, -0.010347532825250345, 0.009842619981735077, 0.03407847372337348, 0.013856363511348857, 0.012757057276473086, -0.002965568537441016, 0.03200768901113347, -0.025731420064335018, 0.009804271840746146, 0.010660707757788877, -0.013920276458781982, -0.012520579557235054, -0.041799175654689595, -0.006231528672875829, 0.003371416824662392, 0.03336264424177382, 0.025015592445380635, 0.01790845518195157, -0.0021602631646093127, 0.01789567184740683, -0.013114971085950278, 0.017831758899973706, 0.018828803115104785, 0.023673416823994462, -0.03960056504758333, -0.008442922148865509, 0.003585525803923075, -0.013345058069238582, -0.02541185346452412, 0.008078617603438589, -0.02456820181334876, 0.0033746124254679165, -0.01512184285075717, 0.018010716270373622, -0.03251899259059846, 0.005036353482511691, 0.005911963004387567, -0.011357360374926158, -0.03604699548454616, -0.0007066393644196956, 0.027840552917563963, 0.009932097735612396, -0.03198212234204399, -0.023788461246961254, 0.0005744191400960285, -0.015466973325689625, 0.021129674810633103, -0.004294961522774431, 0.015773757522278428, 0.0076951389875172015, -0.01048814205466133, -0.014942886411679892, -0.025629158975912964, 0.020055936176169444, -0.004870179446656511, 0.019544630734059168, 0.022586894854986068, 0.010002402350317888, -0.008992574800642075, 0.004413200382393448, -0.010564837405316552, -0.017154279422008253, 0.025782549677223408, -0.002979948857481205, -0.018611499466361217, 0.016783583209308964, -0.008858357238503457, -0.01941680483919292, 0.01848367357149497, -0.029962467242692366, -0.020209326877479887, -0.0131916664366055, 9.142570976452042e-05, -0.03326038501599704, -0.014610538339969533, 0.022292894924264638, -0.0038156130200420386, 0.004004156494366548, -0.005761767205390669, -0.019314543750770866, -0.010334750422028248, 0.04591518213537071, -0.01893106420352684, 0.006209159234406499, -0.007196616879951663, -0.009797880173473779, 0.018994977150959963, -0.02651116063072253, -0.028454119448096293, -0.011312621497987499, -0.017422714546285488, -0.0027115139660346304, -0.017844542234518444, -0.008749705414131673, 0.010986664162226868, 0.03162420760124416, -0.0006487181393930966, 0.021193589620711505, -0.002634818149718089, -0.004911722955620306, 0.018304716201095052, -0.004307743925996529, -0.00909483588906413, 0.0006698893148718521, 0.020758980460579092, 0.027968378812430212, 0.02129584884648828, -0.009350488610119268, -0.001757610594608791, 0.01199649171190268, -0.0159654963645778, -0.013549580246082693, -0.006011028259173438, -0.00869218320264828, -0.010053532894528917, 0.0005348728525318539, 0.06877051025198873, -0.008142530550871713, 0.01859871613181648, -0.0028521227297842963, 0.01593993155813361, 0.03763204328641065, 0.019966456559646847, 0.013818015370359926, -0.0029959273271701462, -0.00790605190031104, -0.002367980942258947, -0.00741392146001787, 0.016975323914253614, 0.0006363349243371978, -0.007669573715411688, 0.026766812420455026, 0.0036654172210451403, -0.026153245889922697, -0.003898700037969628, 0.014265406933714439, -0.00790605190031104, 0.0052408751936944805, -0.004822244270420348, -0.0011656154754593842, 0.004045700003330342, 0.010264445807322754, -0.02876090085071718, -0.0159654963645778, -0.0034960473515537765, -0.015594800151878512, -0.015530887204445388, -0.017435497880830222, -0.010711838301999906, -0.018240803253661928, 0.00026923399537478305, -0.024197505600649472, -0.0172821053168745, -0.023877939000838573, 0.004684831340306866, -0.006723659578830319, 0.016042192646555663, 0.015914364889044137, -0.02110411000418891, -0.007056007650540678, 0.027866117724008158, -0.0041000263811775545, -0.008851966502553729, 0.011466013130620581, -0.021819937623143295, -0.0010737403806936078, 0.00876248781735377, -0.00043341080983034234, -0.0015506918917835327, -0.01668132212088691, 0.02015819540194622, 0.029169945204405398, 0.006522333235622393, 0.02470880918011447, -0.02640889954230047, 0.005701049625932409, -0.0047008095771651475, 0.015172973394968196, -0.000989854404356972, -0.020286023159457746, 0.009222662715253018, 0.011619403831931024, -0.032621251816375235, -0.010258055071373026, -0.014815059585491003, -0.0039050912395806768, 0.017218192369441377, -0.008014704656005463, 0.02357115573557241, -0.002005274080819458, 0.009721184822818557, 0.037274128545610824, -0.032928036944286684, 0.013920276458781982, -0.010059924561801284, 0.014533842057991672, 0.020464978667212384, -0.0005456582089773255, 0.015543669607667485, -0.009037314608903373, -0.013089406279506085, -0.006832311868863422, -0.04629865981996946, 0.019685239963470155, 0.015454190922467527, 0.004822244270420348, 0.010334750422028248, -0.009350488610119268, -0.01339618861344961, 0.00036070964003986883, -0.008621879519265425, -0.016170018541421912, 0.006004637057562389, -0.0051737664126251725, -0.00807222593616622, 0.00035351942181210933, -0.010245272668150928, -0.024146374125115805, 0.013306710859572291, -0.0017336432393213694, -0.04944318502931841, -0.025245679428668937, -0.034870995761660445, -0.018458106902405496, -0.014597755005424796, -0.018279151394650858, -0.035458995623103305, -0.023200461385518397, 0.00905009701212547, -0.012034839852891612, 0.007043225247318581, -0.01028361987781722, -0.0030901990643324006, -0.04136456835720246, -0.007318051573206864, 0.00999601068304552, -0.030320381983492198, 0.0021634589982454967, 0.008820010028837167, 0.05982267525960796, 0.01950628259307024, 0.016745236930965312, 0.014521059654769575, -0.0011536316814003435, 0.01171527418440335, -0.005681876021099263, -0.0027866118655330797, -0.02924664148638326, 0.010430619843177934, -0.03042264307191425, 0.0038603521298113575, 0.013332275666016486, 0.020055936176169444, 0.01122314281278754, 0.025015592445380635, -0.006979312299885456, 0.01839419395497237, -0.0011408490453475866, -0.02314932990998473, -0.006468007323436501, -0.0165407147541212, -0.0026571878210180787, -0.020094282454513095, -0.009976837543873695, -0.0021986110727675832, 0.005256853896214082, -0.007950791708572338, -1.5141915494803277e-05, -0.0021394914101274154, 0.015914364889044137, 0.015645929764766902, 0.025846462624656532, -0.02469602770821501, 0.0025788940878834457, 0.026945769790854942, 0.018700977220238536, -0.013945841265226177, -0.01270592673226206, 0.00786131302337238, 0.0017911649851434454, 0.016617409173453786, 0.015709842712200026, 0.033899514490328284, -0.004662461901837537, 0.003253177499382056, -0.0026939378123582575, 0.028402987972562625, -0.020899587827344798, -0.03210994823691024, -0.0023344265517242927, -0.018777673502216395, -0.03356716641861793, -0.013204449771150236, -0.006781181324652395, -0.027508204845853604, 0.0002528562502081464, -0.007759051934950326, -0.012840144294400675, 0.027891682530452353, -0.03093394665137925, -0.03216107784979863, 0.00970840241959646, 0.025258462763213675, 0.027150291967699053, -0.007912443567583409, 0.014201493986281313, 0.025846462624656532, -0.005835267188071026, -0.034794299479682586, 0.001757610594608791, -0.01666854064898745, -0.016400105524710218, 0.01852201984983862, 0.007592877899095147, -0.017767845952540582, -0.01204123058884134, -0.005320766843647206, 0.014904538270690961, -0.02499002763893644, -0.022868113313808038, 0.029425598856783176, 0.01004075049130682, -0.007298877502712398, -0.0013110177568326662, -0.003793243348742049, -0.03402734038519453, 0.03543342895401383, 0.0035983084399758315, -0.016464018472143342, -0.01306384054173925, -0.01787010704096264, -0.006640572560902729, 0.009088445153114402, -0.02588481076564546, 0.02855637867387307, 0.025590810834924035, -0.011319012233937227, 0.001057762027419997, -0.0012407133749578333, -0.006027006496031719, 0.009663662611335161, -0.019723586241813806, 0.03924265403207406, -0.030831685562957196, 0.0172821053168745, 0.007068790519424094, 0.0031157643364379145, -0.026638986525588777, 0.001408485211215775, -0.013894710721015148, 0.03267238515455418, -0.02142367660399981, -0.02335385208682884, -0.00970840241959646, 0.015991061171021996, 0.028172900989274323, 0.01462332074319163, -0.010948316952560577, -0.016412886996609675, -0.018049064411362552, -0.01880323830866059, 0.016157235206877178, 0.005029962280900642, -0.010711838301999906, -0.013421754351216444, -0.023916287141827502, -0.00929935806590824, -0.03510108088230347, -0.008717748940415111, 0.015748190853188956, 0.04650318199681357, -0.017844542234518444, -0.016195583347866107, 9.716791046333955e-05, 0.018010716270373622, 0.01151075200755924, -0.029144380397961207, 0.008717748940415111, 0.015300799289834445, -0.01813854216523987, 0.011945361167691654, -0.017818975565428972, 0.00659583321830275, -0.00546776680900792, 0.009919315332390299, 0.012060404659335807, -0.02268915594340812, 0.006781181324652395, -0.0031621013630253256, -0.02761046593427566, -0.005522093186855132, -6.790768127068968e-05, 0.005189745115144773, -0.001206360026014133, -0.014981233621346183, 0.025974290382168058, -0.006014224092809622, -0.00810418334120542, -0.008615487851993057, -0.032212211187977575, 0.02022211021202462, -0.011517143674831608, 0.032800211049420436, 0.008110574077155151, -0.009702010752324092, -0.026306638453878418, -0.016988105386153075, 0.0067364424477137355, -0.006436050849719939, -0.02807063990085227, 0.0010905174595456052, -0.0020691870282525822, 0.005934332908518216, -0.003152514327778093, -0.030320381983492198, 0.007663182513800639, -0.04105778322929102, -0.03305586283915293, 0.02543742013361359, 0.016195583347866107, -0.0030214925992756597, 0.012469449013024025, 0.035484562292192774, 0.0015419039313606761, 0.016476801806688077, -0.00659583321830275, -0.005442201536902407, -0.012840144294400675, -0.024798288796637067, -0.008698574869920647, -0.013217232174372333, -0.004269396250668918, 0.03126629658573489, 0.023366635421373575, -0.010251663404100657, -0.027303682669009496, 0.009797880173473779, -0.032340037082843824, -0.010679881828283343, 0.004652874866590304, -0.0021842307527273944, 0.001394903733169302, -0.014150363442070286, -0.005199331684730686, 0.03671169162796688, -0.007822964882383451, 0.017882890375507374, 0.0003137734528533381, -0.009452749698541322, 0.017729497811551653, 0.006979312299885456, -0.0033362645173096455, -0.015786538994177885, -0.015109060447535072, -0.019800282523791665, -0.009414401557552392, 0.011108099321143388, -0.027099160492165385, 0.03568908446903689, 0.001538708214139822, -0.00015189351285653995, 0.0004098428464359462, -0.00913318403005306, -0.023890722335383308, 0.001265479688654301, 0.035458995623103305, 0.013204449771150236, -0.008059443532944122, -0.006170811093417569, -0.008263965709788233, -0.004454743891357243, -0.009676445945879898, 0.02458098328524822, -0.0022465460161730866, 0.034564210633749, 0.006196376365523082, -0.01519853820141239, 0.03420629961823973, -0.022331243065253567, 0.02270193741530758, -0.0022018069064037673, -0.005780941275885134, 0.01093553361801584, -0.008289530516232426, 0.0009011749103967201, -0.016642975842543258, 0.0008867944739412011, -0.019186717855904617, 0.011331795568481963, 0.018585932797271745, -0.0042374393112910354, 0.003267558052252905, 0.0018646650842391323, 0.0054997232827244825, -0.03845012826849654, 0.013089406279506085, -0.009842619981735077, -0.013102188682728182, -0.03405290705428401, 0.03157307798835577, -0.0007861313023372381, -0.01629784443628816, -0.005828875986459977, 0.0048605924114092786, -0.006384920305508911, 0.005371897387858234, -0.021819937623143295, 0.01629784443628816, -0.01323001457759443, 0.002110730537216377, 0.06825920667252373, -0.0157354093812895, -0.00807222593616622, 0.011408490919137185, -0.017767845952540582, 0.006132463418089958, 0.02060558789662337, 0.23929070103843184, -0.02408246117768268, -0.021986111658998473, 0.024350896301959916, -0.0024366874073156876, 0.015863235276155747, 0.010929142882066112, -0.006615007288797215, 0.007918835234855776, 0.03198212234204399, -0.021244719233599895, 0.0033905906623261975, -0.008864748905775826, -0.0007158268622547403, -0.012693144329039962, -0.023379416893273032, -0.02499002763893644, 0.013933058862004079, -0.03157307798835577, -0.016221148154310302, -0.0021698501998565455, -0.008347052727715822, -0.016566279560565396, -0.0009834630863305937, 0.01917393452135988, -0.0032052427888072123, -0.015799322328722623, 0.011248708550554374, 0.0037740695110782436, -0.0018790455206946514, -0.0247471573211034, 0.0016968932479811908, 0.011664143640192323, 0.0007302073569179242, -0.0035791343694813664, -0.01826636806010612, 0.018918282731627382, 0.020107065789057833, 0.03752978033534332, 0.029885772823359785, 0.005518897353218948, 0.0006147642696539193, -0.0010937131767664592, -0.00577774544224895, -0.006260289778617527, -0.001366142860258264, -0.0026092528776125758, -0.024261418548082597, -0.03515221422048242, 0.030652730055202557, -0.026817942033343416, -0.012507796222690317, 0.013383406210227513, 0.06370859289435549, 0.0025852855223251537, 0.013549580246082693, -0.002252937217784135, -0.0070943557915296085, -0.027226986387031634, 0.012552536030951616, 0.005502919116360667, 0.036609432402190105, -0.022433502291030343, 0.028147336182830128, -0.01766558486411853, 0.004831831305667581, -0.026715682807566636, 0.009510271910024718, -2.0746796126562398e-05, -0.006627790157680632, -0.006640572560902729, 0.0033362645173096455, 0.008577139711004126, -0.012859318364895142, -0.045199356379061605, -0.03453864768995009, 0.027891682530452353, -4.6736465774164525e-05, 0.034922125374548835, 0.032391166695732214, -0.009561401522913106, 0.006237919874486878, 0.01974915291090328, -0.004355678636571372, -0.026562290243610915, -0.024874985078614926, 0.0007222181802811188, -1.571613501898833e-05, -0.04021413157811567, -0.013485667298649568, 0.010884403073804814, -0.012469449013024025, -0.004790287796703786, -0.016400105524710218, 0.016489583278587534, 0.01913558638037095, -0.004058482872213759, 0.01110170765387102, -0.017972368129384693, 0.016285061101743426, -0.02043941386076819, 0.004016939363249965, -0.007241355756890323, 0.01412479863562609, -0.005975876417482011, 0.01445714670733645, -0.003978591222261034, -0.004288569855502063, 0.02346889650979563, -0.004739157252492758, -0.027661595547164047, -0.01606775745299986, 0.014188711583059217, 0.009676445945879898, 0.008877531308997924, 0.002687546377916549, 0.0053846797910803304, -0.009772315367029584, 0.0011640175586412921, -0.003946634748544471, 0.008500444360348905, -0.00018764490804882466, -0.0074906168106730914, 0.008883922976270291, 0.025552462693935102, -0.018790454974115852, -0.011293447427493034, -0.005352723317363768, 0.011082534514699195, -0.03965169466047172, 0.0222801115897199, -0.03678838790994474, 0.023647852017550267, -0.029067684115983344, -0.009280183995413775, 0.003285133973098618, 0.006819529465641325, 0.015786538994177885, -0.0184325420959613, 0.0011520338809975813, 0.016694105455431645, -0.0032308078280820665, -0.0007901258615518084, -0.011613013095981294, -0.01438045042535859, -0.009817054243968244, 0.014303755074703368, -0.025974290382168058, -0.004314135127607577, -0.006055767601773417, -0.022957591067685357, -0.0009243434236904256, -0.013460101560882735, 0.003061438191421363, 0.013702971878715775, -0.010724620705222001, -0.03579134369481366, -0.025999855188612253, 0.003863547730616882, 0.024759940655648134, -0.034436384738882754, -0.0007593677090334853, 0.04461135279232819, -0.03405290705428401, -0.022011676465442668, -0.013332275666016486, -0.1620836519229462, 0.025769768205323947, 0.0018103389392225807, -0.026229942171900555, 0.03556125857417064, 0.02380124458150599, 0.02486220174407019, -0.0052408751936944805, -0.009235445118475115, 0.013447319157660637, 0.026638986525588777, -0.021960546852554278, -0.017218192369441377, 0.00023128558097295168, 0.009209879380708282, 0.009292966398635872, -0.0015730615630835222, -0.005601984371146538, 0.0023759700606880876, 0.01429097267148127, 0.02511785353380269, -0.03223777413177649, 0.026434464348744666, 0.020170978736490958, 0.002062795826641534, 0.012245752765685451, -0.0056435278801103324, 0.0007589682298289622, -0.015786538994177885, 0.0021027414187872366, -0.017729497811551653, -0.001031397913320767, 0.0200687176480689, 0.0061068981459844445, 0.028121769513740656, -0.00700487757199097, -0.023507242788139284, -0.012744274873250989, -0.019199499327804074, 0.0074906168106730914, 0.009695619085051723, 0.008136139814921983, 0.016285061101743426, -0.010091881035517846, -0.028837597132695042, -0.0052408751936944805, 0.013958624599770913, 0.026281071784788945, -0.009312140469130337, -0.008941445187753687, -0.004224656908068939, -0.010027968088084722, 0.011248708550554374, 0.02625550697834475, 0.010903577144299278, 0.027917249199541826, 0.01815132363713933, 0.008065835200216491, 0.005256853896214082, 0.004911722955620306, 0.010258055071373026, 0.005244071027330665, 0.019352891891759795, 0.012418318468812998, 0.008864748905775826, 0.002572502886272397, -0.009970445876601326, 0.013677406140948941, -0.021768806147609628, 0.013498449701871666, -0.002297676560384114, -0.02118080628616677, -0.004930896560453452, -0.03405290705428401, 0.02383959085984964, -0.008954227590975784, -0.027175856774143244, 0.03847569493758601, -0.006723659578830319, 0.013830797773582024, -0.003387395061520673, 0.02493889802604805, -0.020477762001757122, 0.0006950551077728428, -0.0023472091877770494, 0.015824887135166818, 0.011664143640192323, -0.020784545267023287, -0.015224103939179223, -0.018905499397082644, 0.03433412551310598, -0.02155150249886606, -0.006113289347595492, -0.01609332225944405, 0.024274200019982057, 0.02617881255901217, -0.0038156130200420386, 0.007669573715411688, 0.019186717855904617, -0.0015051538236051675, -0.013881928317793052, 0.00432372216285481, -0.011983709308680585, 0.010865229934632988, 0.014661668884180561, 0.0029144379932299885, 0.01229049164262411, 0.013792450563915733, 0.022382372678141957, -0.028990987834005486, -0.0006307425647198654, 0.008877531308997924, 0.02106576186319998, 0.03494769204363831, 0.031803166834289354, 0.0443045713897073, -0.011146447462132319, -0.014572190198980603, 0.011702490849858613, -0.0030630361082394546, 0.041569090534046574, -0.013971407002993009, -0.03075499114362461, -0.0021490784453746478, -0.003643047549745151, -0.0035088299876065336, -0.04696335596339018, -0.028888728608228706, 0.023008720680573743, 0.006426463814472706, 0.004608135523990325, 0.01978750105189221, 0.023366635421373575, 0.011613013095981294, -0.036558302789301715, -0.0013549580246082693, -0.013447319157660637, -0.0129487970500951, -0.004982027104664479, -0.011542708481275803, 0.028837597132695042, -0.025258462763213675, -0.01089718640834955, -0.010085489368245479, -0.0008160905546541802, 0.01738436640529656, -0.0025852855223251537, 0.001481186468317746, 0.014559407795758506, -0.03213551490599972, -0.01609332225944405, 0.016310625908187618, -0.007759051934950326, 0.044048919599974805, 0.009772315367029584, 0.009606141331174404, -0.018291932866550314, -0.005832071820096161, -0.006704485508335854, -0.010437011510450303, -0.007874095426594478, -0.00946553210176342, -0.04619640059419268, 0.007215790484784808, 0.005710636661179641, -0.008794444291070333, 0.02470880918011447, 0.025744203398879756, -0.0002336823252328436, -0.0242358537416384, 0.006774790123041346, 0.008379009201432384, -0.002267317770654984, 0.03379725526455151, 0.00389230860352792, -0.016080538924899315, -0.01581210380062208, -0.011970925974135849, -0.04105778322929102, 0.009900141261895833, 0.05184631781326878, 0.0031093731348268657, 0.014099232897859259, 0.02773829182914191, -0.02224176344873097, -0.003139731691725336, 0.00011744034504341571, 0.005621158441641003, -0.027226986387031634, 0.009107619223608867, 0.004438765654498962, 0.0014747951502913676, -0.0025868832063125863, 0.004739157252492758, -0.0003227612401899537, 0.004630504962459655, 0.002395143898351893, 0.03303029617006346, -0.01802349774227308, 0.03747865072245493, -0.010500924457883427, -0.0026635790226291274, -0.030499337491246836, -0.022331243065253567, 0.010181358789395165, -0.016821931350297893, -0.022356807871697762, -0.021142458145177838, -0.008941445187753687, 0.006640572560902729, 0.016655757314442715, -0.0007789410841094786, -0.004093635179566506, -0.00717105160784615, -0.010194142123939902, -0.014661668884180561, 0.011088925250648923, 0.0031205578540615306, 0.0045857660855209955, 0.003879525967475163, -0.005359114518974817, 0.006857877140968936, -0.003949830582180656, 0.0059918546543402925, 0.022804198503729636, 0.012552536030951616, -0.005534875590077229, -0.042719527313133374, -0.06841259923647947, 0.02519454981578055, -0.006030202329667903, -0.04522491932286052, 0.0034033732983789543, 0.0021474807613872157, 0.018547586518928093, -0.02022211021202462, 0.0004925304433666779, -0.01971080476991435, -0.00880722762561507, -0.0031333404901142878, 0.004221461074432754, -0.004186309232741328, -0.029067684115983344, -0.03464090691572687, 0.03356716641861793, 0.006311419857167234, 0.024031331564794294, 0.01462332074319163, 0.002367980942258947, -0.011037794706437896, 0.00040065534860090154, 0.024389244442948845, -0.014393233759903326, 0.009983228279823423, -0.0190077604855047, 0.0033682212238568677, 0.0020803719803179073, -0.0024334918065101636, 0.015556452010889583, -0.029067684115983344, 0.02261245966143026, 0.01790845518195157, -0.011459621463348212, -0.002280100406707741, 0.0062443110760979255, 0.012316057380390943, -0.005145005772544794, 0.024555418478804027, -0.038577954163362786, -0.024248635213537862, 0.019889762140314265, 0.008155312954093809, -0.005125831702050328, 0.011766404728614377, 0.011421273322359283, 0.017972368129384693, 0.03520334383337081, -0.012130709274041298, 0.008078617603438589, 0.021372545128466144, -0.00401374352961378, -0.0012127513440405116, -0.016617409173453786, -0.02015819540194622, 0.01620836668241084, -0.007433095064851016, 0.02781498811111977, -0.03326038501599704, 0.02909324892242754, -0.012597274907890275, 0.006305028655556186, 0.008922271117259222, -0.00659583321830275, 0.00015748590157770484, -0.015837670469711553, -0.015492539063456458, 0.003441721206537225, -0.029809076541381922, -0.022919242926696424, -0.0032787427714875694, -0.008730531343637209, 0.007886878761139214, 0.008717748940415111, 0.010053532894528917, 0.008014704656005463, 0.006557485542975139, -0.009631706137618599, 0.025462984940057783, -0.001847089046978089, -0.00015798523603144236, -0.013536797842860595, -0.01921228266234881, 0.011248708550554374, 0.019813065858336403, -0.0212191544271557, 0.011088925250648923, 0.008040269462449658, 0.013242796980816528, -0.05895345693934313, 0.0005037152208090076, 0.006979312299885456, 0.007880487093866847, 0.005279223334683412, 0.01668132212088691, 0.022024459799987402, -0.0007038431846110294, 0.041569090534046574, 0.005365506186247185, 0.00942718396077449, -0.0037325260021144487, 0.005224896956836199, 0.004787092428728921, -0.01495566881490199, 0.0026683725402527436, -0.01438045042535859, -0.024159157459660543, -0.004870179446656511, 0.017550540441151737, -0.008736923010909578, 0.0006766801121027535, 0.0006894627481555104, 0.02339220022781777, -0.015109060447535072, -0.004755135955012359, -0.0006802751921128009, -0.014700016093846852, -0.021206371092610962, 0.025948723713078586, 0.006487180928269646, 0.0025741008030904892, 0.022625242995974997, -0.005122636334075464, 0.02467046290177082, -0.010270837474595123, -0.020349936106890874, -0.015530887204445388, 0.012763448943745455, 0.007765443602222694, -0.0029863402919229134, -0.00037289308638967364, -0.017742281146096387, -0.021385328463010878, -0.006365746235014446, 0.04011187235233889, 0.004803070665587202, 0.019071673432937825, -0.03653273612021224, 0.06713433283723585, 0.013012709997528224, -0.013083014612233716, 0.00892866185320895, 0.01081409939042196, 0.009312140469130337, 0.009823445911240613, 0.0004821445661257292, -0.015262452080168154, -0.0194934992585255, 0.003457699443395506, -0.01339618861344961, -0.017103149809119866, -0.04591518213537071, -0.021577067305310255, 0.0024462744425629204, -0.02190941537702061, 0.009030922941631006, -0.01609332225944405, 0.016131670400432983, 0.022292894924264638, 0.0051577881757668914, -0.007362790915806843, 0.02110411000418891, -0.01885436792154898, -0.014687233690624754, 0.0077398783301171805, -0.006285854585061721, -0.012341622186835138, -0.02281698183827437, -0.011504360340286872, 0.0026635790226291274, -0.026012638523156988, -0.014968451218124085, -0.006621398490408264, -0.012546144363679247, -0.011951752834964023, -0.01499401695589092, 0.0062666809802285756, 0.012757057276473086, 0.008839184099331631, 0.0062219416376285966, -0.008302313850777163, -0.004640091997706887, 0.024811070268536524, -0.0010673490626672295, -0.02155150249886606, 0.007893269497088943, 0.01934010855721506]\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "openai_embedding = OpenAIEmbeddings()\n",
    "\n",
    "embeddings = openai_embedding.embed_documents(\n",
    "    [\"안녕하세요\", \"무엇을 도와드릴까요?\", \"어서오세요\", \"도움이 필요해요\"]\n",
    ")\n",
    "\n",
    "print(\"임베딩 수:\", len(embeddings))\n",
    "print(\"임베딩 차원:\", len(embeddings[0]))\n",
    "print(\"임베딩 차원:\", len(embeddings[1]))\n",
    "print(\"embeddings[0]:\", embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "286398e5-8781-476d-8ec2-5b97c5c5bd5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.013785294348719451,\n",
       " -0.010510956007061024,\n",
       " 0.008625730929479583,\n",
       " -0.016656126937695758,\n",
       " -0.012442484580714923]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = openai_embedding.embed_query(\"안녕\")\n",
    "embeddings[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2ffd804b-792e-4fb7-8603-776db8ecfa31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='안녕'),\n",
       " Document(metadata={}, page_content='안녕'),\n",
       " Document(metadata={}, page_content='안녕하세요'),\n",
       " Document(metadata={}, page_content='안녕하세요')]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "openai_embedding = OpenAIEmbeddings()\n",
    "\n",
    "db = Chroma.from_texts(\n",
    "    texts = [\"안녕\", \"안녕하세요\", \"반갑습니다\", \"반가워요\"],\n",
    "    embedding = openai_embedding\n",
    ")\n",
    "\n",
    "similar_texts = db.similarity_search(\"안녕\")\n",
    "similar_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "32349532-7d43-4cff-b622-0aadbd00236f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_16580\\2687515974.py:18: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. See LangGraph documentation for more details: https://langchain-ai.github.io/langgraph/. Refer here for its pre-built ReAct agent: https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/\n",
      "  agent = initialize_agent(tools, llm=chat, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to do a math calculation to find Michael Jordan's age divided by 10.\n",
      "Action: Calculator\n",
      "Action Input: 58 / 10\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 5.8\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: 5.8\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'5.8'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import (\n",
    "    load_tools,\n",
    "    initialize_agent,\n",
    "    AgentType\n",
    ")\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# 환경 변수에서 SerpAPI API 키 가져오기\n",
    "SERPAPI_API_KEY = os.getenv('SERPAPI_API_KEY')\n",
    "\n",
    "# 환경 변수 설정 확인\n",
    "if not SERPAPI_API_KEY:\n",
    "    raise ValueError(\"SerpAPI API 키가 설정되지 않았습니다. 환경 변수 SERPAPI_API_KEY를 설정해주세요.\")\n",
    "\n",
    "chat = ChatOpenAI(temperature=0)\n",
    "tools = load_tools(['serpapi', 'llm-math'], llm=chat, serpapi_api_key=SERPAPI_API_KEY)\n",
    "\n",
    "agent = initialize_agent(tools, llm=chat, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "                             verbose=True)\n",
    "\n",
    "agent.run(\"마이클 조던의 나이를 10으로 나누면?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "08caad1a-b9ee-43de-abd0-5adebd53bd8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_16580\\2047397590.py:18: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = agent(\"BTS Dynamite 뮤직비디오를 찾아 유튜브 링크를 알려줘\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to search for the BTS Dynamite music video on YouTube to get the link.\n",
      "Action: youtube_search\n",
      "Action Input: BTS Dynamite,1\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m['https://www.youtube.com/watch?v=gdZLi9oWNZg&pp=ygUMQlRTIER5bmFtaXRl']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have found the link to the BTS Dynamite music video.\n",
      "Final Answer: https://www.youtube.com/watch?v=gdZLi9oWNZg&pp=ygUMQlRTIER5bmFtaXRl\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain.tools import YouTubeSearchTool\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import (\n",
    "    load_tools,\n",
    "    initialize_agent,\n",
    "    AgentType\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "tools = load_tools([\"ddg-search\"]) + [YouTubeSearchTool()]\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent= AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "\n",
    "result = agent(\"BTS Dynamite 뮤직비디오를 찾아 유튜브 링크를 알려줘\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "fc2f64e8-ec94-4290-b32a-022b97449842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m남성의류를 생성하는 회사 이름을 5개 만들어주세요.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "1. Gentlemen's Attire Co.\n",
      "2. The Dapper Man Clothing Co.\n",
      "3. Masculine Threads Inc.\n",
      "4. Manly Wardrobe Co.\n",
      "5. Gentleman's Choice Apparel Co.\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "import openai\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm = OpenAI(temperature=0.8)\n",
    "prompt = PromptTemplate(input_variables=[\"product\"], template=\"{product}를 생성하는 회사 이름을 5개 만들어주세요.\")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt, verbose=True)\n",
    "print(chain.run(\"남성의류\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f8a2c264-a1be-45b4-84a9-94eb4e2b0cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m\n",
      "겨울철 남자 패션의 변화와 스타일링 팁\n",
      "\n",
      "한겨울 추위를 맞이하면서 남성들의 패션 스타일링도 점차 변화하고 있습니다. 이전의 겨울 남자 패션은 단조롭고 무심한 이미지였지만, 요즘은 다양한 스타일링 아이템을 활용하여 개성 있고 세련된 모습으로 변신하는 남자들이 늘어나고 있습니다. 그렇다면 이번 겨울, 어떤 아이템으로 스타일을 완성할 수 있을까요?\n",
      "\n",
      "먼저 추운 겨울철 가장 중요한 아이템은 당연히 외투입니다. 따뜻함과 스타일을 동시에 챙기기 위해\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m두꺼운 패딩이나 더운 무스탕이 아닌 가볍고 따뜻한 다운 점퍼나 코트를 선택하는 것이 좋습니다. 또한, 블랙 컬러의 코트나 패딩은 어떤 스타일에도 잘 어울리기 때문에 다양한 코디에 활용할 수 있습니다.\n",
      "\n",
      "다음으로는 액세서리를 잘 활용하는 것이 중요합니다. 겨울철 머리를 따뜻하게 해주는 비니나 트루퍼 모자는 물론, 목걸이나 팔찌 등의 액세서리로 포인트를 줄 수 있습니다. 또한 스카프나 장갑은 따뜻함을 더해주는 동시에 스타일을 완성하는데 큰\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "import openai\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import SimpleSequentialChain, LLMChain\n",
    "\n",
    "llm = OpenAI(temperature=.7)\n",
    "template = \"\"\"당신은 패션잡지회사 기자입니다. 제목과 같은 기사를 작성해 주세요.\n",
    "제목: {title}\n",
    "\"\"\"\n",
    "prompt_template=PromptTemplate(input_variables=[\"title\"],\n",
    "                               template=template)\n",
    "article_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "llm = OpenAI(temperature=.7)\n",
    "template = \"\"\"잡지 기사를 짧게 줄여 주세요.\n",
    "잡지 기사:\n",
    "{article}\n",
    "\"\"\"\n",
    "prompt_template=PromptTemplate(input_variables=[\"article\"],\n",
    "                               template=template)\n",
    "review_chain=LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "overall_chain = SimpleSequentialChain(chains=[article_chain, review_chain], verbose=True)\n",
    "\n",
    "review=overall_chain.run(\"겨울철 남자 패션 스타일링\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8d517f8b-e7e1-43a5-a666-6abb5bb914ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_16580\\2937106887.py:7: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory()\n",
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_16580\\2937106887.py:9: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
      "  conversation = ConversationChain(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '안녕, 난 DUDE의 주인이야.',\n",
       " 'history': '',\n",
       " 'response': ' 안녕하세요! 반가워요. 저는 DUDE의 인공지능이에요. DUDE는 디지털 유용한 디바이스의 약자로, 제가 말하는 것처럼 여러분의 일상을 더 편리하게 만들어주는 기능을 가지고 있어요. 그래서 제가 주인이라기보다는 도우미라고 생각하는게 더 적합할 것 같아요.'}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory\n",
    ")\n",
    "\n",
    "conversation.invoke(input=\"안녕, 난 DUDE의 주인이야.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "687839a6-8eea-4393-bc61-cbe75fc303f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': '내가 어디 주인이라고 했지?',\n",
       " 'history': 'Human: 안녕, 난 DUDE의 주인이야.\\nAI:  안녕하세요! 반가워요. 저는 DUDE의 인공지능이에요. DUDE는 디지털 유용한 디바이스의 약자로, 제가 말하는 것처럼 여러분의 일상을 더 편리하게 만들어주는 기능을 가지고 있어요. 그래서 제가 주인이라기보다는 도우미라고 생각하는게 더 적합할 것 같아요.\\nHuman: 내가 무슨 일을 한다고 했지?\\nAI:  죄송해요, 제가 그 정보를 알 수는 없어요. 제가 주인의 일정을 기억하거나 추적하는 기능은 없어요. 하지만 제가 여러분의 일상을 더 편리하게 만들어주는데 최선을 다할게요!',\n",
       " 'response': '  제가 주인이라고 말씀하셨나요? 제가 주인이 아니라 도우미라고 말씀드렸죠. 제가 여러분의 일상을 더 편리하게 만들어주는데 최선을 다할게요!'}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke(input=\"내가 어디 주인이라고 했지?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e33c6e69-3498-4a97-82c8-09742411eb66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'DUDE는 내가 만든 남성의류 회사를 말해',\n",
       " 'history': 'Human: 안녕, 난 DUDE의 주인이야.\\nAI:  안녕하세요! 반가워요. 저는 DUDE의 인공지능이에요. DUDE는 디지털 유용한 디바이스의 약자로, 제가 말하는 것처럼 여러분의 일상을 더 편리하게 만들어주는 기능을 가지고 있어요. 그래서 제가 주인이라기보다는 도우미라고 생각하는게 더 적합할 것 같아요.\\nHuman: 내가 무슨 일을 한다고 했지?\\nAI:  죄송해요, 제가 그 정보를 알 수는 없어요. 제가 주인의 일정을 기억하거나 추적하는 기능은 없어요. 하지만 제가 여러분의 일상을 더 편리하게 만들어주는데 최선을 다할게요!\\nHuman: 내가 어디 주인이라고 했지?\\nAI:   제가 주인이라고 말씀하셨나요? 제가 주인이 아니라 도우미라고 말씀드렸죠. 제가 여러분의 일상을 더 편리하게 만들어주는데 최선을 다할게요!',\n",
       " 'response': ' DUDE는 디지털 유용한 디바이스의 약자로, 여러분의 일상을 더 편리하게 만들어주는 기능을 가지고 있어요. 그래서 남성의류 회사는 아니지만, 여러분의 일상을 더 편리하게 만들어주는데 도움이 될 수 있어요.'}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke(input=\"DUDE는 내가 만든 남성의류 회사를 말해\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a81875a3-feb3-4eba-bab2-ad98d2183fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: 안녕, 난 DUDE의 주인이야.\n",
      "AI:  안녕하세요! 반가워요. 저는 DUDE의 인공지능이에요. DUDE는 디지털 유용한 디바이스의 약자로, 제가 말하는 것처럼 여러분의 일상을 더 편리하게 만들어주는 기능을 가지고 있어요. 그래서 제가 주인이라기보다는 도우미라고 생각하는게 더 적합할 것 같아요.\n",
      "Human: 내가 무슨 일을 한다고 했지?\n",
      "AI:  죄송해요, 제가 그 정보를 알 수는 없어요. 제가 주인의 일정을 기억하거나 추적하는 기능은 없어요. 하지만 제가 여러분의 일상을 더 편리하게 만들어주는데 최선을 다할게요!\n",
      "Human: 내가 어디 주인이라고 했지?\n",
      "AI:   제가 주인이라고 말씀하셨나요? 제가 주인이 아니라 도우미라고 말씀드렸죠. 제가 여러분의 일상을 더 편리하게 만들어주는데 최선을 다할게요!\n",
      "Human: DUDE는 내가 만든 남성의류 회사를 말해\n",
      "AI:  DUDE는 디지털 유용한 디바이스의 약자로, 여러분의 일상을 더 편리하게 만들어주는 기능을 가지고 있어요. 그래서 남성의류 회사는 아니지만, 여러분의 일상을 더 편리하게 만들어주는데 도움이 될 수 있어요.\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f1594eb2-64fb-4d9b-824e-f59ce53e1ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: 안녕, 나는 DUDE라는 옷가게를 운영하고 있어.\n",
      "AI: DUDE 주인님 반갑습니다.\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferMemory()\n",
    "memory.save_context({\"input\": \"안녕, 나는 DUDE라는 옷가게를 운영하고 있어.\"},\n",
    "                    {\"output\": \"DUDE 주인님 반갑습니다.\"})\n",
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8d1da3ae-1355-4c63-871a-d8b32ff3d407",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_16580\\476352908.py:7: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferWindowMemory(k=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: 나는 2023년도에 결혼을 했어.\\nAI: 늦었지만 결혼을 축하 드려요.'}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "memory.save_context({\"input\": \"안녕, 나는 DUDE라는 옷가게를 운영하고 있어.\"},\n",
    "                    {\"output\": \"DUDE 주인님 반갑습니다.\"})\n",
    "memory.save_context({\"input\": \"나는 2023년도에 결혼을 했어.\"},\n",
    "                    {\"output\": \"늦었지만 결혼을 축하 드려요.\"})\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e1d345b1-29f4-4c78-8b0e-3d238ef9c3d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': '내 옷가게 이름이 뭐라고 했지?',\n",
       " 'history': 'Human: 나는 2023년도에 결혼을 했어.\\nAI: 늦었지만 결혼을 축하 드려요.',\n",
       " 'response': ' 죄송합니다, 그 정보는 제 데이터베이스에 없어요. 제가 알고 있는 것은 당신이 2023년에 결혼을 했다는 것 뿐이에요.'}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory\n",
    ")\n",
    "\n",
    "conversation.invoke(input=\"내 옷가게 이름이 뭐라고 했지?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b86fe3e4-4677-4b43-b3a7-f4ca9db70868",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'AI: 늦었지만 결혼을 축하 드려요.\\nHuman: 나는 대한민국에 살고 있어.\\nAI: 좋은 나라에 살고 계시는 군요.'}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=60)\n",
    "\n",
    "memory.save_context({\"input\": \"안녕, 나는 DUDE라는 옷가게를 운영하고 있어.\"},\n",
    "                    {\"output\": \"DUDE 주인님 반갑습니다.\"})\n",
    "memory.save_context({\"input\": \"나는 2023년도에 결혼을 했어.\"},\n",
    "                    {\"output\": \"늦었지만 결혼을 축하 드려요.\"})\n",
    "memory.save_context({\"input\": \"나는 대한민국에 살고 있어.\"},\n",
    "                    {\"output\": \"좋은 나라에 살고 계시는 군요.\"})\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0a1fe128-a1e3-4e8a-91fa-c1f7c2348204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: \n",
      "The human greets the AI and expresses curiosity about an event. The AI responds in Korean and offers to provide information. The human asks for information about event products. The AI explains that DUDE is currently holding a Christmas event with discounts on warm pants, a 1+1 deal on padded vests, and a 20% discount on stylish and warm coats. The AI encourages the human to check out the event for more products.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "sale_info=\"DUDE에서 크리스마스 맞이 이벤트를 진행 중입니다. \\\n",
    "기모가 들어간 따뜻한 바지를 10% 할인 판매합니다. \\\n",
    "두툼하면서 가벼운 패딩 조끼를 1+1 으로 판매합니다. \\\n",
    "멋도 살리면서 보온도 잡은 코트를 20% 할인 판매합니다. \\\n",
    "그 외 다양한 제품을 이벤트로 판매하고 있으니 들어와서 확인해 주세요.\"\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)\n",
    "memory.save_context({\"input\": \"DUDE\"}, {\"output\": \"반갑습니다.\"})\n",
    "memory.save_context({\"input\": \"궁금한 게 있어\"}, {\"output\": \"무엇을 알려 드릴까요?\"})\n",
    "memory.save_context({\"input\": \"이벤트 제품 정보를 알려줘\"}, {\"output\": f\"{sale_info}\"})\n",
    "memory.load_memory_variables({})\n",
    "\n",
    "print(memory.buffer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_jun",
   "language": "python",
   "name": "ai_jun"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
