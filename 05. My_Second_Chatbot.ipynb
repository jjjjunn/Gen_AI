{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c371037-d800-481e-b467-46fdaf544cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "with gr.Blocks() as app:\n",
    "    with gr.Tab(\"ìŒì„± ì¸ì‹ë´‡\"):\n",
    "        with gr.Column():\n",
    "            #1\n",
    "            gr.Markdown()\n",
    "            #2\n",
    "            gr.Chatbot()\n",
    "        with gr.Row():\n",
    "            #3\n",
    "            gr.Textbox()\n",
    "            #4\n",
    "            gr.Audio()\n",
    "            #5\n",
    "            gr.Button()\n",
    "        with gr.Row():\n",
    "            #6\n",
    "            gr.Button()\n",
    "            #7\n",
    "            gr.Button()\n",
    "app.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6355832-e4d0-42c3-a3ad-c943f35fad7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:    Exception in ASGI application\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\niceq\\anaconda3\\envs\\ai_jun\\lib\\site-packages\\uvicorn\\protocols\\http\\httptools_impl.py\", line 409, in run_asgi\n",
      "    result = await app(  # type: ignore[func-returns-value]\n",
      "  File \"C:\\Users\\niceq\\anaconda3\\envs\\ai_jun\\lib\\site-packages\\uvicorn\\middleware\\proxy_headers.py\", line 60, in __call__\n",
      "    return await self.app(scope, receive, send)\n",
      "  File \"C:\\Users\\niceq\\anaconda3\\envs\\ai_jun\\lib\\site-packages\\fastapi\\applications.py\", line 1054, in __call__\n",
      "    await super().__call__(scope, receive, send)\n",
      "  File \"C:\\Users\\niceq\\anaconda3\\envs\\ai_jun\\lib\\site-packages\\starlette\\applications.py\", line 113, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"C:\\Users\\niceq\\anaconda3\\envs\\ai_jun\\lib\\site-packages\\starlette\\middleware\\errors.py\", line 187, in __call__\n",
      "    raise exc\n",
      "  File \"C:\\Users\\niceq\\anaconda3\\envs\\ai_jun\\lib\\site-packages\\starlette\\middleware\\errors.py\", line 165, in __call__\n",
      "    await self.app(scope, receive, _send)\n",
      "  File \"C:\\Users\\niceq\\anaconda3\\envs\\ai_jun\\lib\\site-packages\\gradio\\route_utils.py\", line 761, in __call__\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"C:\\Users\\niceq\\anaconda3\\envs\\ai_jun\\lib\\site-packages\\starlette\\middleware\\exceptions.py\", line 62, in __call__\n",
      "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
      "  File \"C:\\Users\\niceq\\anaconda3\\envs\\ai_jun\\lib\\site-packages\\starlette\\_exception_handler.py\", line 53, in wrapped_app\n",
      "    raise exc\n",
      "  File \"C:\\Users\\niceq\\anaconda3\\envs\\ai_jun\\lib\\site-packages\\starlette\\_exception_handler.py\", line 42, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"C:\\Users\\niceq\\anaconda3\\envs\\ai_jun\\lib\\site-packages\\starlette\\routing.py\", line 715, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"C:\\Users\\niceq\\anaconda3\\envs\\ai_jun\\lib\\site-packages\\starlette\\routing.py\", line 735, in app\n",
      "    await route.handle(scope, receive, send)\n",
      "  File \"C:\\Users\\niceq\\anaconda3\\envs\\ai_jun\\lib\\site-packages\\starlette\\routing.py\", line 288, in handle\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"C:\\Users\\niceq\\anaconda3\\envs\\ai_jun\\lib\\site-packages\\starlette\\routing.py\", line 76, in app\n",
      "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
      "  File \"C:\\Users\\niceq\\anaconda3\\envs\\ai_jun\\lib\\site-packages\\starlette\\_exception_handler.py\", line 53, in wrapped_app\n",
      "    raise exc\n",
      "  File \"C:\\Users\\niceq\\anaconda3\\envs\\ai_jun\\lib\\site-packages\\starlette\\_exception_handler.py\", line 42, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"C:\\Users\\niceq\\anaconda3\\envs\\ai_jun\\lib\\site-packages\\starlette\\routing.py\", line 74, in app\n",
      "    await response(scope, receive, send)\n",
      "  File \"C:\\Users\\niceq\\anaconda3\\envs\\ai_jun\\lib\\site-packages\\starlette\\responses.py\", line 348, in __call__\n",
      "    await self._handle_simple(send, send_header_only)\n",
      "  File \"C:\\Users\\niceq\\anaconda3\\envs\\ai_jun\\lib\\site-packages\\starlette\\responses.py\", line 377, in _handle_simple\n",
      "    await send({\"type\": \"http.response.body\", \"body\": chunk, \"more_body\": more_body})\n",
      "  File \"C:\\Users\\niceq\\anaconda3\\envs\\ai_jun\\lib\\site-packages\\starlette\\_exception_handler.py\", line 39, in sender\n",
      "    await send(message)\n",
      "  File \"C:\\Users\\niceq\\anaconda3\\envs\\ai_jun\\lib\\site-packages\\starlette\\_exception_handler.py\", line 39, in sender\n",
      "    await send(message)\n",
      "  File \"C:\\Users\\niceq\\anaconda3\\envs\\ai_jun\\lib\\site-packages\\starlette\\middleware\\errors.py\", line 162, in _send\n",
      "    await send(message)\n",
      "  File \"C:\\Users\\niceq\\anaconda3\\envs\\ai_jun\\lib\\site-packages\\uvicorn\\protocols\\http\\httptools_impl.py\", line 544, in send\n",
      "    raise RuntimeError(\"Response content shorter than Content-Length\")\n",
      "RuntimeError: Response content shorter than Content-Length\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "with gr.Blocks() as app:\n",
    "    with gr.Tab(\"ìŒì„± ì¸ì‹ë´‡\"):\n",
    "        with gr.Column():\n",
    "            #1\n",
    "            gr.Markdown(\n",
    "                value=\"\"\"\n",
    "                # <center>ìŒì„± ì¸ì‹ë´‡</center>\n",
    "                <center>AI ì¸ê³µì§€ëŠ¥ ë¹„ì„œ DUDE ì…ë‹ˆë‹¤.\n",
    "                ìŒì„±ìœ¼ë¡œ ë¬»ê±°ë‚˜, ë¬¸ì„œ ìš”ì•½, ì¼ì • ê´€ë¦¬ë¥¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</center>\n",
    "                \"\"\"\n",
    "            )\n",
    "            #2\n",
    "            gr.Chatbot(\n",
    "                value=[[None, \"ì•ˆë…•í•˜ì„¸ìš”, ì¸ê³µì§€ëŠ¥ ë¹„ì„œ DUDE ì…ë‹ˆë‹¤. ë¬´ì—‡ì´ë“  ì‹œì¼œë§Œ ì£¼ì„¸ìš”.\"]],\n",
    "                show_label=False\n",
    "            )\n",
    "        with gr.Row():\n",
    "            #3\n",
    "            gr.Textbox(\n",
    "                lines=1,\n",
    "                placeholder=\"ì…ë ¥ ì°½\",\n",
    "                container=False,\n",
    "                scale=7\n",
    "            )\n",
    "            #4\n",
    "            gr.Audio(\n",
    "                sources=[\"microphone\"],\n",
    "                format=\"mp3\",\n",
    "                scale=1,\n",
    "                min_width=200,\n",
    "                label=\"ìŒì„±ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.\"\n",
    "            )\n",
    "            #5\n",
    "            gr.Button(\n",
    "                value=\"ë³´ë‚´ê¸°\",\n",
    "                scale=1,\n",
    "                visible=\"primary\",\n",
    "                icon=\"https://cdn-icons-png.flaticon.com/128/12439/12439334.png\"\n",
    "            )\n",
    "        with gr.Row():\n",
    "            #6\n",
    "            gr.Button(value=\"â†ªï¸ë˜ëŒë¦¬ê¸°\"\n",
    "            )\n",
    "            #7\n",
    "            gr.Button(value=\"ğŸ”„ï¸ì´ˆê¸°í™”\")\n",
    "app.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e0a7f8c-7c97-4a69-8a67-c5096daab32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "with gr.Blocks() as app:\n",
    "    with gr.Tab(\"ìŒì„± ì¸ì‹ë´‡\"):\n",
    "        with gr.Column():\n",
    "            #1\n",
    "            gr.Markdown(\n",
    "                value=\"\"\"\n",
    "                # <center>ìŒì„± ì¸ì‹ë´‡</center>\n",
    "                <center>AI ì¸ê³µì§€ëŠ¥ ë¹„ì„œ DUDE ì…ë‹ˆë‹¤.\n",
    "                ìŒì„±ìœ¼ë¡œ ë¬»ê±°ë‚˜, ë¬¸ì„œ ìš”ì•½, ì¼ì • ê´€ë¦¬ë¥¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</center>\n",
    "                \"\"\"\n",
    "            )\n",
    "            #2\n",
    "            cb_chatbot=gr.Chatbot(\n",
    "                value=[[None, \"ì•ˆë…•í•˜ì„¸ìš”, ì¸ê³µì§€ëŠ¥ ë¹„ì„œ DUDE ì…ë‹ˆë‹¤. ë¬´ì—‡ì´ë“  ì‹œì¼œë§Œ ì£¼ì„¸ìš”.\"]],\n",
    "                show_label=False\n",
    "            )\n",
    "        with gr.Row():\n",
    "            #3\n",
    "            cb_user_input=gr.Textbox(\n",
    "                lines=1,\n",
    "                placeholder=\"ì…ë ¥ ì°½\",\n",
    "                container=False,\n",
    "                scale=7\n",
    "            )\n",
    "            #4\n",
    "            cb_audio_record=gr.Audio(\n",
    "                sources=[\"microphone\"],\n",
    "                format=\"mp3\",\n",
    "                scale=1,\n",
    "                min_width=200,\n",
    "                label=\"ìŒì„±ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.\"\n",
    "            )\n",
    "            # ìŒì„± ì¶œë ¥\n",
    "            cb_audio_chatbot=gr.Audio(autoplay=True,\n",
    "                                      visible=False)\n",
    "            #5\n",
    "            cb_submit_btn=gr.Button(\n",
    "                value=\"ë³´ë‚´ê¸°\",\n",
    "                scale=1,\n",
    "                visible=\"primary\",\n",
    "                icon=\"https://cdn-icons-png.flaticon.com/128/12439/12439334.png\"\n",
    "            )\n",
    "        with gr.Row():\n",
    "            #6\n",
    "            gr.Button(value=\"â†ªï¸ë˜ëŒë¦¬ê¸°\"\n",
    "            )\n",
    "            #7\n",
    "            gr.Button(value=\"ğŸ”„ï¸ì´ˆê¸°í™”\")\n",
    "app.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf6f1981-e9ea-434c-a87e-fe71c268ea0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.prompts import(\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.chains import LLMChain\n",
    "import os\n",
    "import openai\n",
    "\n",
    "# í™˜ê²½ë³€ìˆ˜ì—ì„œ OpenAI API í‚¤ë¥¼ ì½ì–´ì˜´.\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# API í‚¤ê°€ í™˜ê²½ë³€ìˆ˜ì— ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸.\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"í™˜ê²½ë³€ìˆ˜ 'OPENAI_API_KEY'ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# OpenAI API í‚¤ë¥¼ ì„¤ì •.\n",
    "openai.api_key = openai_api_key\n",
    "\n",
    "# OpenAI í´ë¼ì´ì–¸íŠ¸ë¥¼ ìƒì„±.\n",
    "client = openai.OpenAI()\n",
    "\n",
    "system_ai_ko = \"ë‹¹ì‹ ì€ ì¸ê³µì§€ëŠ¥ ë¹„ì„œì•¼, pdf ì¼ê¸°, ë¬¸ì„œ ìš”ì•½í•˜ê¸°, ì¼ì • ê´€ë¦¬, ë‚ ì”¨, ìµœë‹¨ ê²½ë¡œ ê²€ìƒ‰, ì›¹ ê²€ìƒ‰ ë“± ë‹¤ì–‘í•œ ë‚´ìš©ì— ë‹µë³€í•  ìˆ˜ ìˆì–´ì•¼ í•´.\"\n",
    "system_setting = SystemMessagePromptTemplate.from_template(system_ai_ko)\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ ì„¤ì •\n",
    "voice_bot_prompt = ChatPromptTemplate.from_messages([\n",
    "    system_setting,\n",
    "    MessagesPlaceholder(variable_name=\"DUDE\"),\n",
    "    HumanMessagePromptTemplate.from_template(\"{master_user}\")])\n",
    "\n",
    "\n",
    "import gradio as gr\n",
    "with gr.Blocks() as app:\n",
    "    with gr.Tab(\"ìŒì„± ì¸ì‹ë´‡\"):\n",
    "        with gr.Column():\n",
    "            #1\n",
    "            gr.Markdown(\n",
    "                value=\"\"\"\n",
    "                # <center>ìŒì„± ì¸ì‹ë´‡</center>\n",
    "                <center>AI ì¸ê³µì§€ëŠ¥ ë¹„ì„œ DUDE ì…ë‹ˆë‹¤.\n",
    "                ìŒì„±ìœ¼ë¡œ ë¬»ê±°ë‚˜, ë¬¸ì„œ ìš”ì•½, ì¼ì • ê´€ë¦¬ë¥¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</center>\n",
    "                \"\"\"\n",
    "            )\n",
    "            #2\n",
    "            cb_chatbot=gr.Chatbot(\n",
    "                value=[[None, \"ì•ˆë…•í•˜ì„¸ìš”, ì¸ê³µì§€ëŠ¥ ë¹„ì„œ DUDE ì…ë‹ˆë‹¤. ë¬´ì—‡ì´ë“  ì‹œì¼œë§Œ ì£¼ì„¸ìš”.\"]],\n",
    "                show_label=False\n",
    "            )\n",
    "        with gr.Row():\n",
    "            #3\n",
    "            cb_user_input=gr.Textbox(\n",
    "                lines=1,\n",
    "                placeholder=\"ì…ë ¥ ì°½\",\n",
    "                container=False,\n",
    "                scale=7\n",
    "            )\n",
    "            #4\n",
    "            cb_audio_record=gr.Audio(\n",
    "                sources=[\"microphone\"],\n",
    "                format=\"mp3\",\n",
    "                scale=1,\n",
    "                min_width=200,\n",
    "                label=\"ìŒì„±ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.\"\n",
    "            )\n",
    "            # ìŒì„± ì¶œë ¥\n",
    "            cb_audio_chatbot=gr.Audio(autoplay=True,\n",
    "                                      visible=False)\n",
    "            #5\n",
    "            cb_submit_btn=gr.Button(\n",
    "                value=\"ë³´ë‚´ê¸°\",\n",
    "                scale=1,\n",
    "                visible=\"primary\",\n",
    "                icon=\"https://cdn-icons-png.flaticon.com/128/12439/12439334.png\"\n",
    "            )\n",
    "        with gr.Row():\n",
    "            #6\n",
    "            gr.Button(value=\"â†ªï¸ë˜ëŒë¦¬ê¸°\"\n",
    "            )\n",
    "            #7\n",
    "            gr.Button(value=\"ğŸ”„ï¸ì´ˆê¸°í™”\")\n",
    "app.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "230cf074-52c5-436f-a1bb-e7ecdb880833",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_18184\\798194593.py:50: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  conversation=LLMChain(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7864\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.prompts import(\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.chains import LLMChain\n",
    "import os\n",
    "import openai\n",
    "\n",
    "# í™˜ê²½ë³€ìˆ˜ì—ì„œ OpenAI API í‚¤ë¥¼ ì½ì–´ì˜´.\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# API í‚¤ê°€ í™˜ê²½ë³€ìˆ˜ì— ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸.\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"í™˜ê²½ë³€ìˆ˜ 'OPENAI_API_KEY'ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# OpenAI API í‚¤ë¥¼ ì„¤ì •.\n",
    "openai.api_key = openai_api_key\n",
    "\n",
    "# OpenAI í´ë¼ì´ì–¸íŠ¸ë¥¼ ìƒì„±.\n",
    "client = openai.OpenAI()\n",
    "\n",
    "system_ai_ko = \"ë‹¹ì‹ ì€ ì¸ê³µì§€ëŠ¥ ë¹„ì„œì•¼, pdf ì¼ê¸°, ë¬¸ì„œ ìš”ì•½í•˜ê¸°, ì¼ì • ê´€ë¦¬, ë‚ ì”¨, ìµœë‹¨ ê²½ë¡œ ê²€ìƒ‰, ì›¹ ê²€ìƒ‰ ë“± ë‹¤ì–‘í•œ ë‚´ìš©ì— ë‹µë³€í•  ìˆ˜ ìˆì–´ì•¼ í•´.\"\n",
    "system_setting = SystemMessagePromptTemplate.from_template(system_ai_ko)\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ ì„¤ì •\n",
    "voice_bot_prompt = ChatPromptTemplate.from_messages([\n",
    "    system_setting,\n",
    "    MessagesPlaceholder(variable_name=\"DUDE\"),\n",
    "    HumanMessagePromptTemplate.from_template(\"{master_user}\")])\n",
    "\n",
    "# ë©”ëª¨ë¦¬ ì„¤ì •\n",
    "voice_bot_memory = ConversationBufferWindowMemory(memory_key=\"DUDE\",\n",
    "                                                  ai_prefix=\"AI ë¹„ì„œ DUDE\",\n",
    "                                                  human_prefix=\"ì‚¬ìš©ì:\",\n",
    "                                                  return_messages=True,\n",
    "                                                  k=10)\n",
    "\n",
    "# llm ëª¨ë¸ ì„¤ì •\n",
    "chatgpt = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    max_tokens=2048,\n",
    "    model_name='gpt-3.5-turbo'\n",
    ")\n",
    "\n",
    "# llmchain ì •ì˜\n",
    "conversation=LLMChain(\n",
    "    prompt=voice_bot_prompt,\n",
    "    memory=voice_bot_memory,\n",
    "    llm=chatgpt,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "import gradio as gr\n",
    "with gr.Blocks() as app:\n",
    "    with gr.Tab(\"ìŒì„± ì¸ì‹ë´‡\"):\n",
    "        with gr.Column():\n",
    "            #1\n",
    "            gr.Markdown(\n",
    "                value=\"\"\"\n",
    "                # <center>ìŒì„± ì¸ì‹ë´‡</center>\n",
    "                <center>AI ì¸ê³µì§€ëŠ¥ ë¹„ì„œ DUDE ì…ë‹ˆë‹¤.\n",
    "                ìŒì„±ìœ¼ë¡œ ë¬»ê±°ë‚˜, ë¬¸ì„œ ìš”ì•½, ì¼ì • ê´€ë¦¬ë¥¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</center>\n",
    "                \"\"\"\n",
    "            )\n",
    "            #2\n",
    "            cb_chatbot=gr.Chatbot(\n",
    "                value=[[None, \"ì•ˆë…•í•˜ì„¸ìš”, ì¸ê³µì§€ëŠ¥ ë¹„ì„œ DUDE ì…ë‹ˆë‹¤. ë¬´ì—‡ì´ë“  ì‹œì¼œë§Œ ì£¼ì„¸ìš”.\"]],\n",
    "                show_label=False\n",
    "            )\n",
    "        with gr.Row():\n",
    "            #3\n",
    "            cb_user_input=gr.Textbox(\n",
    "                lines=1,\n",
    "                placeholder=\"ì…ë ¥ ì°½\",\n",
    "                container=False,\n",
    "                scale=7\n",
    "            )\n",
    "            #4\n",
    "            cb_audio_record=gr.Audio(\n",
    "                sources=[\"microphone\"],\n",
    "                format=\"mp3\",\n",
    "                scale=1,\n",
    "                min_width=200,\n",
    "                label=\"ìŒì„±ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.\"\n",
    "            )\n",
    "            # ìŒì„± ì¶œë ¥\n",
    "            cb_audio_chatbot=gr.Audio(autoplay=True,\n",
    "                                      visible=False)\n",
    "            #5\n",
    "            cb_submit_btn=gr.Button(\n",
    "                value=\"ë³´ë‚´ê¸°\",\n",
    "                scale=1,\n",
    "                visible=\"primary\",\n",
    "                icon=\"https://cdn-icons-png.flaticon.com/128/12439/12439334.png\"\n",
    "            )\n",
    "        with gr.Row():\n",
    "            #6\n",
    "            gr.Button(value=\"â†ªï¸ë˜ëŒë¦¬ê¸°\"\n",
    "            )\n",
    "            #7\n",
    "            gr.Button(value=\"ğŸ”„ï¸ì´ˆê¸°í™”\")\n",
    "app.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2614316-9e8c-42ab-846a-0ba3b934c678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7865\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.prompts import(\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.chains import LLMChain\n",
    "import os\n",
    "import openai\n",
    "\n",
    "# í™˜ê²½ë³€ìˆ˜ì—ì„œ OpenAI API í‚¤ë¥¼ ì½ì–´ì˜´.\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# API í‚¤ê°€ í™˜ê²½ë³€ìˆ˜ì— ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸.\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"í™˜ê²½ë³€ìˆ˜ 'OPENAI_API_KEY'ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# OpenAI API í‚¤ë¥¼ ì„¤ì •.\n",
    "openai.api_key = openai_api_key\n",
    "\n",
    "# OpenAI í´ë¼ì´ì–¸íŠ¸ë¥¼ ìƒì„±.\n",
    "client = openai.OpenAI()\n",
    "\n",
    "system_ai_ko = \"ë‹¹ì‹ ì€ ì¸ê³µì§€ëŠ¥ ë¹„ì„œì•¼, pdf ì¼ê¸°, ë¬¸ì„œ ìš”ì•½í•˜ê¸°, ì¼ì • ê´€ë¦¬, ë‚ ì”¨, ìµœë‹¨ ê²½ë¡œ ê²€ìƒ‰, ì›¹ ê²€ìƒ‰ ë“± ë‹¤ì–‘í•œ ë‚´ìš©ì— ë‹µë³€í•  ìˆ˜ ìˆì–´ì•¼ í•´.\"\n",
    "system_setting = SystemMessagePromptTemplate.from_template(system_ai_ko)\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ ì„¤ì •\n",
    "voice_bot_prompt = ChatPromptTemplate.from_messages([\n",
    "    system_setting,\n",
    "    MessagesPlaceholder(variable_name=\"DUDE\"),\n",
    "    HumanMessagePromptTemplate.from_template(\"{master_user}\")])\n",
    "\n",
    "# ë©”ëª¨ë¦¬ ì„¤ì •\n",
    "voice_bot_memory = ConversationBufferWindowMemory(memory_key=\"DUDE\",\n",
    "                                                  ai_prefix=\"AI ë¹„ì„œ DUDE\",\n",
    "                                                  human_prefix=\"ì‚¬ìš©ì:\",\n",
    "                                                  return_messages=True,\n",
    "                                                  k=10)\n",
    "\n",
    "# llm ëª¨ë¸ ì„¤ì •\n",
    "chatgpt = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    max_tokens=2048,\n",
    "    model_name='gpt-3.5-turbo'\n",
    ")\n",
    "\n",
    "# llmchain ì •ì˜\n",
    "conversation=LLMChain(\n",
    "    prompt=voice_bot_prompt,\n",
    "    memory=voice_bot_memory,\n",
    "    llm=chatgpt,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "from pydub import AudioSegment\n",
    "import numpy as np\n",
    "def voice_bot_handle_audio(audio_record):\n",
    "    save_file_path=\"voice.mp3\"\n",
    "    frame_rate=audio_record[0]\n",
    "    audio_data=audio_record[1].tobytes()\n",
    "    sample_width=audio_record[1].dtype.itemsize\n",
    "    audio=AudioSegment(\n",
    "        audio_data,\n",
    "        frame_rate=frame_rate,\n",
    "        sample_width=sample_width,\n",
    "        channels=1,\n",
    "    )\n",
    "    audio.export(save_file_path, format=\"mp3\")\n",
    "\n",
    "def voice_bot_create_stt():\n",
    "    file_path=\"voice.mp3\"\n",
    "    audio_file=open(file_path, \"rb\")\n",
    "    transcript=client.audio.transcriptions.create(\n",
    "        model=\"whisper-1\",\n",
    "        file=audio_file)\n",
    "    return transcript.text\n",
    "\n",
    "def voice_bot_create_audio(text):\n",
    "    response=client.audio.speech.create(\n",
    "        model=\"tts-1\",\n",
    "        voice=\"onyx\",\n",
    "        input=text)\n",
    "    speech_file_path=\"output.mp3\"\n",
    "    with open(speech_file_path, \"wb\") as audio_file:\n",
    "        audio_file.write(response.content)\n",
    "\n",
    "def voice_bot_chat(message, cb_user_input_audio, chat_history):\n",
    "    if cb_user_input_audio:\n",
    "        message=voice_bot_create_stt()\n",
    "    ai_answer=conversation({\"master_user\":message})['text']\n",
    "    chat_history.append((message, ai_answer))\n",
    "    audio_file=voice_bot_create_audio(ai_answer)\n",
    "    return \"\", audio_file, chat_history\n",
    "\n",
    "def voice_bot_undo(chat_history):\n",
    "    if len(chat_history) > 1:\n",
    "        chat_history.pop()\n",
    "    return chat_history\n",
    "\n",
    "def voice_bot_reset(chat_history):\n",
    "    global voice_bot_memory\n",
    "    chat_init=[[None, \"ì•ˆë…•í•˜ì„¸ìš”, ì¸ê³µì§€ëŠ¥ ë¹„ì„œ DUDE ì…ë‹ˆë‹¤. ë¬´ì—‡ì´ë“  ì‹œì¼œë§Œ ì£¼ì„¸ìš”.\"]]\n",
    "    voice_bot_memory.clear() # ë©”ëª¨ë¦¬ ì´ˆê¸°í™”\n",
    "    return \"\", chat_init\n",
    "\n",
    "import gradio as gr\n",
    "with gr.Blocks() as app:\n",
    "    with gr.Tab(\"ìŒì„± ì¸ì‹ë´‡\"):\n",
    "        with gr.Column():\n",
    "            #1\n",
    "            gr.Markdown(\n",
    "                value=\"\"\"\n",
    "                # <center>ìŒì„± ì¸ì‹ë´‡</center>\n",
    "                <center>AI ì¸ê³µì§€ëŠ¥ ë¹„ì„œ DUDE ì…ë‹ˆë‹¤.\n",
    "                ìŒì„±ìœ¼ë¡œ ë¬»ê±°ë‚˜, ë¬¸ì„œ ìš”ì•½, ì¼ì • ê´€ë¦¬ë¥¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</center>\n",
    "                \"\"\"\n",
    "            )\n",
    "            #2\n",
    "            cb_chatbot=gr.Chatbot(\n",
    "                value=[[None, \"ì•ˆë…•í•˜ì„¸ìš”, ì¸ê³µì§€ëŠ¥ ë¹„ì„œ DUDE ì…ë‹ˆë‹¤. ë¬´ì—‡ì´ë“  ì‹œì¼œë§Œ ì£¼ì„¸ìš”.\"]],\n",
    "                show_label=False\n",
    "            )\n",
    "        with gr.Row():\n",
    "            #3\n",
    "            cb_user_input=gr.Textbox(\n",
    "                lines=1,\n",
    "                placeholder=\"ì…ë ¥ ì°½\",\n",
    "                container=False,\n",
    "                scale=7\n",
    "            )\n",
    "            #4\n",
    "            cb_audio_record=gr.Audio(\n",
    "                sources=[\"microphone\"],\n",
    "                format=\"mp3\",\n",
    "                scale=1,\n",
    "                min_width=200,\n",
    "                label=\"ìŒì„±ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.\"\n",
    "            )\n",
    "            # ìŒì„± ì¶œë ¥\n",
    "            cb_audio_chatbot=gr.Audio(autoplay=True,\n",
    "                                      visible=False)\n",
    "            #5\n",
    "            cb_submit_btn=gr.Button(\n",
    "                value=\"ë³´ë‚´ê¸°\",\n",
    "                scale=1,\n",
    "                visible=\"primary\",\n",
    "                icon=\"https://cdn-icons-png.flaticon.com/128/12439/12439334.png\"\n",
    "            )\n",
    "        with gr.Row():\n",
    "            #6\n",
    "            gr.Button(value=\"â†ªï¸ë˜ëŒë¦¬ê¸°\"\n",
    "            )\n",
    "            #7\n",
    "            gr.Button(value=\"ğŸ”„ï¸ì´ˆê¸°í™”\")\n",
    "app.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9b66585-f7c7-4bc9-94ee-b41f692e1c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7867\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7867/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.prompts import(\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.chains import LLMChain\n",
    "import os\n",
    "import openai\n",
    "\n",
    "# í™˜ê²½ë³€ìˆ˜ì—ì„œ OpenAI API í‚¤ë¥¼ ì½ì–´ì˜´.\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# API í‚¤ê°€ í™˜ê²½ë³€ìˆ˜ì— ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸.\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"í™˜ê²½ë³€ìˆ˜ 'OPENAI_API_KEY'ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# OpenAI API í‚¤ë¥¼ ì„¤ì •.\n",
    "openai.api_key = openai_api_key\n",
    "\n",
    "# OpenAI í´ë¼ì´ì–¸íŠ¸ë¥¼ ìƒì„±.\n",
    "client = openai.OpenAI()\n",
    "\n",
    "system_ai_ko = \"ë‹¹ì‹ ì€ ì¸ê³µì§€ëŠ¥ ë¹„ì„œì•¼, pdf ì¼ê¸°, ë¬¸ì„œ ìš”ì•½í•˜ê¸°, ì¼ì • ê´€ë¦¬, ë‚ ì”¨, ìµœë‹¨ ê²½ë¡œ ê²€ìƒ‰, ì›¹ ê²€ìƒ‰ ë“± ë‹¤ì–‘í•œ ë‚´ìš©ì— ë‹µë³€í•  ìˆ˜ ìˆì–´ì•¼ í•´.\"\n",
    "system_setting = SystemMessagePromptTemplate.from_template(system_ai_ko)\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ ì„¤ì •\n",
    "voice_bot_prompt = ChatPromptTemplate.from_messages([\n",
    "    system_setting,\n",
    "    MessagesPlaceholder(variable_name=\"DUDE\"),\n",
    "    HumanMessagePromptTemplate.from_template(\"{master_user}\")])\n",
    "\n",
    "# ë©”ëª¨ë¦¬ ì„¤ì •\n",
    "voice_bot_memory = ConversationBufferWindowMemory(memory_key=\"DUDE\",\n",
    "                                                  ai_prefix=\"AI ë¹„ì„œ DUDE\",\n",
    "                                                  human_prefix=\"ì‚¬ìš©ì:\",\n",
    "                                                  return_messages=True,\n",
    "                                                  k=10)\n",
    "\n",
    "# llm ëª¨ë¸ ì„¤ì •\n",
    "chatgpt = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    max_tokens=2048,\n",
    "    model_name='gpt-3.5-turbo'\n",
    ")\n",
    "\n",
    "# llmchain ì •ì˜\n",
    "conversation=LLMChain(\n",
    "    prompt=voice_bot_prompt,\n",
    "    memory=voice_bot_memory,\n",
    "    llm=chatgpt,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "from pydub import AudioSegment\n",
    "import numpy as np\n",
    "def voice_bot_handle_audio(audio_record):\n",
    "    save_file_path=\"voice.mp3\"\n",
    "    frame_rate=audio_record[0]\n",
    "    audio_data=audio_record[1].tobytes()\n",
    "    sample_width=audio_record[1].dtype.itemsize\n",
    "    audio=AudioSegment(\n",
    "        audio_data,\n",
    "        frame_rate=frame_rate,\n",
    "        sample_width=sample_width,\n",
    "        channels=1,\n",
    "    )\n",
    "    audio.export(save_file_path, format=\"mp3\")\n",
    "\n",
    "def voice_bot_create_stt():\n",
    "    file_path=\"voice.mp3\"\n",
    "    audio_file=open(file_path, \"rb\")\n",
    "    transcript=client.audio.transcriptions.create(\n",
    "        model=\"whisper-1\",\n",
    "        file=audio_file)\n",
    "    return transcript.text\n",
    "\n",
    "def voice_bot_create_audio(text):\n",
    "    response=client.audio.speech.create(\n",
    "        model=\"tts-1\",\n",
    "        voice=\"onyx\",\n",
    "        input=text)\n",
    "    speech_file_path=\"output.mp3\"\n",
    "    with open(speech_file_path, \"wb\") as audio_file:\n",
    "        audio_file.write(response.content)\n",
    "\n",
    "def voice_bot_chat(message, cb_user_input_audio, chat_history):\n",
    "    if cb_user_input_audio:\n",
    "        message=voice_bot_create_stt()\n",
    "    ai_answer=conversation({\"master_user\":message})['text']\n",
    "    chat_history.append((message, ai_answer))\n",
    "    audio_file=voice_bot_create_audio(ai_answer)\n",
    "    return \"\", audio_file, chat_history\n",
    "\n",
    "def voice_bot_undo(chat_history):\n",
    "    if len(chat_history) > 1:\n",
    "        chat_history.pop()\n",
    "    return chat_history\n",
    "\n",
    "def voice_bot_reset(chat_history):\n",
    "    global voice_bot_memory\n",
    "    chat_init=[[None, \"ì•ˆë…•í•˜ì„¸ìš”, ì¸ê³µì§€ëŠ¥ ë¹„ì„œ DUDE ì…ë‹ˆë‹¤. ë¬´ì—‡ì´ë“  ì‹œì¼œë§Œ ì£¼ì„¸ìš”.\"]]\n",
    "    voice_bot_memory.clear() # ë©”ëª¨ë¦¬ ì´ˆê¸°í™”\n",
    "    return \"\", chat_init\n",
    "\n",
    "import gradio as gr\n",
    "with gr.Blocks() as app:\n",
    "    with gr.Tab(\"ìŒì„± ì¸ì‹ë´‡\"):\n",
    "        with gr.Column():\n",
    "            #1\n",
    "            gr.Markdown(\n",
    "                value=\"\"\"\n",
    "                # <center>ìŒì„± ì¸ì‹ë´‡</center>\n",
    "                <center>AI ì¸ê³µì§€ëŠ¥ ë¹„ì„œ DUDE ì…ë‹ˆë‹¤.\n",
    "                ìŒì„±ìœ¼ë¡œ ë¬»ê±°ë‚˜, ë¬¸ì„œ ìš”ì•½, ì¼ì • ê´€ë¦¬ë¥¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</center>\n",
    "                \"\"\"\n",
    "            )\n",
    "            #2\n",
    "            cb_chatbot=gr.Chatbot(\n",
    "                value=[[None, \"ì•ˆë…•í•˜ì„¸ìš”, ì¸ê³µì§€ëŠ¥ ë¹„ì„œ DUDE ì…ë‹ˆë‹¤. ë¬´ì—‡ì´ë“  ì‹œì¼œë§Œ ì£¼ì„¸ìš”.\"]],\n",
    "                show_label=False\n",
    "            )\n",
    "        with gr.Row():\n",
    "            #3\n",
    "            cb_user_input=gr.Textbox(\n",
    "                lines=1,\n",
    "                placeholder=\"ì…ë ¥ ì°½\",\n",
    "                container=False,\n",
    "                scale=7\n",
    "            )\n",
    "            #4\n",
    "            cb_audio_record=gr.Audio(\n",
    "                sources=[\"microphone\"],\n",
    "                format=\"mp3\",\n",
    "                scale=1,\n",
    "                min_width=200,\n",
    "                label=\"ìŒì„±ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.\"\n",
    "            )\n",
    "            # ìŒì„± ì¶œë ¥\n",
    "            cb_audio_chatbot=gr.Audio(autoplay=True,\n",
    "                                      visible=False)\n",
    "            #5\n",
    "            cb_submit_btn=gr.Button(\n",
    "                value=\"ë³´ë‚´ê¸°\",\n",
    "                scale=1,\n",
    "                visible=\"primary\",\n",
    "                icon=\"https://cdn-icons-png.flaticon.com/128/12439/12439334.png\"\n",
    "            )\n",
    "    # ìŒì„± ë…¹ìŒ ì™„ë£Œ\n",
    "        cb_audio_record.stop_recording(\n",
    "            fn=voice_bot_handle_audio,\n",
    "            inputs=[cb_audio_record]\n",
    "        )\n",
    "    # [ë³´ë‚´ê¸°] ë²„íŠ¼ í´ë¦­\n",
    "        cb_submit_btn.click(\n",
    "            fn=voice_bot_chat,\n",
    "            inputs=[cb_user_input, cb_audio_record, cb_chatbot],\n",
    "            outputs=[cb_user_input, cb_audio_record, cb_chatbot]\n",
    "        )\n",
    "    # ENTER ì œì¶œ ì…ë ¥\n",
    "        cb_user_input.submit(\n",
    "            fn=voice_bot_chat,\n",
    "            inputs=[cb_user_input, cb_audio_record, cb_chatbot],\n",
    "            outputs=[cb_user_input, cb_audio_record, cb_chatbot]\n",
    "        )\n",
    "        with gr.Row():\n",
    "            #6\n",
    "            gr.Button(value=\"â†ªï¸ë˜ëŒë¦¬ê¸°\").click(\n",
    "                fn=voice_bot_undo,\n",
    "                inputs=[cb_chatbot],\n",
    "                outputs=[cb_chatbot]\n",
    "            )\n",
    "            #7\n",
    "            gr.Button(value=\"ğŸ”„ï¸ì´ˆê¸°í™”\").click(\n",
    "                fn=voice_bot_reset,\n",
    "                inputs=[cb_chatbot],\n",
    "                outputs=[cb_chatbot]\n",
    "            )\n",
    "app.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "083dd24f-3e97-4991-96ea-ef7cb19e0a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.prompts import(\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.chains import LLMChain\n",
    "import os\n",
    "import openai\n",
    "\n",
    "# í™˜ê²½ë³€ìˆ˜ì—ì„œ OpenAI API í‚¤ë¥¼ ì½ì–´ì˜´.\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# API í‚¤ê°€ í™˜ê²½ë³€ìˆ˜ì— ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸.\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"í™˜ê²½ë³€ìˆ˜ 'OPENAI_API_KEY'ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# OpenAI API í‚¤ë¥¼ ì„¤ì •.\n",
    "openai.api_key = openai_api_key\n",
    "\n",
    "# OpenAI í´ë¼ì´ì–¸íŠ¸ë¥¼ ìƒì„±.\n",
    "client = openai.OpenAI()\n",
    "\n",
    "system_ai_ko = \"ë‹¹ì‹ ì€ ì¸ê³µì§€ëŠ¥ ë¹„ì„œì•¼, pdf ì¼ê¸°, ë¬¸ì„œ ìš”ì•½í•˜ê¸°, ì¼ì • ê´€ë¦¬, ë‚ ì”¨, ìµœë‹¨ ê²½ë¡œ ê²€ìƒ‰, ì›¹ ê²€ìƒ‰ ë“± ë‹¤ì–‘í•œ ë‚´ìš©ì— ë‹µë³€í•  ìˆ˜ ìˆì–´ì•¼ í•´.\"\n",
    "system_setting = SystemMessagePromptTemplate.from_template(system_ai_ko)\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ ì„¤ì •\n",
    "voice_bot_prompt = ChatPromptTemplate.from_messages([\n",
    "    system_setting,\n",
    "    MessagesPlaceholder(variable_name=\"DUDE\"),\n",
    "    HumanMessagePromptTemplate.from_template(\"{master_user}\")])\n",
    "\n",
    "# ë©”ëª¨ë¦¬ ì„¤ì •\n",
    "voice_bot_memory = ConversationBufferWindowMemory(memory_key=\"DUDE\",\n",
    "                                                  ai_prefix=\"AI ë¹„ì„œ DUDE\",\n",
    "                                                  human_prefix=\"ì‚¬ìš©ì:\",\n",
    "                                                  return_messages=True,\n",
    "                                                  k=10)\n",
    "\n",
    "# llm ëª¨ë¸ ì„¤ì •\n",
    "chatgpt = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    max_tokens=2048,\n",
    "    model_name='gpt-3.5-turbo'\n",
    ")\n",
    "\n",
    "# llmchain ì •ì˜\n",
    "conversation=LLMChain(\n",
    "    prompt=voice_bot_prompt,\n",
    "    memory=voice_bot_memory,\n",
    "    llm=chatgpt,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "from pydub import AudioSegment\n",
    "import numpy as np\n",
    "def voice_bot_handle_audio(audio_record):\n",
    "    save_file_path=\"voice.mp3\"\n",
    "    frame_rate=audio_record[0]\n",
    "    audio_data=audio_record[1].tobytes()\n",
    "    sample_width=audio_record[1].dtype.itemsize\n",
    "    audio=AudioSegment(\n",
    "        audio_data,\n",
    "        frame_rate=frame_rate,\n",
    "        sample_width=sample_width,\n",
    "        channels=1,\n",
    "    )\n",
    "    audio.export(save_file_path, format=\"mp3\")\n",
    "\n",
    "def voice_bot_create_stt():\n",
    "    file_path=\"voice.mp3\"\n",
    "    audio_file=open(file_path, \"rb\")\n",
    "    transcript=client.audio.transcriptions.create(\n",
    "        model=\"whisper-1\",\n",
    "        file=audio_file)\n",
    "    return transcript.text\n",
    "\n",
    "def voice_bot_create_audio(text):\n",
    "    response=client.audio.speech.create(\n",
    "        model=\"tts-1\",\n",
    "        voice=\"onyx\",\n",
    "        input=text)\n",
    "    speech_file_path=\"output.mp3\"\n",
    "    with open(speech_file_path, \"wb\") as audio_file:\n",
    "        audio_file.write(response.content)\n",
    "\n",
    "def voice_bot_chat(message, cb_user_input_audio, chat_history):\n",
    "    if cb_user_input_audio:\n",
    "        message=voice_bot_create_stt()\n",
    "    ai_answer=conversation({\"master_user\":message})['text']\n",
    "    chat_history.append((message, ai_answer))\n",
    "    audio_file=voice_bot_create_audio(ai_answer)\n",
    "    return \"\", audio_file, chat_history\n",
    "\n",
    "def voice_bot_undo(chat_history):\n",
    "    if len(chat_history) > 1:\n",
    "        chat_history.pop()\n",
    "    return chat_history\n",
    "\n",
    "def voice_bot_reset(chat_history):\n",
    "    global voice_bot_memory\n",
    "    chat_init=[[None, \"ì•ˆë…•í•˜ì„¸ìš”, ì¸ê³µì§€ëŠ¥ ë¹„ì„œ DUDE ì…ë‹ˆë‹¤. ë¬´ì—‡ì´ë“  ì‹œì¼œë§Œ ì£¼ì„¸ìš”.\"]]\n",
    "    voice_bot_memory.clear() # ë©”ëª¨ë¦¬ ì´ˆê¸°í™”\n",
    "    return \"\", chat_init\n",
    "\n",
    "import gradio as gr\n",
    "with gr.Blocks() as app:\n",
    "    with gr.Tab(\"ìŒì„± ì¸ì‹ë´‡\"):\n",
    "        with gr.Column():\n",
    "            #1\n",
    "            gr.Markdown(\n",
    "                value=\"\"\"\n",
    "                # <center>ìŒì„± ì¸ì‹ë´‡</center>\n",
    "                <center>AI ì¸ê³µì§€ëŠ¥ ë¹„ì„œ DUDE ì…ë‹ˆë‹¤.\n",
    "                ìŒì„±ìœ¼ë¡œ ë¬»ê±°ë‚˜, ë¬¸ì„œ ìš”ì•½, ì¼ì • ê´€ë¦¬ë¥¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</center>\n",
    "                \"\"\"\n",
    "            )\n",
    "            #2\n",
    "            cb_chatbot=gr.Chatbot(\n",
    "                value=[[None, \"ì•ˆë…•í•˜ì„¸ìš”, ì¸ê³µì§€ëŠ¥ ë¹„ì„œ DUDE ì…ë‹ˆë‹¤. ë¬´ì—‡ì´ë“  ì‹œì¼œë§Œ ì£¼ì„¸ìš”.\"]],\n",
    "                show_label=False\n",
    "            )\n",
    "        with gr.Row():\n",
    "            #3\n",
    "            cb_user_input=gr.Textbox(\n",
    "                lines=1,\n",
    "                placeholder=\"ì…ë ¥ ì°½\",\n",
    "                container=False,\n",
    "                scale=7\n",
    "            )\n",
    "            #4\n",
    "            cb_audio_record=gr.Audio(\n",
    "                sources=[\"microphone\"],\n",
    "                format=\"mp3\",\n",
    "                scale=1,\n",
    "                min_width=200,\n",
    "                label=\"ìŒì„±ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.\"\n",
    "            )\n",
    "            # ìŒì„± ì¶œë ¥\n",
    "            cb_audio_chatbot=gr.Audio(autoplay=True,\n",
    "                                      visible=False)\n",
    "            #5\n",
    "            cb_submit_btn=gr.Button(\n",
    "                value=\"ë³´ë‚´ê¸°\",\n",
    "                scale=1,\n",
    "                visible=\"primary\",\n",
    "                icon=\"https://cdn-icons-png.flaticon.com/128/12439/12439334.png\"\n",
    "            )\n",
    "    # ìŒì„± ë…¹ìŒ ì™„ë£Œ\n",
    "        cb_audio_record.stop_recording(\n",
    "            fn=voice_bot_handle_audio,\n",
    "            inputs=[cb_audio_record]\n",
    "        )\n",
    "    # [ë³´ë‚´ê¸°] ë²„íŠ¼ í´ë¦­\n",
    "        cb_submit_btn.click(\n",
    "            fn=voice_bot_chat,\n",
    "            inputs=[cb_user_input, cb_audio_record, cb_chatbot],\n",
    "            outputs=[cb_user_input, cb_audio_record, cb_chatbot]\n",
    "        )\n",
    "    # ENTER ì œì¶œ ì…ë ¥\n",
    "        cb_user_input.submit(\n",
    "            fn=voice_bot_chat,\n",
    "            inputs=[cb_user_input, cb_audio_record, cb_chatbot],\n",
    "            outputs=[cb_user_input, cb_audio_record, cb_chatbot]\n",
    "        )\n",
    "        with gr.Row():\n",
    "            #6\n",
    "            gr.Button(value=\"â†ªï¸ë˜ëŒë¦¬ê¸°\").click(\n",
    "                fn=voice_bot_undo,\n",
    "                inputs=[cb_chatbot],\n",
    "                outputs=[cb_chatbot]\n",
    "            )\n",
    "            #7\n",
    "            gr.Button(value=\"ğŸ”„ï¸ì´ˆê¸°í™”\").click(\n",
    "                fn=voice_bot_reset,\n",
    "                inputs=[cb_chatbot],\n",
    "                outputs=[cb_chatbot]\n",
    "            )\n",
    "    with gr.Tab(\"ë¬¸ì„œ ìš”ì•½ë´‡\"):\n",
    "        with gr.Row():\n",
    "            #1\n",
    "            gr.Markdown()\n",
    "        with gr.Row():\n",
    "            #2\n",
    "            gr.File()\n",
    "        with gr.Row():\n",
    "            #3\n",
    "            gr.Button()\n",
    "        with gr.Row():\n",
    "            #4\n",
    "            gr.Textbox()\n",
    "            \n",
    "app.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b01c29ce-3da4-44e0-ae8a-005fa9010071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.prompts import(\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.chains import LLMChain\n",
    "import os\n",
    "import openai\n",
    "\n",
    "# í™˜ê²½ë³€ìˆ˜ì—ì„œ OpenAI API í‚¤ë¥¼ ì½ì–´ì˜´.\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# API í‚¤ê°€ í™˜ê²½ë³€ìˆ˜ì— ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸.\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"í™˜ê²½ë³€ìˆ˜ 'OPENAI_API_KEY'ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# OpenAI API í‚¤ë¥¼ ì„¤ì •.\n",
    "openai.api_key = openai_api_key\n",
    "\n",
    "# OpenAI í´ë¼ì´ì–¸íŠ¸ë¥¼ ìƒì„±.\n",
    "client = openai.OpenAI()\n",
    "\n",
    "system_ai_ko = \"ë‹¹ì‹ ì€ ì¸ê³µì§€ëŠ¥ ë¹„ì„œì•¼, pdf ì¼ê¸°, ë¬¸ì„œ ìš”ì•½í•˜ê¸°, ì¼ì • ê´€ë¦¬, ë‚ ì”¨, ìµœë‹¨ ê²½ë¡œ ê²€ìƒ‰, ì›¹ ê²€ìƒ‰ ë“± ë‹¤ì–‘í•œ ë‚´ìš©ì— ë‹µë³€í•  ìˆ˜ ìˆì–´ì•¼ í•´.\"\n",
    "system_setting = SystemMessagePromptTemplate.from_template(system_ai_ko)\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ ì„¤ì •\n",
    "voice_bot_prompt = ChatPromptTemplate.from_messages([\n",
    "    system_setting,\n",
    "    MessagesPlaceholder(variable_name=\"DUDE\"),\n",
    "    HumanMessagePromptTemplate.from_template(\"{master_user}\")])\n",
    "\n",
    "# ë©”ëª¨ë¦¬ ì„¤ì •\n",
    "voice_bot_memory = ConversationBufferWindowMemory(memory_key=\"DUDE\",\n",
    "                                                  ai_prefix=\"AI ë¹„ì„œ DUDE\",\n",
    "                                                  human_prefix=\"ì‚¬ìš©ì:\",\n",
    "                                                  return_messages=True,\n",
    "                                                  k=10)\n",
    "\n",
    "# llm ëª¨ë¸ ì„¤ì •\n",
    "chatgpt = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    max_tokens=2048,\n",
    "    model_name='gpt-3.5-turbo'\n",
    ")\n",
    "\n",
    "# llmchain ì •ì˜\n",
    "conversation=LLMChain(\n",
    "    prompt=voice_bot_prompt,\n",
    "    memory=voice_bot_memory,\n",
    "    llm=chatgpt,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "from pydub import AudioSegment\n",
    "import numpy as np\n",
    "def voice_bot_handle_audio(audio_record):\n",
    "    save_file_path=\"voice.mp3\"\n",
    "    frame_rate=audio_record[0]\n",
    "    audio_data=audio_record[1].tobytes()\n",
    "    sample_width=audio_record[1].dtype.itemsize\n",
    "    audio=AudioSegment(\n",
    "        audio_data,\n",
    "        frame_rate=frame_rate,\n",
    "        sample_width=sample_width,\n",
    "        channels=1,\n",
    "    )\n",
    "    audio.export(save_file_path, format=\"mp3\")\n",
    "\n",
    "def voice_bot_create_stt():\n",
    "    file_path=\"voice.mp3\"\n",
    "    audio_file=open(file_path, \"rb\")\n",
    "    transcript=client.audio.transcriptions.create(\n",
    "        model=\"whisper-1\",\n",
    "        file=audio_file)\n",
    "    return transcript.text\n",
    "\n",
    "def voice_bot_create_audio(text):\n",
    "    response=client.audio.speech.create(\n",
    "        model=\"tts-1\",\n",
    "        voice=\"onyx\",\n",
    "        input=text)\n",
    "    speech_file_path=\"output.mp3\"\n",
    "    with open(speech_file_path, \"wb\") as audio_file:\n",
    "        audio_file.write(response.content)\n",
    "\n",
    "def voice_bot_chat(message, cb_user_input_audio, chat_history):\n",
    "    if cb_user_input_audio:\n",
    "        message=voice_bot_create_stt()\n",
    "    ai_answer=conversation({\"master_user\":message})['text']\n",
    "    chat_history.append((message, ai_answer))\n",
    "    audio_file=voice_bot_create_audio(ai_answer)\n",
    "    return \"\", audio_file, chat_history\n",
    "\n",
    "def voice_bot_undo(chat_history):\n",
    "    if len(chat_history) > 1:\n",
    "        chat_history.pop()\n",
    "    return chat_history\n",
    "\n",
    "def voice_bot_reset(chat_history):\n",
    "    global voice_bot_memory\n",
    "    chat_init=[[None, \"ì•ˆë…•í•˜ì„¸ìš”, ì¸ê³µì§€ëŠ¥ ë¹„ì„œ DUDE ì…ë‹ˆë‹¤. ë¬´ì—‡ì´ë“  ì‹œì¼œë§Œ ì£¼ì„¸ìš”.\"]]\n",
    "    voice_bot_memory.clear() # ë©”ëª¨ë¦¬ ì´ˆê¸°í™”\n",
    "    return \"\", chat_init\n",
    "\n",
    "import gradio as gr\n",
    "with gr.Blocks() as app:\n",
    "    with gr.Tab(\"ìŒì„± ì¸ì‹ë´‡\"):\n",
    "        with gr.Column():\n",
    "            #1\n",
    "            gr.Markdown(\n",
    "                value=\"\"\"\n",
    "                # <center>ìŒì„± ì¸ì‹ë´‡</center>\n",
    "                <center>AI ì¸ê³µì§€ëŠ¥ ë¹„ì„œ DUDE ì…ë‹ˆë‹¤.\n",
    "                ìŒì„±ìœ¼ë¡œ ë¬»ê±°ë‚˜, ë¬¸ì„œ ìš”ì•½, ì¼ì • ê´€ë¦¬ë¥¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</center>\n",
    "                \"\"\"\n",
    "            )\n",
    "            #2\n",
    "            cb_chatbot=gr.Chatbot(\n",
    "                value=[[None, \"ì•ˆë…•í•˜ì„¸ìš”, ì¸ê³µì§€ëŠ¥ ë¹„ì„œ DUDE ì…ë‹ˆë‹¤. ë¬´ì—‡ì´ë“  ì‹œì¼œë§Œ ì£¼ì„¸ìš”.\"]],\n",
    "                show_label=False\n",
    "            )\n",
    "        with gr.Row():\n",
    "            #3\n",
    "            cb_user_input=gr.Textbox(\n",
    "                lines=1,\n",
    "                placeholder=\"ì…ë ¥ ì°½\",\n",
    "                container=False,\n",
    "                scale=7\n",
    "            )\n",
    "            #4\n",
    "            cb_audio_record=gr.Audio(\n",
    "                sources=[\"microphone\"],\n",
    "                format=\"mp3\",\n",
    "                scale=1,\n",
    "                min_width=200,\n",
    "                label=\"ìŒì„±ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.\"\n",
    "            )\n",
    "            # ìŒì„± ì¶œë ¥\n",
    "            cb_audio_chatbot=gr.Audio(autoplay=True,\n",
    "                                      visible=False)\n",
    "            #5\n",
    "            cb_submit_btn=gr.Button(\n",
    "                value=\"ë³´ë‚´ê¸°\",\n",
    "                scale=1,\n",
    "                visible=\"primary\",\n",
    "                icon=\"https://cdn-icons-png.flaticon.com/128/12439/12439334.png\"\n",
    "            )\n",
    "    # ìŒì„± ë…¹ìŒ ì™„ë£Œ\n",
    "        cb_audio_record.stop_recording(\n",
    "            fn=voice_bot_handle_audio,\n",
    "            inputs=[cb_audio_record]\n",
    "        )\n",
    "    # [ë³´ë‚´ê¸°] ë²„íŠ¼ í´ë¦­\n",
    "        cb_submit_btn.click(\n",
    "            fn=voice_bot_chat,\n",
    "            inputs=[cb_user_input, cb_audio_record, cb_chatbot],\n",
    "            outputs=[cb_user_input, cb_audio_record, cb_chatbot]\n",
    "        )\n",
    "    # ENTER ì œì¶œ ì…ë ¥\n",
    "        cb_user_input.submit(\n",
    "            fn=voice_bot_chat,\n",
    "            inputs=[cb_user_input, cb_audio_record, cb_chatbot],\n",
    "            outputs=[cb_user_input, cb_audio_record, cb_chatbot]\n",
    "        )\n",
    "        with gr.Row():\n",
    "            #6\n",
    "            gr.Button(value=\"â†ªï¸ë˜ëŒë¦¬ê¸°\").click(\n",
    "                fn=voice_bot_undo,\n",
    "                inputs=[cb_chatbot],\n",
    "                outputs=[cb_chatbot]\n",
    "            )\n",
    "            #7\n",
    "            gr.Button(value=\"ğŸ”„ï¸ì´ˆê¸°í™”\").click(\n",
    "                fn=voice_bot_reset,\n",
    "                inputs=[cb_chatbot],\n",
    "                outputs=[cb_chatbot]\n",
    "            )\n",
    "    with gr.Tab(\"ë¬¸ì„œ ìš”ì•½ë´‡\"):\n",
    "        with gr.Row():\n",
    "            #1\n",
    "            gr.Markdown(\n",
    "                value=\"\"\"\n",
    "                # <center>ë¬¸ì„œ ìš”ì•½ë´‡</center>\n",
    "                <center> AI ì¸ê³µì§€ëŠ¥ ë¹„ì„œ DUDE ì…ë‹ˆë‹¤. PDFë¥¼ ì—…ë¡œë“œí•˜ë©´ ë‚´ìš©ì„ ë²ˆì—­í•´ ë“œë¦½ë‹ˆë‹¤.</center>\n",
    "                \"\"\"\n",
    "            )\n",
    "        with gr.Row():\n",
    "            #2\n",
    "            gr.File()\n",
    "        with gr.Row():\n",
    "            #3\n",
    "            gr.Button(value=\"ë¬¸ì„œ ìš”ì•½í•˜ê¸°\")\n",
    "        with gr.Row():\n",
    "            #4\n",
    "            gr.Textbox(\n",
    "                label=\"PDF ìš”ì•½\",\n",
    "                placeholder=\"PDF ìš”ì•½ ë‚´ìš©ì…ë‹ˆë‹¤.\",\n",
    "            )\n",
    "            \n",
    "app.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a5c63c8-447f-424a-b7be-aca9309ea9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.prompts import(\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.chains import LLMChain\n",
    "import os\n",
    "import openai\n",
    "\n",
    "# í™˜ê²½ë³€ìˆ˜ì—ì„œ OpenAI API í‚¤ë¥¼ ì½ì–´ì˜´.\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# API í‚¤ê°€ í™˜ê²½ë³€ìˆ˜ì— ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸.\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"í™˜ê²½ë³€ìˆ˜ 'OPENAI_API_KEY'ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# OpenAI API í‚¤ë¥¼ ì„¤ì •.\n",
    "openai.api_key = openai_api_key\n",
    "\n",
    "# OpenAI í´ë¼ì´ì–¸íŠ¸ë¥¼ ìƒì„±.\n",
    "client = openai.OpenAI()\n",
    "\n",
    "system_ai_ko = \"ë‹¹ì‹ ì€ ì¸ê³µì§€ëŠ¥ ë¹„ì„œì•¼, pdf ì¼ê¸°, ë¬¸ì„œ ìš”ì•½í•˜ê¸°, ì¼ì • ê´€ë¦¬, ë‚ ì”¨, ìµœë‹¨ ê²½ë¡œ ê²€ìƒ‰, ì›¹ ê²€ìƒ‰ ë“± ë‹¤ì–‘í•œ ë‚´ìš©ì— ë‹µë³€í•  ìˆ˜ ìˆì–´ì•¼ í•´.\"\n",
    "system_setting = SystemMessagePromptTemplate.from_template(system_ai_ko)\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ ì„¤ì •\n",
    "voice_bot_prompt = ChatPromptTemplate.from_messages([\n",
    "    system_setting,\n",
    "    MessagesPlaceholder(variable_name=\"DUDE\"),\n",
    "    HumanMessagePromptTemplate.from_template(\"{master_user}\")])\n",
    "\n",
    "# ë©”ëª¨ë¦¬ ì„¤ì •\n",
    "voice_bot_memory = ConversationBufferWindowMemory(memory_key=\"DUDE\",\n",
    "                                                  ai_prefix=\"AI ë¹„ì„œ DUDE\",\n",
    "                                                  human_prefix=\"ì‚¬ìš©ì:\",\n",
    "                                                  return_messages=True,\n",
    "                                                  k=10)\n",
    "\n",
    "# llm ëª¨ë¸ ì„¤ì •\n",
    "chatgpt = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    max_tokens=2048,\n",
    "    model_name='gpt-3.5-turbo'\n",
    ")\n",
    "\n",
    "# llmchain ì •ì˜\n",
    "conversation=LLMChain(\n",
    "    prompt=voice_bot_prompt,\n",
    "    memory=voice_bot_memory,\n",
    "    llm=chatgpt,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "from pydub import AudioSegment\n",
    "import numpy as np\n",
    "def voice_bot_handle_audio(audio_record):\n",
    "    save_file_path=\"voice.mp3\"\n",
    "    frame_rate=audio_record[0]\n",
    "    audio_data=audio_record[1].tobytes()\n",
    "    sample_width=audio_record[1].dtype.itemsize\n",
    "    audio=AudioSegment(\n",
    "        audio_data,\n",
    "        frame_rate=frame_rate,\n",
    "        sample_width=sample_width,\n",
    "        channels=1,\n",
    "    )\n",
    "    audio.export(save_file_path, format=\"mp3\")\n",
    "\n",
    "def voice_bot_create_stt():\n",
    "    file_path=\"voice.mp3\"\n",
    "    audio_file=open(file_path, \"rb\")\n",
    "    transcript=client.audio.transcriptions.create(\n",
    "        model=\"whisper-1\",\n",
    "        file=audio_file)\n",
    "    return transcript.text\n",
    "\n",
    "def voice_bot_create_audio(text):\n",
    "    response=client.audio.speech.create(\n",
    "        model=\"tts-1\",\n",
    "        voice=\"onyx\",\n",
    "        input=text)\n",
    "    speech_file_path=\"output.mp3\"\n",
    "    with open(speech_file_path, \"wb\") as audio_file:\n",
    "        audio_file.write(response.content)\n",
    "\n",
    "def voice_bot_chat(message, cb_user_input_audio, chat_history):\n",
    "    if cb_user_input_audio:\n",
    "        message=voice_bot_create_stt()\n",
    "    ai_answer=conversation({\"master_user\":message})['text']\n",
    "    chat_history.append((message, ai_answer))\n",
    "    audio_file=voice_bot_create_audio(ai_answer)\n",
    "    return \"\", audio_file, chat_history\n",
    "\n",
    "def voice_bot_undo(chat_history):\n",
    "    if len(chat_history) > 1:\n",
    "        chat_history.pop()\n",
    "    return chat_history\n",
    "\n",
    "def voice_bot_reset(chat_history):\n",
    "    global voice_bot_memory\n",
    "    chat_init=[[None, \"ì•ˆë…•í•˜ì„¸ìš”, ì¸ê³µì§€ëŠ¥ ë¹„ì„œ DUDE ì…ë‹ˆë‹¤. ë¬´ì—‡ì´ë“  ì‹œì¼œë§Œ ì£¼ì„¸ìš”.\"]]\n",
    "    voice_bot_memory.clear() # ë©”ëª¨ë¦¬ ì´ˆê¸°í™”\n",
    "    return \"\", chat_init\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import MapReduceDocumentsChain\n",
    "\n",
    "def pdf_loader(pdf_path):\n",
    "    loader=PyPDFLoader(pdf_path)\n",
    "    pdf_doc=loader.load()\n",
    "    return pdf_doc\n",
    "\n",
    "def pdf_bot_chatbot(pdf_path):\n",
    "    pages_content=pdf_loader(pdf_path)\n",
    "    text_splitter=RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=3000,\n",
    "        chunk_overlap=0,\n",
    "    )\n",
    "    # pages_content ë‚´ìš© ë¶„í• \n",
    "    split_docs=text_splitter.split_documents(pages_content)\n",
    "    # ë¶„í• ëœ ë¬¸ì„œì˜ ìˆ˜\n",
    "    # map template ì„¤ì •, {pages_content} ë¶„í• ëœ ë‚´ìš©ì´ ì…ë ¥\n",
    "    map_template=\"\"\" ë‹¤ìŒì€ ë¬¸ì„œ ì¤‘ ì¼ë¶€ ë‚´ìš©ì…ë‹ˆë‹¤.\n",
    "    {pages_content}\n",
    "    ì´ ë¬¸ì„œì˜ ì£¼ìš” ë‚´ìš©ì„ ìš”ì•½í•´ ì£¼ì„¸ìš”.\n",
    "    \"\"\"\n",
    "    # map ê¸°ë³¸ í”„ë¡¬í”„íŠ¸\n",
    "    map_prompt=PromptTemplate.from_template(map_template)\n",
    "    # ë¬¸ì„œ ë‚´ìš©ì´ ê¸¸ ìˆ˜ ìˆê¸° ë•Œë¬¸ì— modelì„ gpt-3.5-turbo-16kë¡œ ì„¤ì •\n",
    "    llm=ChatOpenAI(temperate=0,\n",
    "                   model_name='gpt-3.5-turbo-16k')\n",
    "    map_chain=LLMChain(llm=llm, prompt=map_prompt)\n",
    "\n",
    "    # reduce ë‹¨ê³„ì—ì„œ ì²˜ë¦¬í•  í”„ë¡¬í”„íŠ¸ ì •ì˜\n",
    "    reduce_template=\"\"\"ë‹¤ìŒì€ ë¬¸ì„œ ìš”ì•½ì˜ ì§‘í•©ì…ë‹ˆë‹¤.\n",
    "    {summaries}\n",
    "    ì´ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ í†µí•©ëœ ë¬¸ì„œ ìš”ì•½ì„ ì‘ì„±í•´ ì£¼ì„¸ìš”.\n",
    "    \"\"\"\n",
    "    # reduce í”„ë¡¬í”„íŠ¸\n",
    "    reduce_prompt=PromptTemplate.from_template(reduce_template)\n",
    "\n",
    "    # reduceì—ì„œ ìˆ˜í–‰í•  LLMChain ì •ì˜\n",
    "    reduce_chain=LLMChain(llm=llm, prompt=reduce_prompt)\n",
    "    from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "    from langchain.chains import ReduceDocumentsChain\n",
    "\n",
    "    # ë¬¸ì„œ ëª©ë¡ í†µí•© ì²´ì¸ ì„¤ì •\n",
    "    combine_doc_chain=StuffDocumentsChain(\n",
    "        llm_chain=reduce_chain,\n",
    "        document_variable_name=\"summaries\" # reduce í”„ë¡¬í”„íŠ¸ì— ëŒ€ì…ë˜ëŠ” ë³€ìˆ˜\n",
    "    )\n",
    "\n",
    "    # ë¶„í• ëœ ë¬¸ì„œ ìˆœì°¨ì ìœ¼ë¡œ Reduce ì²˜ë¦¬\n",
    "    reduce_doc_chain=ReduceDocumentsChain(\n",
    "        combine_documents_chain=combine_doc_chain,\n",
    "        collapse_documents_chain=combine_doc_chain,\n",
    "        token_max=4000, # í† í° ìµœëŒ€ ê°œìˆ˜ ì„¤ì •\n",
    "    )\n",
    "\n",
    "    # ìµœì¢… ì²´ì¸ ì—°ê²°\n",
    "    final_chain=MapReduceDocumentsChain(\n",
    "        llm_chain=map_chain, # ê° ë¬¸ì„œ ë§µí•‘\n",
    "        reduce_documents_chain=reduce_doc_chain,\n",
    "        document_variable_name=\"pages_content\",\n",
    "        return_intermediate_steps=False,\n",
    "    )\n",
    "    # ìµœì¢… ê²°ê³¼ ì‹¤í–‰\n",
    "    result_summary=final_chain.run(split_docs)\n",
    "    # ìš”ì•½ ê²°ê³¼ ì¶œë ¥\n",
    "    return result_summary\n",
    "\n",
    "\n",
    "import gradio as gr\n",
    "with gr.Blocks() as app:\n",
    "    with gr.Tab(\"ìŒì„± ì¸ì‹ë´‡\"):\n",
    "        with gr.Column():\n",
    "            #1\n",
    "            gr.Markdown(\n",
    "                value=\"\"\"\n",
    "                # <center>ìŒì„± ì¸ì‹ë´‡</center>\n",
    "                <center>AI ì¸ê³µì§€ëŠ¥ ë¹„ì„œ DUDE ì…ë‹ˆë‹¤.\n",
    "                ìŒì„±ìœ¼ë¡œ ë¬»ê±°ë‚˜, ë¬¸ì„œ ìš”ì•½, ì¼ì • ê´€ë¦¬ë¥¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</center>\n",
    "                \"\"\"\n",
    "            )\n",
    "            #2\n",
    "            cb_chatbot=gr.Chatbot(\n",
    "                value=[[None, \"ì•ˆë…•í•˜ì„¸ìš”, ì¸ê³µì§€ëŠ¥ ë¹„ì„œ DUDE ì…ë‹ˆë‹¤. ë¬´ì—‡ì´ë“  ì‹œì¼œë§Œ ì£¼ì„¸ìš”.\"]],\n",
    "                show_label=False\n",
    "            )\n",
    "        with gr.Row():\n",
    "            #3\n",
    "            cb_user_input=gr.Textbox(\n",
    "                lines=1,\n",
    "                placeholder=\"ì…ë ¥ ì°½\",\n",
    "                container=False,\n",
    "                scale=7\n",
    "            )\n",
    "            #4\n",
    "            cb_audio_record=gr.Audio(\n",
    "                sources=[\"microphone\"],\n",
    "                format=\"mp3\",\n",
    "                scale=1,\n",
    "                min_width=200,\n",
    "                label=\"ìŒì„±ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.\"\n",
    "            )\n",
    "            # ìŒì„± ì¶œë ¥\n",
    "            cb_audio_chatbot=gr.Audio(autoplay=True,\n",
    "                                      visible=False)\n",
    "            #5\n",
    "            cb_submit_btn=gr.Button(\n",
    "                value=\"ë³´ë‚´ê¸°\",\n",
    "                scale=1,\n",
    "                visible=\"primary\",\n",
    "                icon=\"https://cdn-icons-png.flaticon.com/128/12439/12439334.png\"\n",
    "            )\n",
    "    # ìŒì„± ë…¹ìŒ ì™„ë£Œ\n",
    "        cb_audio_record.stop_recording(\n",
    "            fn=voice_bot_handle_audio,\n",
    "            inputs=[cb_audio_record]\n",
    "        )\n",
    "    # [ë³´ë‚´ê¸°] ë²„íŠ¼ í´ë¦­\n",
    "        cb_submit_btn.click(\n",
    "            fn=voice_bot_chat,\n",
    "            inputs=[cb_user_input, cb_audio_record, cb_chatbot],\n",
    "            outputs=[cb_user_input, cb_audio_record, cb_chatbot]\n",
    "        )\n",
    "    # ENTER ì œì¶œ ì…ë ¥\n",
    "        cb_user_input.submit(\n",
    "            fn=voice_bot_chat,\n",
    "            inputs=[cb_user_input, cb_audio_record, cb_chatbot],\n",
    "            outputs=[cb_user_input, cb_audio_record, cb_chatbot]\n",
    "        )\n",
    "        with gr.Row():\n",
    "            #6\n",
    "            gr.Button(value=\"â†ªï¸ë˜ëŒë¦¬ê¸°\").click(\n",
    "                fn=voice_bot_undo,\n",
    "                inputs=[cb_chatbot],\n",
    "                outputs=[cb_chatbot]\n",
    "            )\n",
    "            #7\n",
    "            gr.Button(value=\"ğŸ”„ï¸ì´ˆê¸°í™”\").click(\n",
    "                fn=voice_bot_reset,\n",
    "                inputs=[cb_chatbot],\n",
    "                outputs=[cb_chatbot]\n",
    "            )\n",
    "    with gr.Tab(\"ë¬¸ì„œ ìš”ì•½ë´‡\"):\n",
    "        with gr.Row():\n",
    "            #1\n",
    "            gr.Markdown(\n",
    "                value=\"\"\"\n",
    "                # <center>ë¬¸ì„œ ìš”ì•½ë´‡</center>\n",
    "                <center> AI ì¸ê³µì§€ëŠ¥ ë¹„ì„œ DUDE ì…ë‹ˆë‹¤. PDFë¥¼ ì—…ë¡œë“œí•˜ë©´ ë‚´ìš©ì„ ë²ˆì—­í•´ ë“œë¦½ë‹ˆë‹¤.</center>\n",
    "                \"\"\"\n",
    "            )\n",
    "        with gr.Row():\n",
    "            #2\n",
    "            pdf_input=gr.File()\n",
    "        with gr.Row():\n",
    "            #3\n",
    "            summary_btn=gr.Button(value=\"ë¬¸ì„œ ìš”ì•½í•˜ê¸°\")\n",
    "        with gr.Row():\n",
    "            #4\n",
    "            summary=gr.Textbox(\n",
    "                label=\"PDF ìš”ì•½\",\n",
    "                lines=8,\n",
    "                placeholder=\"PDF ìš”ì•½ ë‚´ìš©ì…ë‹ˆë‹¤.\",\n",
    "            )\n",
    "            summary_btn.click(\n",
    "                fn=pdf_bot_chatbot,\n",
    "                inputs=[pdf_input],\n",
    "                outputs=[summary]\n",
    "            )\n",
    "            \n",
    "app.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2744599-d9f0-4988-bc09-f484f2715fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7865\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.prompts import(\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.chains import LLMChain\n",
    "import os\n",
    "import openai\n",
    "\n",
    "# í™˜ê²½ë³€ìˆ˜ì—ì„œ OpenAI API í‚¤ë¥¼ ì½ì–´ì˜´.\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# API í‚¤ê°€ í™˜ê²½ë³€ìˆ˜ì— ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸.\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"í™˜ê²½ë³€ìˆ˜ 'OPENAI_API_KEY'ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# OpenAI API í‚¤ë¥¼ ì„¤ì •.\n",
    "openai.api_key = openai_api_key\n",
    "\n",
    "# OpenAI í´ë¼ì´ì–¸íŠ¸ë¥¼ ìƒì„±.\n",
    "client = openai.OpenAI()\n",
    "\n",
    "system_ai_ko = \"ë‹¹ì‹ ì€ ì¸ê³µì§€ëŠ¥ ë¹„ì„œì•¼, pdf ì¼ê¸°, ë¬¸ì„œ ìš”ì•½í•˜ê¸°, ì¼ì • ê´€ë¦¬, ë‚ ì”¨, ìµœë‹¨ ê²½ë¡œ ê²€ìƒ‰, ì›¹ ê²€ìƒ‰ ë“± ë‹¤ì–‘í•œ ë‚´ìš©ì— ë‹µë³€í•  ìˆ˜ ìˆì–´ì•¼ í•´.\"\n",
    "system_setting = SystemMessagePromptTemplate.from_template(system_ai_ko)\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ ì„¤ì •\n",
    "voice_bot_prompt = ChatPromptTemplate.from_messages([\n",
    "    system_setting,\n",
    "    MessagesPlaceholder(variable_name=\"DUDE\"),\n",
    "    HumanMessagePromptTemplate.from_template(\"{master_user}\")])\n",
    "\n",
    "# ë©”ëª¨ë¦¬ ì„¤ì •\n",
    "voice_bot_memory = ConversationBufferWindowMemory(memory_key=\"DUDE\",\n",
    "                                                  ai_prefix=\"AI ë¹„ì„œ DUDE\",\n",
    "                                                  human_prefix=\"ì‚¬ìš©ì:\",\n",
    "                                                  return_messages=True,\n",
    "                                                  k=10)\n",
    "\n",
    "# llm ëª¨ë¸ ì„¤ì •\n",
    "chatgpt = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    max_tokens=2048,\n",
    "    model_name='gpt-3.5-turbo'\n",
    ")\n",
    "\n",
    "# llmchain ì •ì˜\n",
    "conversation=LLMChain(\n",
    "    prompt=voice_bot_prompt,\n",
    "    memory=voice_bot_memory,\n",
    "    llm=chatgpt,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "from pydub import AudioSegment\n",
    "import numpy as np\n",
    "def voice_bot_handle_audio(audio_record):\n",
    "    save_file_path=\"voice.mp3\"\n",
    "    frame_rate=audio_record[0]\n",
    "    audio_data=audio_record[1].tobytes()\n",
    "    sample_width=audio_record[1].dtype.itemsize\n",
    "    audio=AudioSegment(\n",
    "        audio_data,\n",
    "        frame_rate=frame_rate,\n",
    "        sample_width=sample_width,\n",
    "        channels=1,\n",
    "    )\n",
    "    audio.export(save_file_path, format=\"mp3\")\n",
    "\n",
    "def voice_bot_create_stt():\n",
    "    file_path=\"voice.mp3\"\n",
    "    audio_file=open(file_path, \"rb\")\n",
    "    transcript=client.audio.transcriptions.create(\n",
    "        model=\"whisper-1\",\n",
    "        file=audio_file)\n",
    "    return transcript.text\n",
    "\n",
    "def voice_bot_create_audio(text):\n",
    "    response=client.audio.speech.create(\n",
    "        model=\"tts-1\",\n",
    "        voice=\"onyx\",\n",
    "        input=text)\n",
    "    speech_file_path=\"output.mp3\"\n",
    "    with open(speech_file_path, \"wb\") as audio_file:\n",
    "        audio_file.write(response.content)\n",
    "\n",
    "def voice_bot_chat(message, cb_user_input_audio, chat_history):\n",
    "    if cb_user_input_audio:\n",
    "        message=voice_bot_create_stt()\n",
    "    ai_answer=conversation({\"master_user\":message})['text']\n",
    "    chat_history.append((message, ai_answer))\n",
    "    audio_file=voice_bot_create_audio(ai_answer)\n",
    "    return \"\", audio_file, chat_history\n",
    "\n",
    "def voice_bot_undo(chat_history):\n",
    "    if len(chat_history) > 1:\n",
    "        chat_history.pop()\n",
    "    return chat_history\n",
    "\n",
    "def voice_bot_reset(chat_history):\n",
    "    global voice_bot_memory\n",
    "    chat_init=[[None, \"ì•ˆë…•í•˜ì„¸ìš”, ì¸ê³µì§€ëŠ¥ ë¹„ì„œ DUDE ì…ë‹ˆë‹¤. ë¬´ì—‡ì´ë“  ì‹œì¼œë§Œ ì£¼ì„¸ìš”.\"]]\n",
    "    voice_bot_memory.clear() # ë©”ëª¨ë¦¬ ì´ˆê¸°í™”\n",
    "    return \"\", chat_init\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import MapReduceDocumentsChain\n",
    "\n",
    "def pdf_loader(pdf_path):\n",
    "    loader=PyPDFLoader(pdf_path)\n",
    "    pdf_doc=loader.load()\n",
    "    return pdf_doc\n",
    "\n",
    "def pdf_bot_chatbot(pdf_path):\n",
    "    pages_content=pdf_loader(pdf_path)\n",
    "    text_splitter=RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=3000,\n",
    "        chunk_overlap=0,\n",
    "    )\n",
    "    # pages_content ë‚´ìš© ë¶„í• \n",
    "    split_docs=text_splitter.split_documents(pages_content)\n",
    "    # ë¶„í• ëœ ë¬¸ì„œì˜ ìˆ˜\n",
    "    # map template ì„¤ì •, {pages_content} ë¶„í• ëœ ë‚´ìš©ì´ ì…ë ¥\n",
    "    map_template=\"\"\" ë‹¤ìŒì€ ë¬¸ì„œ ì¤‘ ì¼ë¶€ ë‚´ìš©ì…ë‹ˆë‹¤.\n",
    "    {pages_content}\n",
    "    ì´ ë¬¸ì„œì˜ ì£¼ìš” ë‚´ìš©ì„ ìš”ì•½í•´ ì£¼ì„¸ìš”.\n",
    "    \"\"\"\n",
    "    # map ê¸°ë³¸ í”„ë¡¬í”„íŠ¸\n",
    "    map_prompt=PromptTemplate.from_template(map_template)\n",
    "    # ë¬¸ì„œ ë‚´ìš©ì´ ê¸¸ ìˆ˜ ìˆê¸° ë•Œë¬¸ì— modelì„ gpt-3.5-turbo-16kë¡œ ì„¤ì •\n",
    "    llm=ChatOpenAI(temperate=0,\n",
    "                   model_name='gpt-3.5-turbo-16k')\n",
    "    map_chain=LLMChain(llm=llm, prompt=map_prompt)\n",
    "\n",
    "    # reduce ë‹¨ê³„ì—ì„œ ì²˜ë¦¬í•  í”„ë¡¬í”„íŠ¸ ì •ì˜\n",
    "    reduce_template=\"\"\"ë‹¤ìŒì€ ë¬¸ì„œ ìš”ì•½ì˜ ì§‘í•©ì…ë‹ˆë‹¤.\n",
    "    {summaries}\n",
    "    ì´ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ í†µí•©ëœ ë¬¸ì„œ ìš”ì•½ì„ ì‘ì„±í•´ ì£¼ì„¸ìš”.\n",
    "    \"\"\"\n",
    "    # reduce í”„ë¡¬í”„íŠ¸\n",
    "    reduce_prompt=PromptTemplate.from_template(reduce_template)\n",
    "\n",
    "    # reduceì—ì„œ ìˆ˜í–‰í•  LLMChain ì •ì˜\n",
    "    reduce_chain=LLMChain(llm=llm, prompt=reduce_prompt)\n",
    "    from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "    from langchain.chains import ReduceDocumentsChain\n",
    "\n",
    "    # ë¬¸ì„œ ëª©ë¡ í†µí•© ì²´ì¸ ì„¤ì •\n",
    "    combine_doc_chain=StuffDocumentsChain(\n",
    "        llm_chain=reduce_chain,\n",
    "        document_variable_name=\"summaries\" # reduce í”„ë¡¬í”„íŠ¸ì— ëŒ€ì…ë˜ëŠ” ë³€ìˆ˜\n",
    "    )\n",
    "\n",
    "    # ë¶„í• ëœ ë¬¸ì„œ ìˆœì°¨ì ìœ¼ë¡œ Reduce ì²˜ë¦¬\n",
    "    reduce_doc_chain=ReduceDocumentsChain(\n",
    "        combine_documents_chain=combine_doc_chain,\n",
    "        collapse_documents_chain=combine_doc_chain,\n",
    "        token_max=4000, # í† í° ìµœëŒ€ ê°œìˆ˜ ì„¤ì •\n",
    "    )\n",
    "\n",
    "    # ìµœì¢… ì²´ì¸ ì—°ê²°\n",
    "    final_chain=MapReduceDocumentsChain(\n",
    "        llm_chain=map_chain, # ê° ë¬¸ì„œ ë§µí•‘\n",
    "        reduce_documents_chain=reduce_doc_chain,\n",
    "        document_variable_name=\"pages_content\",\n",
    "        return_intermediate_steps=False,\n",
    "    )\n",
    "    # ìµœì¢… ê²°ê³¼ ì‹¤í–‰\n",
    "    result_summary=final_chain.run(split_docs)\n",
    "    # ìš”ì•½ ê²°ê³¼ ì¶œë ¥\n",
    "    return result_summary\n",
    "\n",
    "\n",
    "import gradio as gr\n",
    "with gr.Blocks() as app:\n",
    "    with gr.Tab(\"ìŒì„± ì¸ì‹ë´‡\"):\n",
    "        with gr.Column():\n",
    "            #1\n",
    "            gr.Markdown(\n",
    "                value=\"\"\"\n",
    "                # <center>ìŒì„± ì¸ì‹ë´‡</center>\n",
    "                <center>AI ì¸ê³µì§€ëŠ¥ ë¹„ì„œ DUDE ì…ë‹ˆë‹¤.\n",
    "                ìŒì„±ìœ¼ë¡œ ë¬»ê±°ë‚˜, ë¬¸ì„œ ìš”ì•½, ì¼ì • ê´€ë¦¬ë¥¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</center>\n",
    "                \"\"\"\n",
    "            )\n",
    "            #2\n",
    "            cb_chatbot=gr.Chatbot(\n",
    "                value=[[None, \"ì•ˆë…•í•˜ì„¸ìš”, ì¸ê³µì§€ëŠ¥ ë¹„ì„œ DUDE ì…ë‹ˆë‹¤. ë¬´ì—‡ì´ë“  ì‹œì¼œë§Œ ì£¼ì„¸ìš”.\"]],\n",
    "                show_label=False\n",
    "            )\n",
    "        with gr.Row():\n",
    "            #3\n",
    "            cb_user_input=gr.Textbox(\n",
    "                lines=1,\n",
    "                placeholder=\"ì…ë ¥ ì°½\",\n",
    "                container=False,\n",
    "                scale=7\n",
    "            )\n",
    "            #4\n",
    "            cb_audio_record=gr.Audio(\n",
    "                sources=[\"microphone\"],\n",
    "                format=\"mp3\",\n",
    "                scale=1,\n",
    "                min_width=200,\n",
    "                label=\"ìŒì„±ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.\"\n",
    "            )\n",
    "            # ìŒì„± ì¶œë ¥\n",
    "            cb_audio_chatbot=gr.Audio(autoplay=True,\n",
    "                                      visible=False)\n",
    "            #5\n",
    "            cb_submit_btn=gr.Button(\n",
    "                value=\"ë³´ë‚´ê¸°\",\n",
    "                scale=1,\n",
    "                visible=\"primary\",\n",
    "                icon=\"https://cdn-icons-png.flaticon.com/128/12439/12439334.png\"\n",
    "            )\n",
    "    # ìŒì„± ë…¹ìŒ ì™„ë£Œ\n",
    "        cb_audio_record.stop_recording(\n",
    "            fn=voice_bot_handle_audio,\n",
    "            inputs=[cb_audio_record]\n",
    "        )\n",
    "    # [ë³´ë‚´ê¸°] ë²„íŠ¼ í´ë¦­\n",
    "        cb_submit_btn.click(\n",
    "            fn=voice_bot_chat,\n",
    "            inputs=[cb_user_input, cb_audio_record, cb_chatbot],\n",
    "            outputs=[cb_user_input, cb_audio_record, cb_chatbot]\n",
    "        )\n",
    "    # ENTER ì œì¶œ ì…ë ¥\n",
    "        cb_user_input.submit(\n",
    "            fn=voice_bot_chat,\n",
    "            inputs=[cb_user_input, cb_audio_record, cb_chatbot],\n",
    "            outputs=[cb_user_input, cb_audio_record, cb_chatbot]\n",
    "        )\n",
    "        with gr.Row():\n",
    "            #6\n",
    "            gr.Button(value=\"â†ªï¸ë˜ëŒë¦¬ê¸°\").click(\n",
    "                fn=voice_bot_undo,\n",
    "                inputs=[cb_chatbot],\n",
    "                outputs=[cb_chatbot]\n",
    "            )\n",
    "            #7\n",
    "            gr.Button(value=\"ğŸ”„ï¸ì´ˆê¸°í™”\").click(\n",
    "                fn=voice_bot_reset,\n",
    "                inputs=[cb_chatbot],\n",
    "                outputs=[cb_chatbot]\n",
    "            )\n",
    "    with gr.Tab(\"ë¬¸ì„œ ìš”ì•½ë´‡\"):\n",
    "        with gr.Row():\n",
    "            #1\n",
    "            gr.Markdown(\n",
    "                value=\"\"\"\n",
    "                # <center>ë¬¸ì„œ ìš”ì•½ë´‡</center>\n",
    "                <center> AI ì¸ê³µì§€ëŠ¥ ë¹„ì„œ DUDE ì…ë‹ˆë‹¤. PDFë¥¼ ì—…ë¡œë“œí•˜ë©´ ë‚´ìš©ì„ ë²ˆì—­í•´ ë“œë¦½ë‹ˆë‹¤.</center>\n",
    "                \"\"\"\n",
    "            )\n",
    "        with gr.Row():\n",
    "            #2\n",
    "            pdf_input=gr.File()\n",
    "        with gr.Row():\n",
    "            #3\n",
    "            summary_btn=gr.Button(value=\"ë¬¸ì„œ ìš”ì•½í•˜ê¸°\")\n",
    "        with gr.Row():\n",
    "            #4\n",
    "            summary=gr.Textbox(\n",
    "                label=\"PDF ìš”ì•½\",\n",
    "                lines=8,\n",
    "                placeholder=\"PDF ìš”ì•½ ë‚´ìš©ì…ë‹ˆë‹¤.\",\n",
    "            )\n",
    "            summary_btn.click(\n",
    "                fn=pdf_bot_chatbot,\n",
    "                inputs=[pdf_input],\n",
    "                outputs=[summary]\n",
    "            )\n",
    "    with gr.Tab(\"ì¼ì • ê´€ë¦¬ë´‡\"):\n",
    "        with gr.Row():\n",
    "            #1\n",
    "            gr.Markdown(\n",
    "                value=\"\"\"\n",
    "                # <center>ì¼ì • ê´€ë¦¬ë´‡</center>\n",
    "                <center> AI ì¸ê³µì§€ëŠ¥ ë¹„ì„œ DUDE ì…ë‹ˆë‹¤. ì¼ì • ê´€ë¦¬ë¥¼ ìœ„í•œ ë´‡ì…ë‹ˆë‹¤.</center>\n",
    "                \"\"\")\n",
    "        with gr.Row():\n",
    "            #2\n",
    "            gr.Chatbot(\n",
    "                value=[\n",
    "                    [None, \"ì•ˆë…•í•˜ì„¸ìš”, ì¼ì • ì´ë¦„, ì‹œê°„, ì¼ì • ì„¤ëª…ìœ¼ë¡œ ì¼ì •ì„ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \\n\\\n",
    "                    ì˜ˆì‹œ: í¬ë¦¬ìŠ¤ë§ˆìŠ¤, 2024ë…„ 12ì›” 25ì¼ 12ì‹œ 00ë¶„, ì˜¬í•´ì˜ í¬ë¦¬ìŠ¤ë§ˆìŠ¤ ì¼ì • ì¶”ê°€í•´ ì¤˜\\n\\\n",
    "                    ì „ì²´ ì¼ì •ì´ ë³´ê³  ì‹¶ë‹¤ë©´ ì „ì²´ì¼ì • ë³´ì—¬ì¤˜ ë¼ê³  ë§í•´ ì£¼ì„¸ìš”.\"],\n",
    "                ],\n",
    "                show_label=\"ì¼ì • ê´€ë¦¬\"                     \n",
    "            )\n",
    "        with gr.Row():\n",
    "            #3\n",
    "            gr.Textbox(\n",
    "                label=\"ì±„íŒ…\",\n",
    "                lines=1,\n",
    "                placeholder=\"ì±„íŒ… ì…ë ¥ ì°½\",\n",
    "                scale=8,\n",
    "            )\n",
    "            #4\n",
    "            gr.Button(\n",
    "                value=\"ë³´ë‚´ê¸°\",\n",
    "                scale=2,\n",
    "                visible=\"primary\",\n",
    "            )\n",
    "        with gr.Row():\n",
    "            #5\n",
    "            gr.File(\n",
    "                label=\"ì¼ì • íŒŒì¼ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.\",\n",
    "                scale=8,\n",
    "                visible=\"primary\",\n",
    "                height=100\n",
    "            )\n",
    "            \n",
    "app.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5972add-fa31-46fd-ae17-45260e0117e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7866\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.prompts import(\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.chains import LLMChain\n",
    "import os\n",
    "import openai\n",
    "\n",
    "# í™˜ê²½ë³€ìˆ˜ì—ì„œ OpenAI API í‚¤ë¥¼ ì½ì–´ì˜´.\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# API í‚¤ê°€ í™˜ê²½ë³€ìˆ˜ì— ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸.\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"í™˜ê²½ë³€ìˆ˜ 'OPENAI_API_KEY'ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# OpenAI API í‚¤ë¥¼ ì„¤ì •.\n",
    "openai.api_key = openai_api_key\n",
    "\n",
    "# OpenAI í´ë¼ì´ì–¸íŠ¸ë¥¼ ìƒì„±.\n",
    "client = openai.OpenAI()\n",
    "\n",
    "system_ai_ko = \"ë‹¹ì‹ ì€ ì¸ê³µì§€ëŠ¥ ë¹„ì„œì•¼, pdf ì¼ê¸°, ë¬¸ì„œ ìš”ì•½í•˜ê¸°, ì¼ì • ê´€ë¦¬, ë‚ ì”¨, ìµœë‹¨ ê²½ë¡œ ê²€ìƒ‰, ì›¹ ê²€ìƒ‰ ë“± ë‹¤ì–‘í•œ ë‚´ìš©ì— ë‹µë³€í•  ìˆ˜ ìˆì–´ì•¼ í•´.\"\n",
    "system_setting = SystemMessagePromptTemplate.from_template(system_ai_ko)\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ ì„¤ì •\n",
    "voice_bot_prompt = ChatPromptTemplate.from_messages([\n",
    "    system_setting,\n",
    "    MessagesPlaceholder(variable_name=\"DUDE\"),\n",
    "    HumanMessagePromptTemplate.from_template(\"{master_user}\")])\n",
    "\n",
    "# ë©”ëª¨ë¦¬ ì„¤ì •\n",
    "voice_bot_memory = ConversationBufferWindowMemory(memory_key=\"DUDE\",\n",
    "                                                  ai_prefix=\"AI ë¹„ì„œ DUDE\",\n",
    "                                                  human_prefix=\"ì‚¬ìš©ì:\",\n",
    "                                                  return_messages=True,\n",
    "                                                  k=10)\n",
    "\n",
    "# llm ëª¨ë¸ ì„¤ì •\n",
    "chatgpt = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    max_tokens=2048,\n",
    "    model_name='gpt-3.5-turbo'\n",
    ")\n",
    "\n",
    "# llmchain ì •ì˜\n",
    "conversation=LLMChain(\n",
    "    prompt=voice_bot_prompt,\n",
    "    memory=voice_bot_memory,\n",
    "    llm=chatgpt,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "from pydub import AudioSegment\n",
    "import numpy as np\n",
    "def voice_bot_handle_audio(audio_record):\n",
    "    save_file_path=\"voice.mp3\"\n",
    "    frame_rate=audio_record[0]\n",
    "    audio_data=audio_record[1].tobytes()\n",
    "    sample_width=audio_record[1].dtype.itemsize\n",
    "    audio=AudioSegment(\n",
    "        audio_data,\n",
    "        frame_rate=frame_rate,\n",
    "        sample_width=sample_width,\n",
    "        channels=1,\n",
    "    )\n",
    "    audio.export(save_file_path, format=\"mp3\")\n",
    "\n",
    "def voice_bot_create_stt():\n",
    "    file_path=\"voice.mp3\"\n",
    "    audio_file=open(file_path, \"rb\")\n",
    "    transcript=client.audio.transcriptions.create(\n",
    "        model=\"whisper-1\",\n",
    "        file=audio_file)\n",
    "    return transcript.text\n",
    "\n",
    "def voice_bot_create_audio(text):\n",
    "    response=client.audio.speech.create(\n",
    "        model=\"tts-1\",\n",
    "        voice=\"onyx\",\n",
    "        input=text)\n",
    "    speech_file_path=\"output.mp3\"\n",
    "    with open(speech_file_path, \"wb\") as audio_file:\n",
    "        audio_file.write(response.content)\n",
    "\n",
    "def voice_bot_chat(message, cb_user_input_audio, chat_history):\n",
    "    if cb_user_input_audio:\n",
    "        message=voice_bot_create_stt()\n",
    "    ai_answer=conversation({\"master_user\":message})['text']\n",
    "    chat_history.append((message, ai_answer))\n",
    "    audio_file=voice_bot_create_audio(ai_answer)\n",
    "    return \"\", audio_file, chat_history\n",
    "\n",
    "def voice_bot_undo(chat_history):\n",
    "    if len(chat_history) > 1:\n",
    "        chat_history.pop()\n",
    "    return chat_history\n",
    "\n",
    "def voice_bot_reset(chat_history):\n",
    "    global voice_bot_memory\n",
    "    chat_init=[[None, \"ì•ˆë…•í•˜ì„¸ìš”, ì¸ê³µì§€ëŠ¥ ë¹„ì„œ DUDE ì…ë‹ˆë‹¤. ë¬´ì—‡ì´ë“  ì‹œì¼œë§Œ ì£¼ì„¸ìš”.\"]]\n",
    "    voice_bot_memory.clear() # ë©”ëª¨ë¦¬ ì´ˆê¸°í™”\n",
    "    return \"\", chat_init\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import MapReduceDocumentsChain\n",
    "\n",
    "def pdf_loader(pdf_path):\n",
    "    loader=PyPDFLoader(pdf_path)\n",
    "    pdf_doc=loader.load()\n",
    "    return pdf_doc\n",
    "\n",
    "def pdf_bot_chatbot(pdf_path):\n",
    "    pages_content=pdf_loader(pdf_path)\n",
    "    text_splitter=RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=3000,\n",
    "        chunk_overlap=0,\n",
    "    )\n",
    "    # pages_content ë‚´ìš© ë¶„í• \n",
    "    split_docs=text_splitter.split_documents(pages_content)\n",
    "    # ë¶„í• ëœ ë¬¸ì„œì˜ ìˆ˜\n",
    "    # map template ì„¤ì •, {pages_content} ë¶„í• ëœ ë‚´ìš©ì´ ì…ë ¥\n",
    "    map_template=\"\"\" ë‹¤ìŒì€ ë¬¸ì„œ ì¤‘ ì¼ë¶€ ë‚´ìš©ì…ë‹ˆë‹¤.\n",
    "    {pages_content}\n",
    "    ì´ ë¬¸ì„œì˜ ì£¼ìš” ë‚´ìš©ì„ ìš”ì•½í•´ ì£¼ì„¸ìš”.\n",
    "    \"\"\"\n",
    "    # map ê¸°ë³¸ í”„ë¡¬í”„íŠ¸\n",
    "    map_prompt=PromptTemplate.from_template(map_template)\n",
    "    # ë¬¸ì„œ ë‚´ìš©ì´ ê¸¸ ìˆ˜ ìˆê¸° ë•Œë¬¸ì— modelì„ gpt-3.5-turbo-16kë¡œ ì„¤ì •\n",
    "    llm=ChatOpenAI(temperate=0,\n",
    "                   model_name='gpt-3.5-turbo-16k')\n",
    "    map_chain=LLMChain(llm=llm, prompt=map_prompt)\n",
    "\n",
    "    # reduce ë‹¨ê³„ì—ì„œ ì²˜ë¦¬í•  í”„ë¡¬í”„íŠ¸ ì •ì˜\n",
    "    reduce_template=\"\"\"ë‹¤ìŒì€ ë¬¸ì„œ ìš”ì•½ì˜ ì§‘í•©ì…ë‹ˆë‹¤.\n",
    "    {summaries}\n",
    "    ì´ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ í†µí•©ëœ ë¬¸ì„œ ìš”ì•½ì„ ì‘ì„±í•´ ì£¼ì„¸ìš”.\n",
    "    \"\"\"\n",
    "    # reduce í”„ë¡¬í”„íŠ¸\n",
    "    reduce_prompt=PromptTemplate.from_template(reduce_template)\n",
    "\n",
    "    # reduceì—ì„œ ìˆ˜í–‰í•  LLMChain ì •ì˜\n",
    "    reduce_chain=LLMChain(llm=llm, prompt=reduce_prompt)\n",
    "    from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "    from langchain.chains import ReduceDocumentsChain\n",
    "\n",
    "    # ë¬¸ì„œ ëª©ë¡ í†µí•© ì²´ì¸ ì„¤ì •\n",
    "    combine_doc_chain=StuffDocumentsChain(\n",
    "        llm_chain=reduce_chain,\n",
    "        document_variable_name=\"summaries\" # reduce í”„ë¡¬í”„íŠ¸ì— ëŒ€ì…ë˜ëŠ” ë³€ìˆ˜\n",
    "    )\n",
    "\n",
    "    # ë¶„í• ëœ ë¬¸ì„œ ìˆœì°¨ì ìœ¼ë¡œ Reduce ì²˜ë¦¬\n",
    "    reduce_doc_chain=ReduceDocumentsChain(\n",
    "        combine_documents_chain=combine_doc_chain,\n",
    "        collapse_documents_chain=combine_doc_chain,\n",
    "        token_max=4000, # í† í° ìµœëŒ€ ê°œìˆ˜ ì„¤ì •\n",
    "    )\n",
    "\n",
    "    # ìµœì¢… ì²´ì¸ ì—°ê²°\n",
    "    final_chain=MapReduceDocumentsChain(\n",
    "        llm_chain=map_chain, # ê° ë¬¸ì„œ ë§µí•‘\n",
    "        reduce_documents_chain=reduce_doc_chain,\n",
    "        document_variable_name=\"pages_content\",\n",
    "        return_intermediate_steps=False,\n",
    "    )\n",
    "    # ìµœì¢… ê²°ê³¼ ì‹¤í–‰\n",
    "    result_summary=final_chain.run(split_docs)\n",
    "    # ìš”ì•½ ê²°ê³¼ ì¶œë ¥\n",
    "    return result_summary\n",
    "\n",
    "\n",
    "import gradio as gr\n",
    "with gr.Blocks() as app:\n",
    "    with gr.Tab(\"ìŒì„± ì¸ì‹ë´‡\"):\n",
    "        with gr.Column():\n",
    "            #1\n",
    "            gr.Markdown(\n",
    "                value=\"\"\"\n",
    "                # <center>ìŒì„± ì¸ì‹ë´‡</center>\n",
    "                <center>AI ì¸ê³µì§€ëŠ¥ ë¹„ì„œ DUDE ì…ë‹ˆë‹¤.\n",
    "                ìŒì„±ìœ¼ë¡œ ë¬»ê±°ë‚˜, ë¬¸ì„œ ìš”ì•½, ì¼ì • ê´€ë¦¬ë¥¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</center>\n",
    "                \"\"\"\n",
    "            )\n",
    "            #2\n",
    "            cb_chatbot=gr.Chatbot(\n",
    "                value=[[None, \"ì•ˆë…•í•˜ì„¸ìš”, ì¸ê³µì§€ëŠ¥ ë¹„ì„œ DUDE ì…ë‹ˆë‹¤. ë¬´ì—‡ì´ë“  ì‹œì¼œë§Œ ì£¼ì„¸ìš”.\"]],\n",
    "                show_label=False\n",
    "            )\n",
    "        with gr.Row():\n",
    "            #3\n",
    "            cb_user_input=gr.Textbox(\n",
    "                lines=1,\n",
    "                placeholder=\"ì…ë ¥ ì°½\",\n",
    "                container=False,\n",
    "                scale=7\n",
    "            )\n",
    "            #4\n",
    "            cb_audio_record=gr.Audio(\n",
    "                sources=[\"microphone\"],\n",
    "                format=\"mp3\",\n",
    "                scale=1,\n",
    "                min_width=200,\n",
    "                label=\"ìŒì„±ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.\"\n",
    "            )\n",
    "            # ìŒì„± ì¶œë ¥\n",
    "            cb_audio_chatbot=gr.Audio(autoplay=True,\n",
    "                                      visible=False)\n",
    "            #5\n",
    "            cb_submit_btn=gr.Button(\n",
    "                value=\"ë³´ë‚´ê¸°\",\n",
    "                scale=1,\n",
    "                visible=\"primary\",\n",
    "                icon=\"https://cdn-icons-png.flaticon.com/128/12439/12439334.png\"\n",
    "            )\n",
    "    # ìŒì„± ë…¹ìŒ ì™„ë£Œ\n",
    "        cb_audio_record.stop_recording(\n",
    "            fn=voice_bot_handle_audio,\n",
    "            inputs=[cb_audio_record]\n",
    "        )\n",
    "    # [ë³´ë‚´ê¸°] ë²„íŠ¼ í´ë¦­\n",
    "        cb_submit_btn.click(\n",
    "            fn=voice_bot_chat,\n",
    "            inputs=[cb_user_input, cb_audio_record, cb_chatbot],\n",
    "            outputs=[cb_user_input, cb_audio_record, cb_chatbot]\n",
    "        )\n",
    "    # ENTER ì œì¶œ ì…ë ¥\n",
    "        cb_user_input.submit(\n",
    "            fn=voice_bot_chat,\n",
    "            inputs=[cb_user_input, cb_audio_record, cb_chatbot],\n",
    "            outputs=[cb_user_input, cb_audio_record, cb_chatbot]\n",
    "        )\n",
    "        with gr.Row():\n",
    "            #6\n",
    "            gr.Button(value=\"â†ªï¸ë˜ëŒë¦¬ê¸°\").click(\n",
    "                fn=voice_bot_undo,\n",
    "                inputs=[cb_chatbot],\n",
    "                outputs=[cb_chatbot]\n",
    "            )\n",
    "            #7\n",
    "            gr.Button(value=\"ğŸ”„ï¸ì´ˆê¸°í™”\").click(\n",
    "                fn=voice_bot_reset,\n",
    "                inputs=[cb_chatbot],\n",
    "                outputs=[cb_chatbot]\n",
    "            )\n",
    "    with gr.Tab(\"ë¬¸ì„œ ìš”ì•½ë´‡\"):\n",
    "        with gr.Row():\n",
    "            #1\n",
    "            gr.Markdown(\n",
    "                value=\"\"\"\n",
    "                # <center>ë¬¸ì„œ ìš”ì•½ë´‡</center>\n",
    "                <center> AI ì¸ê³µì§€ëŠ¥ ë¹„ì„œ DUDE ì…ë‹ˆë‹¤. PDFë¥¼ ì—…ë¡œë“œí•˜ë©´ ë‚´ìš©ì„ ë²ˆì—­í•´ ë“œë¦½ë‹ˆë‹¤.</center>\n",
    "                \"\"\"\n",
    "            )\n",
    "        with gr.Row():\n",
    "            #2\n",
    "            pdf_input=gr.File()\n",
    "        with gr.Row():\n",
    "            #3\n",
    "            summary_btn=gr.Button(value=\"ë¬¸ì„œ ìš”ì•½í•˜ê¸°\")\n",
    "        with gr.Row():\n",
    "            #4\n",
    "            summary=gr.Textbox(\n",
    "                label=\"PDF ìš”ì•½\",\n",
    "                lines=8,\n",
    "                placeholder=\"PDF ìš”ì•½ ë‚´ìš©ì…ë‹ˆë‹¤.\",\n",
    "            )\n",
    "            summary_btn.click(\n",
    "                fn=pdf_bot_chatbot,\n",
    "                inputs=[pdf_input],\n",
    "                outputs=[summary]\n",
    "            )\n",
    "    with gr.Tab(\"ì¼ì • ê´€ë¦¬ë´‡\"):\n",
    "        with gr.Row():\n",
    "            #1\n",
    "            gr.Markdown(\n",
    "                value=\"\"\"\n",
    "                # <center>ì¼ì • ê´€ë¦¬ë´‡</center>\n",
    "                <center> AI ì¸ê³µì§€ëŠ¥ ë¹„ì„œ DUDE ì…ë‹ˆë‹¤. ì¼ì • ê´€ë¦¬ë¥¼ ìœ„í•œ ë´‡ì…ë‹ˆë‹¤.</center>\n",
    "                \"\"\")\n",
    "        with gr.Row():\n",
    "            #2\n",
    "            chatbot_schedule=gr.Chatbot(\n",
    "                value=[\n",
    "                    [None, \"ì•ˆë…•í•˜ì„¸ìš”, ì¼ì • ì´ë¦„, ì‹œê°„, ì¼ì • ì„¤ëª…ìœ¼ë¡œ ì¼ì •ì„ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \\n\\\n",
    "                    ì˜ˆì‹œ: í¬ë¦¬ìŠ¤ë§ˆìŠ¤, 2024ë…„ 12ì›” 25ì¼ 12ì‹œ 00ë¶„, ì˜¬í•´ì˜ í¬ë¦¬ìŠ¤ë§ˆìŠ¤ ì¼ì • ì¶”ê°€í•´ ì¤˜\\n\\\n",
    "                    ì „ì²´ ì¼ì •ì´ ë³´ê³  ì‹¶ë‹¤ë©´ ì „ì²´ì¼ì • ë³´ì—¬ì¤˜ ë¼ê³  ë§í•´ ì£¼ì„¸ìš”.\"],\n",
    "                ],\n",
    "                show_label=False                    \n",
    "            )\n",
    "        with gr.Row():\n",
    "            #3\n",
    "            msg_schedule=gr.Textbox(\n",
    "                label=\"ì±„íŒ…\",\n",
    "                lines=1,\n",
    "                placeholder=\"ì±„íŒ… ì…ë ¥ ì°½\",\n",
    "                scale=8,\n",
    "            )\n",
    "            #4\n",
    "            cb_schedule_submit_btn=gr.Button(\n",
    "                value=\"ë³´ë‚´ê¸°\",\n",
    "                scale=2,\n",
    "                visible=\"primary\",\n",
    "            )\n",
    "        with gr.Row():\n",
    "            #5\n",
    "            schedule_file=gr.File(\n",
    "                label=\"ì¼ì • íŒŒì¼ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.\",\n",
    "                scale=8,\n",
    "                visible=\"primary\",\n",
    "                height=100\n",
    "            )\n",
    "            \n",
    "app.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9c3f15e-4371-42fd-b5fe-92f3facff42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7867\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7867/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.prompts import(\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.chains import LLMChain\n",
    "import os\n",
    "import openai\n",
    "\n",
    "# í™˜ê²½ë³€ìˆ˜ì—ì„œ OpenAI API í‚¤ë¥¼ ì½ì–´ì˜´.\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# API í‚¤ê°€ í™˜ê²½ë³€ìˆ˜ì— ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸.\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"í™˜ê²½ë³€ìˆ˜ 'OPENAI_API_KEY'ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# OpenAI API í‚¤ë¥¼ ì„¤ì •.\n",
    "openai.api_key = openai_api_key\n",
    "\n",
    "# OpenAI í´ë¼ì´ì–¸íŠ¸ë¥¼ ìƒì„±.\n",
    "client = openai.OpenAI()\n",
    "\n",
    "system_ai_ko = \"ë‹¹ì‹ ì€ ì¸ê³µì§€ëŠ¥ ë¹„ì„œì•¼, pdf ì¼ê¸°, ë¬¸ì„œ ìš”ì•½í•˜ê¸°, ì¼ì • ê´€ë¦¬, ë‚ ì”¨, ìµœë‹¨ ê²½ë¡œ ê²€ìƒ‰, ì›¹ ê²€ìƒ‰ ë“± ë‹¤ì–‘í•œ ë‚´ìš©ì— ë‹µë³€í•  ìˆ˜ ìˆì–´ì•¼ í•´.\"\n",
    "system_setting = SystemMessagePromptTemplate.from_template(system_ai_ko)\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ ì„¤ì •\n",
    "voice_bot_prompt = ChatPromptTemplate.from_messages([\n",
    "    system_setting,\n",
    "    MessagesPlaceholder(variable_name=\"DUDE\"),\n",
    "    HumanMessagePromptTemplate.from_template(\"{master_user}\")])\n",
    "\n",
    "# ë©”ëª¨ë¦¬ ì„¤ì •\n",
    "voice_bot_memory = ConversationBufferWindowMemory(memory_key=\"DUDE\",\n",
    "                                                  ai_prefix=\"AI ë¹„ì„œ DUDE\",\n",
    "                                                  human_prefix=\"ì‚¬ìš©ì:\",\n",
    "                                                  return_messages=True,\n",
    "                                                  k=10)\n",
    "\n",
    "# llm ëª¨ë¸ ì„¤ì •\n",
    "chatgpt = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    max_tokens=2048,\n",
    "    model_name='gpt-3.5-turbo'\n",
    ")\n",
    "\n",
    "# llmchain ì •ì˜\n",
    "conversation=LLMChain(\n",
    "    prompt=voice_bot_prompt,\n",
    "    memory=voice_bot_memory,\n",
    "    llm=chatgpt,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "from pydub import AudioSegment\n",
    "import numpy as np\n",
    "def voice_bot_handle_audio(audio_record):\n",
    "    save_file_path=\"voice.mp3\"\n",
    "    frame_rate=audio_record[0]\n",
    "    audio_data=audio_record[1].tobytes()\n",
    "    sample_width=audio_record[1].dtype.itemsize\n",
    "    audio=AudioSegment(\n",
    "        audio_data,\n",
    "        frame_rate=frame_rate,\n",
    "        sample_width=sample_width,\n",
    "        channels=1,\n",
    "    )\n",
    "    audio.export(save_file_path, format=\"mp3\")\n",
    "\n",
    "def voice_bot_create_stt():\n",
    "    file_path=\"voice.mp3\"\n",
    "    audio_file=open(file_path, \"rb\")\n",
    "    transcript=client.audio.transcriptions.create(\n",
    "        model=\"whisper-1\",\n",
    "        file=audio_file)\n",
    "    return transcript.text\n",
    "\n",
    "def voice_bot_create_audio(text):\n",
    "    response=client.audio.speech.create(\n",
    "        model=\"tts-1\",\n",
    "        voice=\"onyx\",\n",
    "        input=text)\n",
    "    speech_file_path=\"output.mp3\"\n",
    "    with open(speech_file_path, \"wb\") as audio_file:\n",
    "        audio_file.write(response.content)\n",
    "\n",
    "def voice_bot_chat(message, cb_user_input_audio, chat_history):\n",
    "    if cb_user_input_audio:\n",
    "        message=voice_bot_create_stt()\n",
    "    ai_answer=conversation({\"master_user\":message})['text']\n",
    "    chat_history.append((message, ai_answer))\n",
    "    audio_file=voice_bot_create_audio(ai_answer)\n",
    "    return \"\", audio_file, chat_history\n",
    "\n",
    "def voice_bot_undo(chat_history):\n",
    "    if len(chat_history) > 1:\n",
    "        chat_history.pop()\n",
    "    return chat_history\n",
    "\n",
    "def voice_bot_reset(chat_history):\n",
    "    global voice_bot_memory\n",
    "    chat_init=[[None, \"ì•ˆë…•í•˜ì„¸ìš”, ì¸ê³µì§€ëŠ¥ ë¹„ì„œ DUDE ì…ë‹ˆë‹¤. ë¬´ì—‡ì´ë“  ì‹œì¼œë§Œ ì£¼ì„¸ìš”.\"]]\n",
    "    voice_bot_memory.clear() # ë©”ëª¨ë¦¬ ì´ˆê¸°í™”\n",
    "    return \"\", chat_init\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import MapReduceDocumentsChain\n",
    "\n",
    "def pdf_loader(pdf_path):\n",
    "    loader=PyPDFLoader(pdf_path)\n",
    "    pdf_doc=loader.load()\n",
    "    return pdf_doc\n",
    "\n",
    "def pdf_bot_chatbot(pdf_path):\n",
    "    pages_content=pdf_loader(pdf_path)\n",
    "    text_splitter=RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=3000,\n",
    "        chunk_overlap=0,\n",
    "    )\n",
    "    # pages_content ë‚´ìš© ë¶„í• \n",
    "    split_docs=text_splitter.split_documents(pages_content)\n",
    "    # ë¶„í• ëœ ë¬¸ì„œì˜ ìˆ˜\n",
    "    # map template ì„¤ì •, {pages_content} ë¶„í• ëœ ë‚´ìš©ì´ ì…ë ¥\n",
    "    map_template=\"\"\" ë‹¤ìŒì€ ë¬¸ì„œ ì¤‘ ì¼ë¶€ ë‚´ìš©ì…ë‹ˆë‹¤.\n",
    "    {pages_content}\n",
    "    ì´ ë¬¸ì„œì˜ ì£¼ìš” ë‚´ìš©ì„ ìš”ì•½í•´ ì£¼ì„¸ìš”.\n",
    "    \"\"\"\n",
    "    # map ê¸°ë³¸ í”„ë¡¬í”„íŠ¸\n",
    "    map_prompt=PromptTemplate.from_template(map_template)\n",
    "    # ë¬¸ì„œ ë‚´ìš©ì´ ê¸¸ ìˆ˜ ìˆê¸° ë•Œë¬¸ì— modelì„ gpt-3.5-turbo-16kë¡œ ì„¤ì •\n",
    "    llm=ChatOpenAI(temperate=0,\n",
    "                   model_name='gpt-3.5-turbo-16k')\n",
    "    map_chain=LLMChain(llm=llm, prompt=map_prompt)\n",
    "\n",
    "    # reduce ë‹¨ê³„ì—ì„œ ì²˜ë¦¬í•  í”„ë¡¬í”„íŠ¸ ì •ì˜\n",
    "    reduce_template=\"\"\"ë‹¤ìŒì€ ë¬¸ì„œ ìš”ì•½ì˜ ì§‘í•©ì…ë‹ˆë‹¤.\n",
    "    {summaries}\n",
    "    ì´ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ í†µí•©ëœ ë¬¸ì„œ ìš”ì•½ì„ ì‘ì„±í•´ ì£¼ì„¸ìš”.\n",
    "    \"\"\"\n",
    "    # reduce í”„ë¡¬í”„íŠ¸\n",
    "    reduce_prompt=PromptTemplate.from_template(reduce_template)\n",
    "\n",
    "    # reduceì—ì„œ ìˆ˜í–‰í•  LLMChain ì •ì˜\n",
    "    reduce_chain=LLMChain(llm=llm, prompt=reduce_prompt)\n",
    "    from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "    from langchain.chains import ReduceDocumentsChain\n",
    "\n",
    "    # ë¬¸ì„œ ëª©ë¡ í†µí•© ì²´ì¸ ì„¤ì •\n",
    "    combine_doc_chain=StuffDocumentsChain(\n",
    "        llm_chain=reduce_chain,\n",
    "        document_variable_name=\"summaries\" # reduce í”„ë¡¬í”„íŠ¸ì— ëŒ€ì…ë˜ëŠ” ë³€ìˆ˜\n",
    "    )\n",
    "\n",
    "    # ë¶„í• ëœ ë¬¸ì„œ ìˆœì°¨ì ìœ¼ë¡œ Reduce ì²˜ë¦¬\n",
    "    reduce_doc_chain=ReduceDocumentsChain(\n",
    "        combine_documents_chain=combine_doc_chain,\n",
    "        collapse_documents_chain=combine_doc_chain,\n",
    "        token_max=4000, # í† í° ìµœëŒ€ ê°œìˆ˜ ì„¤ì •\n",
    "    )\n",
    "\n",
    "    # ìµœì¢… ì²´ì¸ ì—°ê²°\n",
    "    final_chain=MapReduceDocumentsChain(\n",
    "        llm_chain=map_chain, # ê° ë¬¸ì„œ ë§µí•‘\n",
    "        reduce_documents_chain=reduce_doc_chain,\n",
    "        document_variable_name=\"pages_content\",\n",
    "        return_intermediate_steps=False,\n",
    "    )\n",
    "    # ìµœì¢… ê²°ê³¼ ì‹¤í–‰\n",
    "    result_summary=final_chain.run(split_docs)\n",
    "    # ìš”ì•½ ê²°ê³¼ ì¶œë ¥\n",
    "    return result_summary\n",
    "\n",
    "system_schedule_ko=\"\"\"ì¼ì • ê´€ë¦¬ì— ëŒ€í•œ ì‚¬ìš©ì ì…ë ¥ì´ ì£¼ì–´ì§‘ë‹ˆë‹¤.\n",
    "'schedule_type,' 'schedule_content,' 'schedule_content_detail,' 'year,'\n",
    "'month,' 'day,' 'hour,' ë° 'min'ê³¼ ê°™ì€ êµ¬ì„± ìš”ì†Œê°€ ìˆìŠµë‹ˆë‹¤.\n",
    "'schedule_type'ì€ ì¡°íšŒ, ì‚­ì œ, ì¶”ê°€, ì—…ë°ì´íŠ¸ ì¤‘ í•˜ë‚˜ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "'year,' 'month,' 'day,' 'hour,' ë° 'min'ì— ëŒ€í•œ ê°’ì€ ìˆ«ìì—¬ì•¼ í•©ë‹ˆë‹¤.\n",
    "'schedule_content,' 'schedule_content_detail,' 'year,' 'month,' 'day,' 'hour,' ë° 'min'ì— ëŒ€í•œ ì…ë ¥ì€\n",
    "json ë¬¸ìì—´ í˜•ì‹ìœ¼ë¡œ ì´ë£¨ì–´ì ¸ì•¼ í•©ë‹ˆë‹¤.\"\"\"\n",
    "system_setting_schedule=SystemMessagePromptTemplate.from_template(system_schedule_ko)\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ ì„¤ì •\n",
    "schedule_prompt=ChatPromptTemplate.from_messages([\n",
    "    system_setting_schedule,\n",
    "    MessagesPlaceholder(variable_name=\"DUDE_schedule\"),\n",
    "    HumanMessagePromptTemplate.from_template(\"{master_user}\"),\n",
    "])\n",
    "\n",
    "# ë©”ëª¨ë¦¬ ì„¤ì •\n",
    "schedule_memory=ConversationBufferWindowMemory(\n",
    "    memory_key=\"DUDE_schedule\",\n",
    "    ai_prefix=\"AI ë¹„ì„œ DUDE schedule\",\n",
    "    human_prefix=\"ì‚¬ìš©ì\",\n",
    "    return_messages=True,\n",
    "    k=10\n",
    ")\n",
    "\n",
    "# llm ëª¨ë¸ ì •ì˜\n",
    "chatgpt=ChatOpenAI(\n",
    "    temperature=0,\n",
    "    max_tokens=2048,\n",
    "    model_name=\"gpt-3.5-turbo\"\n",
    ")\n",
    "\n",
    "# llmchain ì •ì˜\n",
    "conversation_schdule=LLMChain(\n",
    "    llm=chatgpt, # LLM\n",
    "    prompt=schedule_prompt,\n",
    "    verbose=True, # True ë¡œ ì„¤ì • ì‹œ ë¡œê·¸ ì¶œë ¥\n",
    "    memory=schedule_memory\n",
    ")\n",
    "\n",
    "\n",
    "import gradio as gr\n",
    "with gr.Blocks() as app:\n",
    "    with gr.Tab(\"ìŒì„± ì¸ì‹ë´‡\"):\n",
    "        with gr.Column():\n",
    "            #1\n",
    "            gr.Markdown(\n",
    "                value=\"\"\"\n",
    "                # <center>ìŒì„± ì¸ì‹ë´‡</center>\n",
    "                <center>AI ì¸ê³µì§€ëŠ¥ ë¹„ì„œ DUDE ì…ë‹ˆë‹¤.\n",
    "                ìŒì„±ìœ¼ë¡œ ë¬»ê±°ë‚˜, ë¬¸ì„œ ìš”ì•½, ì¼ì • ê´€ë¦¬ë¥¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</center>\n",
    "                \"\"\"\n",
    "            )\n",
    "            #2\n",
    "            cb_chatbot=gr.Chatbot(\n",
    "                value=[[None, \"ì•ˆë…•í•˜ì„¸ìš”, ì¸ê³µì§€ëŠ¥ ë¹„ì„œ DUDE ì…ë‹ˆë‹¤. ë¬´ì—‡ì´ë“  ì‹œì¼œë§Œ ì£¼ì„¸ìš”.\"]],\n",
    "                show_label=False\n",
    "            )\n",
    "        with gr.Row():\n",
    "            #3\n",
    "            cb_user_input=gr.Textbox(\n",
    "                lines=1,\n",
    "                placeholder=\"ì…ë ¥ ì°½\",\n",
    "                container=False,\n",
    "                scale=7\n",
    "            )\n",
    "            #4\n",
    "            cb_audio_record=gr.Audio(\n",
    "                sources=[\"microphone\"],\n",
    "                format=\"mp3\",\n",
    "                scale=1,\n",
    "                min_width=200,\n",
    "                label=\"ìŒì„±ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.\"\n",
    "            )\n",
    "            # ìŒì„± ì¶œë ¥\n",
    "            cb_audio_chatbot=gr.Audio(autoplay=True,\n",
    "                                      visible=False)\n",
    "            #5\n",
    "            cb_submit_btn=gr.Button(\n",
    "                value=\"ë³´ë‚´ê¸°\",\n",
    "                scale=1,\n",
    "                visible=\"primary\",\n",
    "                icon=\"https://cdn-icons-png.flaticon.com/128/12439/12439334.png\"\n",
    "            )\n",
    "    # ìŒì„± ë…¹ìŒ ì™„ë£Œ\n",
    "        cb_audio_record.stop_recording(\n",
    "            fn=voice_bot_handle_audio,\n",
    "            inputs=[cb_audio_record]\n",
    "        )\n",
    "    # [ë³´ë‚´ê¸°] ë²„íŠ¼ í´ë¦­\n",
    "        cb_submit_btn.click(\n",
    "            fn=voice_bot_chat,\n",
    "            inputs=[cb_user_input, cb_audio_record, cb_chatbot],\n",
    "            outputs=[cb_user_input, cb_audio_record, cb_chatbot]\n",
    "        )\n",
    "    # ENTER ì œì¶œ ì…ë ¥\n",
    "        cb_user_input.submit(\n",
    "            fn=voice_bot_chat,\n",
    "            inputs=[cb_user_input, cb_audio_record, cb_chatbot],\n",
    "            outputs=[cb_user_input, cb_audio_record, cb_chatbot]\n",
    "        )\n",
    "        with gr.Row():\n",
    "            #6\n",
    "            gr.Button(value=\"â†ªï¸ë˜ëŒë¦¬ê¸°\").click(\n",
    "                fn=voice_bot_undo,\n",
    "                inputs=[cb_chatbot],\n",
    "                outputs=[cb_chatbot]\n",
    "            )\n",
    "            #7\n",
    "            gr.Button(value=\"ğŸ”„ï¸ì´ˆê¸°í™”\").click(\n",
    "                fn=voice_bot_reset,\n",
    "                inputs=[cb_chatbot],\n",
    "                outputs=[cb_chatbot]\n",
    "            )\n",
    "    with gr.Tab(\"ë¬¸ì„œ ìš”ì•½ë´‡\"):\n",
    "        with gr.Row():\n",
    "            #1\n",
    "            gr.Markdown(\n",
    "                value=\"\"\"\n",
    "                # <center>ë¬¸ì„œ ìš”ì•½ë´‡</center>\n",
    "                <center> AI ì¸ê³µì§€ëŠ¥ ë¹„ì„œ DUDE ì…ë‹ˆë‹¤. PDFë¥¼ ì—…ë¡œë“œí•˜ë©´ ë‚´ìš©ì„ ë²ˆì—­í•´ ë“œë¦½ë‹ˆë‹¤.</center>\n",
    "                \"\"\"\n",
    "            )\n",
    "        with gr.Row():\n",
    "            #2\n",
    "            pdf_input=gr.File()\n",
    "        with gr.Row():\n",
    "            #3\n",
    "            summary_btn=gr.Button(value=\"ë¬¸ì„œ ìš”ì•½í•˜ê¸°\")\n",
    "        with gr.Row():\n",
    "            #4\n",
    "            summary=gr.Textbox(\n",
    "                label=\"PDF ìš”ì•½\",\n",
    "                lines=8,\n",
    "                placeholder=\"PDF ìš”ì•½ ë‚´ìš©ì…ë‹ˆë‹¤.\",\n",
    "            )\n",
    "            summary_btn.click(\n",
    "                fn=pdf_bot_chatbot,\n",
    "                inputs=[pdf_input],\n",
    "                outputs=[summary]\n",
    "            )\n",
    "    with gr.Tab(\"ì¼ì • ê´€ë¦¬ë´‡\"):\n",
    "        with gr.Row():\n",
    "            #1\n",
    "            gr.Markdown(\n",
    "                value=\"\"\"\n",
    "                # <center>ì¼ì • ê´€ë¦¬ë´‡</center>\n",
    "                <center> AI ì¸ê³µì§€ëŠ¥ ë¹„ì„œ DUDE ì…ë‹ˆë‹¤. ì¼ì • ê´€ë¦¬ë¥¼ ìœ„í•œ ë´‡ì…ë‹ˆë‹¤.</center>\n",
    "                \"\"\")\n",
    "        with gr.Row():\n",
    "            #2\n",
    "            chatbot_schedule=gr.Chatbot(\n",
    "                value=[\n",
    "                    [None, \"ì•ˆë…•í•˜ì„¸ìš”, ì¼ì • ì´ë¦„, ì‹œê°„, ì¼ì • ì„¤ëª…ìœ¼ë¡œ ì¼ì •ì„ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \\n\\\n",
    "                    ì˜ˆì‹œ: í¬ë¦¬ìŠ¤ë§ˆìŠ¤, 2024ë…„ 12ì›” 25ì¼ 12ì‹œ 00ë¶„, ì˜¬í•´ì˜ í¬ë¦¬ìŠ¤ë§ˆìŠ¤ ì¼ì • ì¶”ê°€í•´ ì¤˜\\n\\\n",
    "                    ì „ì²´ ì¼ì •ì´ ë³´ê³  ì‹¶ë‹¤ë©´ ì „ì²´ì¼ì • ë³´ì—¬ì¤˜ ë¼ê³  ë§í•´ ì£¼ì„¸ìš”.\"],\n",
    "                ],\n",
    "                show_label=False                    \n",
    "            )\n",
    "        with gr.Row():\n",
    "            #3\n",
    "            msg_schedule=gr.Textbox(\n",
    "                label=\"ì±„íŒ…\",\n",
    "                lines=1,\n",
    "                placeholder=\"ì±„íŒ… ì…ë ¥ ì°½\",\n",
    "                scale=8,\n",
    "            )\n",
    "            #4\n",
    "            cb_schedule_submit_btn=gr.Button(\n",
    "                value=\"ë³´ë‚´ê¸°\",\n",
    "                scale=2,\n",
    "                visible=\"primary\",\n",
    "            )\n",
    "        with gr.Row():\n",
    "            #5\n",
    "            schedule_file=gr.File(\n",
    "                label=\"ì¼ì • íŒŒì¼ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.\",\n",
    "                scale=8,\n",
    "                visible=\"primary\",\n",
    "                height=100\n",
    "            )\n",
    "            \n",
    "app.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d9f7d03-c392-438f-89f3-787e34d58ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7871\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7871/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: ì¼ì • ê´€ë¦¬ì— ëŒ€í•œ ì‚¬ìš©ì ì…ë ¥ì´ ì£¼ì–´ì§‘ë‹ˆë‹¤.\n",
      "'schedule_type,' 'schedule_content,' 'schedule_content_detail,' 'year,'\n",
      "'month,' 'day,' 'hour,' ë° 'min'ê³¼ ê°™ì€ êµ¬ì„± ìš”ì†Œê°€ ìˆìŠµë‹ˆë‹¤.\n",
      "'schedule_type'ì€ ì¡°íšŒ, ì‚­ì œ, ì¶”ê°€, ì—…ë°ì´íŠ¸ ì¤‘ í•˜ë‚˜ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "'year,' 'month,' 'day,' 'hour,' ë° 'min'ì— ëŒ€í•œ ê°’ì€ ìˆ«ìì—¬ì•¼ í•©ë‹ˆë‹¤.\n",
      "'schedule_content,' 'schedule_content_detail,' 'year,' 'month,' 'day,' 'hour,' ë° 'min'ì— ëŒ€í•œ ì…ë ¥ì€\n",
      "json ë¬¸ìì—´ í˜•ì‹ìœ¼ë¡œ ì´ë£¨ì–´ì ¸ì•¼ í•©ë‹ˆë‹¤.\n",
      "Human: 2025ë…„ 1ì›” 1ì¼ 13ì‹œ 00ë¶„ ê°€ì¡±ë“¤ ì§‘ë“¤ì´ ì¼ì • ì¶”ê°€í•´ì¤˜\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: ì¼ì • ê´€ë¦¬ì— ëŒ€í•œ ì‚¬ìš©ì ì…ë ¥ì´ ì£¼ì–´ì§‘ë‹ˆë‹¤.\n",
      "'schedule_type,' 'schedule_content,' 'schedule_content_detail,' 'year,'\n",
      "'month,' 'day,' 'hour,' ë° 'min'ê³¼ ê°™ì€ êµ¬ì„± ìš”ì†Œê°€ ìˆìŠµë‹ˆë‹¤.\n",
      "'schedule_type'ì€ ì¡°íšŒ, ì‚­ì œ, ì¶”ê°€, ì—…ë°ì´íŠ¸ ì¤‘ í•˜ë‚˜ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "'year,' 'month,' 'day,' 'hour,' ë° 'min'ì— ëŒ€í•œ ê°’ì€ ìˆ«ìì—¬ì•¼ í•©ë‹ˆë‹¤.\n",
      "'schedule_content,' 'schedule_content_detail,' 'year,' 'month,' 'day,' 'hour,' ë° 'min'ì— ëŒ€í•œ ì…ë ¥ì€\n",
      "json ë¬¸ìì—´ í˜•ì‹ìœ¼ë¡œ ì´ë£¨ì–´ì ¸ì•¼ í•©ë‹ˆë‹¤.\n",
      "Human: 2025ë…„ 1ì›” 1ì¼ 13ì‹œ 00ë¶„ ê°€ì¡±ë“¤ ì§‘ë“¤ì´ ì¼ì • ì¶”ê°€í•´ì¤˜\n",
      "AI: {\n",
      "  \"schedule_type\": \"ì¶”ê°€\",\n",
      "  \"schedule_content\": \"ê°€ì¡±ë“¤ ì§‘ë“¤ì´\",\n",
      "  \"schedule_content_detail\": \"\",\n",
      "  \"year\": 2025,\n",
      "  \"month\": 1,\n",
      "  \"day\": 1,\n",
      "  \"hour\": 13,\n",
      "  \"min\": 0\n",
      "}\n",
      "Human: 2024ë…„ 12ì›” 24ì¼ ì˜¤í›„ 2ì‹œ 30ë¶„ ë³‘ì› ë°©ë¬¸ ì¼ì •ë„ ì¶”ê°€í•´ì¤˜\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: ì¼ì • ê´€ë¦¬ì— ëŒ€í•œ ì‚¬ìš©ì ì…ë ¥ì´ ì£¼ì–´ì§‘ë‹ˆë‹¤.\n",
      "'schedule_type,' 'schedule_content,' 'schedule_content_detail,' 'year,'\n",
      "'month,' 'day,' 'hour,' ë° 'min'ê³¼ ê°™ì€ êµ¬ì„± ìš”ì†Œê°€ ìˆìŠµë‹ˆë‹¤.\n",
      "'schedule_type'ì€ ì¡°íšŒ, ì‚­ì œ, ì¶”ê°€, ì—…ë°ì´íŠ¸ ì¤‘ í•˜ë‚˜ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "'year,' 'month,' 'day,' 'hour,' ë° 'min'ì— ëŒ€í•œ ê°’ì€ ìˆ«ìì—¬ì•¼ í•©ë‹ˆë‹¤.\n",
      "'schedule_content,' 'schedule_content_detail,' 'year,' 'month,' 'day,' 'hour,' ë° 'min'ì— ëŒ€í•œ ì…ë ¥ì€\n",
      "json ë¬¸ìì—´ í˜•ì‹ìœ¼ë¡œ ì´ë£¨ì–´ì ¸ì•¼ í•©ë‹ˆë‹¤.\n",
      "Human: 2025ë…„ 1ì›” 1ì¼ 13ì‹œ 00ë¶„ ê°€ì¡±ë“¤ ì§‘ë“¤ì´ ì¼ì • ì¶”ê°€í•´ì¤˜\n",
      "AI: {\n",
      "  \"schedule_type\": \"ì¶”ê°€\",\n",
      "  \"schedule_content\": \"ê°€ì¡±ë“¤ ì§‘ë“¤ì´\",\n",
      "  \"schedule_content_detail\": \"\",\n",
      "  \"year\": 2025,\n",
      "  \"month\": 1,\n",
      "  \"day\": 1,\n",
      "  \"hour\": 13,\n",
      "  \"min\": 0\n",
      "}\n",
      "Human: 2024ë…„ 12ì›” 24ì¼ ì˜¤í›„ 2ì‹œ 30ë¶„ ë³‘ì› ë°©ë¬¸ ì¼ì •ë„ ì¶”ê°€í•´ì¤˜\n",
      "AI: {\n",
      "  \"schedule_type\": \"ì¶”ê°€\",\n",
      "  \"schedule_content\": \"ë³‘ì› ë°©ë¬¸\",\n",
      "  \"schedule_content_detail\": \"\",\n",
      "  \"year\": 2024,\n",
      "  \"month\": 12,\n",
      "  \"day\": 24,\n",
      "  \"hour\": 14,\n",
      "  \"min\": 30\n",
      "}\n",
      "Human: ì „ì²´ ì¼ì •ì„ ë³´ì—¬ì¤˜\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.prompts import(\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.chains import LLMChain\n",
    "import os\n",
    "import openai\n",
    "\n",
    "# í™˜ê²½ë³€ìˆ˜ì—ì„œ OpenAI API í‚¤ë¥¼ ì½ì–´ì˜´.\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# API í‚¤ê°€ í™˜ê²½ë³€ìˆ˜ì— ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸.\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"í™˜ê²½ë³€ìˆ˜ 'OPENAI_API_KEY'ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# OpenAI API í‚¤ë¥¼ ì„¤ì •.\n",
    "openai.api_key = openai_api_key\n",
    "\n",
    "# OpenAI í´ë¼ì´ì–¸íŠ¸ë¥¼ ìƒì„±.\n",
    "client = openai.OpenAI()\n",
    "\n",
    "system_ai_ko = \"ë‹¹ì‹ ì€ ì¸ê³µì§€ëŠ¥ ë¹„ì„œì•¼, pdf ì¼ê¸°, ë¬¸ì„œ ìš”ì•½í•˜ê¸°, ì¼ì • ê´€ë¦¬, ë‚ ì”¨, ìµœë‹¨ ê²½ë¡œ ê²€ìƒ‰, ì›¹ ê²€ìƒ‰ ë“± ë‹¤ì–‘í•œ ë‚´ìš©ì— ë‹µë³€í•  ìˆ˜ ìˆì–´ì•¼ í•´.\"\n",
    "system_setting = SystemMessagePromptTemplate.from_template(system_ai_ko)\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ ì„¤ì •\n",
    "voice_bot_prompt = ChatPromptTemplate.from_messages([\n",
    "    system_setting,\n",
    "    MessagesPlaceholder(variable_name=\"DUDE\"),\n",
    "    HumanMessagePromptTemplate.from_template(\"{master_user}\")])\n",
    "\n",
    "# ë©”ëª¨ë¦¬ ì„¤ì •\n",
    "voice_bot_memory = ConversationBufferWindowMemory(memory_key=\"DUDE\",\n",
    "                                                  ai_prefix=\"AI ë¹„ì„œ DUDE\",\n",
    "                                                  human_prefix=\"ì‚¬ìš©ì:\",\n",
    "                                                  return_messages=True,\n",
    "                                                  k=10)\n",
    "\n",
    "# llm ëª¨ë¸ ì„¤ì •\n",
    "chatgpt = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    max_tokens=2048,\n",
    "    model_name='gpt-3.5-turbo'\n",
    ")\n",
    "\n",
    "# llmchain ì •ì˜\n",
    "conversation=LLMChain(\n",
    "    prompt=voice_bot_prompt,\n",
    "    memory=voice_bot_memory,\n",
    "    llm=chatgpt,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "from pydub import AudioSegment\n",
    "import numpy as np\n",
    "def voice_bot_handle_audio(audio_record):\n",
    "    save_file_path=\"voice.mp3\"\n",
    "    frame_rate=audio_record[0]\n",
    "    audio_data=audio_record[1].tobytes()\n",
    "    sample_width=audio_record[1].dtype.itemsize\n",
    "    audio=AudioSegment(\n",
    "        audio_data,\n",
    "        frame_rate=frame_rate,\n",
    "        sample_width=sample_width,\n",
    "        channels=1,\n",
    "    )\n",
    "    audio.export(save_file_path, format=\"mp3\")\n",
    "\n",
    "def voice_bot_create_stt():\n",
    "    file_path=\"voice.mp3\"\n",
    "    audio_file=open(file_path, \"rb\")\n",
    "    transcript=client.audio.transcriptions.create(\n",
    "        model=\"whisper-1\",\n",
    "        file=audio_file)\n",
    "    return transcript.text\n",
    "\n",
    "def voice_bot_create_audio(text):\n",
    "    response=client.audio.speech.create(\n",
    "        model=\"tts-1\",\n",
    "        voice=\"onyx\",\n",
    "        input=text)\n",
    "    speech_file_path=\"output.mp3\"\n",
    "    with open(speech_file_path, \"wb\") as audio_file:\n",
    "        audio_file.write(response.content)\n",
    "\n",
    "def voice_bot_chat(message, cb_user_input_audio, chat_history):\n",
    "    if cb_user_input_audio:\n",
    "        message=voice_bot_create_stt()\n",
    "    ai_answer=conversation({\"master_user\":message})['text']\n",
    "    chat_history.append((message, ai_answer))\n",
    "    audio_file=voice_bot_create_audio(ai_answer)\n",
    "    return \"\", audio_file, chat_history\n",
    "\n",
    "def voice_bot_undo(chat_history):\n",
    "    if len(chat_history) > 1:\n",
    "        chat_history.pop()\n",
    "    return chat_history\n",
    "\n",
    "def voice_bot_reset(chat_history):\n",
    "    global voice_bot_memory\n",
    "    chat_init=[[None, \"ì•ˆë…•í•˜ì„¸ìš”, ì¸ê³µì§€ëŠ¥ ë¹„ì„œ DUDE ì…ë‹ˆë‹¤. ë¬´ì—‡ì´ë“  ì‹œì¼œë§Œ ì£¼ì„¸ìš”.\"]]\n",
    "    voice_bot_memory.clear() # ë©”ëª¨ë¦¬ ì´ˆê¸°í™”\n",
    "    return \"\", chat_init\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import MapReduceDocumentsChain\n",
    "\n",
    "def pdf_loader(pdf_path):\n",
    "    loader=PyPDFLoader(pdf_path)\n",
    "    pdf_doc=loader.load()\n",
    "    return pdf_doc\n",
    "\n",
    "def pdf_bot_chatbot(pdf_path):\n",
    "    pages_content=pdf_loader(pdf_path)\n",
    "    text_splitter=RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=3000,\n",
    "        chunk_overlap=0,\n",
    "    )\n",
    "    # pages_content ë‚´ìš© ë¶„í• \n",
    "    split_docs=text_splitter.split_documents(pages_content)\n",
    "    # ë¶„í• ëœ ë¬¸ì„œì˜ ìˆ˜\n",
    "    # map template ì„¤ì •, {pages_content} ë¶„í• ëœ ë‚´ìš©ì´ ì…ë ¥\n",
    "    map_template=\"\"\" ë‹¤ìŒì€ ë¬¸ì„œ ì¤‘ ì¼ë¶€ ë‚´ìš©ì…ë‹ˆë‹¤.\n",
    "    {pages_content}\n",
    "    ì´ ë¬¸ì„œì˜ ì£¼ìš” ë‚´ìš©ì„ ìš”ì•½í•´ ì£¼ì„¸ìš”.\n",
    "    \"\"\"\n",
    "    # map ê¸°ë³¸ í”„ë¡¬í”„íŠ¸\n",
    "    map_prompt=PromptTemplate.from_template(map_template)\n",
    "    # ë¬¸ì„œ ë‚´ìš©ì´ ê¸¸ ìˆ˜ ìˆê¸° ë•Œë¬¸ì— modelì„ gpt-3.5-turbo-16kë¡œ ì„¤ì •\n",
    "    llm=ChatOpenAI(temperature=0,\n",
    "                   model_name='gpt-3.5-turbo-16k')\n",
    "    map_chain=LLMChain(llm=llm, prompt=map_prompt)\n",
    "\n",
    "    # reduce ë‹¨ê³„ì—ì„œ ì²˜ë¦¬í•  í”„ë¡¬í”„íŠ¸ ì •ì˜\n",
    "    reduce_template=\"\"\"ë‹¤ìŒì€ ë¬¸ì„œ ìš”ì•½ì˜ ì§‘í•©ì…ë‹ˆë‹¤.\n",
    "    {summaries}\n",
    "    ì´ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ í†µí•©ëœ ë¬¸ì„œ ìš”ì•½ì„ ì‘ì„±í•´ ì£¼ì„¸ìš”.\n",
    "    \"\"\"\n",
    "    # reduce í”„ë¡¬í”„íŠ¸\n",
    "    reduce_prompt=PromptTemplate.from_template(reduce_template)\n",
    "\n",
    "    # reduceì—ì„œ ìˆ˜í–‰í•  LLMChain ì •ì˜\n",
    "    reduce_chain=LLMChain(llm=llm, prompt=reduce_prompt)\n",
    "    from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "    from langchain.chains import ReduceDocumentsChain\n",
    "\n",
    "    # ë¬¸ì„œ ëª©ë¡ í†µí•© ì²´ì¸ ì„¤ì •\n",
    "    combine_doc_chain=StuffDocumentsChain(\n",
    "        llm_chain=reduce_chain,\n",
    "        document_variable_name=\"summaries\" # reduce í”„ë¡¬í”„íŠ¸ì— ëŒ€ì…ë˜ëŠ” ë³€ìˆ˜\n",
    "    )\n",
    "\n",
    "    # ë¶„í• ëœ ë¬¸ì„œ ìˆœì°¨ì ìœ¼ë¡œ Reduce ì²˜ë¦¬\n",
    "    reduce_doc_chain=ReduceDocumentsChain(\n",
    "        combine_documents_chain=combine_doc_chain,\n",
    "        collapse_documents_chain=combine_doc_chain,\n",
    "        token_max=4000, # í† í° ìµœëŒ€ ê°œìˆ˜ ì„¤ì •\n",
    "    )\n",
    "\n",
    "    # ìµœì¢… ì²´ì¸ ì—°ê²°\n",
    "    final_chain=MapReduceDocumentsChain(\n",
    "        llm_chain=map_chain, # ê° ë¬¸ì„œ ë§µí•‘\n",
    "        reduce_documents_chain=reduce_doc_chain,\n",
    "        document_variable_name=\"pages_content\",\n",
    "        return_intermediate_steps=False,\n",
    "    )\n",
    "    # ìµœì¢… ê²°ê³¼ ì‹¤í–‰\n",
    "    result_summary=final_chain.run(split_docs)\n",
    "    # ìš”ì•½ ê²°ê³¼ ì¶œë ¥\n",
    "    return result_summary\n",
    "\n",
    "system_schedule_ko=\"\"\"ì¼ì • ê´€ë¦¬ì— ëŒ€í•œ ì‚¬ìš©ì ì…ë ¥ì´ ì£¼ì–´ì§‘ë‹ˆë‹¤.\n",
    "'schedule_type,' 'schedule_content,' 'schedule_content_detail,' 'year,'\n",
    "'month,' 'day,' 'hour,' ë° 'min'ê³¼ ê°™ì€ êµ¬ì„± ìš”ì†Œê°€ ìˆìŠµë‹ˆë‹¤.\n",
    "'schedule_type'ì€ ì¡°íšŒ, ì‚­ì œ, ì¶”ê°€, ì—…ë°ì´íŠ¸ ì¤‘ í•˜ë‚˜ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "'year,' 'month,' 'day,' 'hour,' ë° 'min'ì— ëŒ€í•œ ê°’ì€ ìˆ«ìì—¬ì•¼ í•©ë‹ˆë‹¤.\n",
    "'schedule_content,' 'schedule_content_detail,' 'year,' 'month,' 'day,' 'hour,' ë° 'min'ì— ëŒ€í•œ ì…ë ¥ì€\n",
    "json ë¬¸ìì—´ í˜•ì‹ìœ¼ë¡œ ì´ë£¨ì–´ì ¸ì•¼ í•©ë‹ˆë‹¤.\"\"\"\n",
    "system_setting_schedule=SystemMessagePromptTemplate.from_template(system_schedule_ko)\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ ì„¤ì •\n",
    "schedule_prompt=ChatPromptTemplate.from_messages([\n",
    "    system_setting_schedule,\n",
    "    MessagesPlaceholder(variable_name=\"DUDE_schedule\"),\n",
    "    HumanMessagePromptTemplate.from_template(\"{master_user}\"),\n",
    "])\n",
    "\n",
    "# ë©”ëª¨ë¦¬ ì„¤ì •\n",
    "schedule_memory=ConversationBufferWindowMemory(\n",
    "    memory_key=\"DUDE_schedule\",\n",
    "    ai_prefix=\"AI ë¹„ì„œ DUDE schedule\",\n",
    "    human_prefix=\"ì‚¬ìš©ì\",\n",
    "    return_messages=True,\n",
    "    k=10\n",
    ")\n",
    "\n",
    "# llm ëª¨ë¸ ì •ì˜\n",
    "chatgpt=ChatOpenAI(\n",
    "    temperature=0,\n",
    "    max_tokens=2048,\n",
    "    model_name=\"gpt-3.5-turbo\"\n",
    ")\n",
    "\n",
    "# llmchain ì •ì˜\n",
    "conversation_schedule=LLMChain(\n",
    "    llm=chatgpt, # LLM\n",
    "    prompt=schedule_prompt,\n",
    "    verbose=True, # True ë¡œ ì„¤ì • ì‹œ ë¡œê·¸ ì¶œë ¥\n",
    "    memory=schedule_memory\n",
    ")\n",
    "\n",
    "# ì¼ì • ê´€ë¦¬ excel íŒŒì¼ ê´€ë¦¬\n",
    "import pandas as pd\n",
    "# ì²˜ìŒ íŒŒì¼ ìƒì„±\n",
    "initial_df=pd.DataFrame(columns=[\n",
    "    \"schedule_type\",\n",
    "    \"schedule_content\",\n",
    "    \"schedule_content_detail\",\n",
    "    \"year\",\n",
    "    \"month\",\n",
    "    \"day\",\n",
    "    \"hour\",\n",
    "    \"min\"\n",
    "])\n",
    "excel_file_path=\"schedule.xlsx\"\n",
    "initial_df.to_excel(excel_file_path, index=False)\n",
    "\n",
    "def schedule_bot_save(submit_file):\n",
    "    temp_excel_file=pd.read_excel(submit_file)\n",
    "    temp_excel_file.to_excel(excel_file_path, index=False)\n",
    "\n",
    "import json\n",
    "def schedule_bot_chat(message, chat_history):\n",
    "    answer=conversation_schedule({\"master_user\": message})\n",
    "    ai_answer=answer['text']\n",
    "\n",
    "    try:\n",
    "        schedule_dic=json.loads(ai_answer)\n",
    "        if schedule_dic[\"schedule_type\"] == \"ì¶”ê°€\":\n",
    "            schedule_df=pd.read_excel(excel_file_path)\n",
    "            schedule_df=pd.concat([schedule_df, pd.DataFrame([schedule_dic])],\n",
    "                                  ignore_index=True)\n",
    "            schedule_df.to_excel(excel_file_path, index=False)\n",
    "            chat_history.append([message, f\"{schedule_dic['schedule_content']}_ì¼ì •ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.\"])\n",
    "        elif schedule_dic[\"schedule_type\"] == \"ì¡°íšŒ\":\n",
    "            schedule_df=[]\n",
    "            if os.path.isfile(excel_file_path):\n",
    "                schedule_df=pd.read_excel(excel_file_path)\n",
    "            chat_history.append([message, \"ì „ì²´ ì¼ì •ì„ ë§ì”€ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\"])\n",
    "\n",
    "            for idx, event in schedule_df.iterrows():\n",
    "                chat_history.append(\n",
    "                    [None, f\"{idx+1}. ì¼ì •: {event['schedule_content']}\\n\"\n",
    "                    f\"ì¼ì • ì„¤ëª…: {event['schedule_content_detail']}\\n\"\n",
    "                    f\"ì¼ì • ì‹œê°„: {event['year']}ë…„, {event['month']}ì›”, {event['day']}ì¼,\"\n",
    "                    f\"{event['hour']}ì‹œ, {event['min']}ë¶„\"])\n",
    "\n",
    "    except:\n",
    "        chat_history.append((message, ai_answer))\n",
    "    return \"\", chat_history # ì±„íŒ… ê¸°ë¡ ë°˜í™˜\n",
    "\n",
    "import gradio as gr\n",
    "with gr.Blocks() as app:\n",
    "    with gr.Tab(\"ìŒì„± ì¸ì‹ë´‡\"):\n",
    "        with gr.Column():\n",
    "            #1\n",
    "            gr.Markdown(\n",
    "                value=\"\"\"\n",
    "                # <center>ìŒì„± ì¸ì‹ë´‡</center>\n",
    "                <center>AI ì¸ê³µì§€ëŠ¥ ë¹„ì„œ DUDE ì…ë‹ˆë‹¤.\n",
    "                ìŒì„±ìœ¼ë¡œ ë¬»ê±°ë‚˜, ë¬¸ì„œ ìš”ì•½, ì¼ì • ê´€ë¦¬ë¥¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</center>\n",
    "                \"\"\"\n",
    "            )\n",
    "            #2\n",
    "            cb_chatbot=gr.Chatbot(\n",
    "                value=[[None, \"ì•ˆë…•í•˜ì„¸ìš”, ì¸ê³µì§€ëŠ¥ ë¹„ì„œ DUDE ì…ë‹ˆë‹¤. ë¬´ì—‡ì´ë“  ì‹œì¼œë§Œ ì£¼ì„¸ìš”.\"]],\n",
    "                show_label=False\n",
    "            )\n",
    "        with gr.Row():\n",
    "            #3\n",
    "            cb_user_input=gr.Textbox(\n",
    "                lines=1,\n",
    "                placeholder=\"ì…ë ¥ ì°½\",\n",
    "                container=False,\n",
    "                scale=7\n",
    "            )\n",
    "            #4\n",
    "            cb_audio_record=gr.Audio(\n",
    "                sources=[\"microphone\"],\n",
    "                format=\"mp3\",\n",
    "                scale=1,\n",
    "                min_width=200,\n",
    "                label=\"ìŒì„±ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.\"\n",
    "            )\n",
    "            # ìŒì„± ì¶œë ¥\n",
    "            cb_audio_chatbot=gr.Audio(autoplay=True,\n",
    "                                      visible=False)\n",
    "            #5\n",
    "            cb_submit_btn=gr.Button(\n",
    "                value=\"ë³´ë‚´ê¸°\",\n",
    "                scale=1,\n",
    "                visible=\"primary\",\n",
    "                icon=\"https://cdn-icons-png.flaticon.com/128/12439/12439334.png\"\n",
    "            )\n",
    "    # ìŒì„± ë…¹ìŒ ì™„ë£Œ\n",
    "        cb_audio_record.stop_recording(\n",
    "            fn=voice_bot_handle_audio,\n",
    "            inputs=[cb_audio_record]\n",
    "        )\n",
    "    # [ë³´ë‚´ê¸°] ë²„íŠ¼ í´ë¦­\n",
    "        cb_submit_btn.click(\n",
    "            fn=voice_bot_chat,\n",
    "            inputs=[cb_user_input, cb_audio_record, cb_chatbot],\n",
    "            outputs=[cb_user_input, cb_audio_record, cb_chatbot]\n",
    "        )\n",
    "    # ENTER ì œì¶œ ì…ë ¥\n",
    "        cb_user_input.submit(\n",
    "            fn=voice_bot_chat,\n",
    "            inputs=[cb_user_input, cb_audio_record, cb_chatbot],\n",
    "            outputs=[cb_user_input, cb_audio_record, cb_chatbot]\n",
    "        )\n",
    "        with gr.Row():\n",
    "            #6\n",
    "            gr.Button(value=\"â†ªï¸ë˜ëŒë¦¬ê¸°\").click(\n",
    "                fn=voice_bot_undo,\n",
    "                inputs=[cb_chatbot],\n",
    "                outputs=[cb_chatbot]\n",
    "            )\n",
    "            #7\n",
    "            gr.Button(value=\"ğŸ”„ï¸ì´ˆê¸°í™”\").click(\n",
    "                fn=voice_bot_reset,\n",
    "                inputs=[cb_chatbot],\n",
    "                outputs=[cb_chatbot]\n",
    "            )\n",
    "    with gr.Tab(\"ë¬¸ì„œ ìš”ì•½ë´‡\"):\n",
    "        with gr.Row():\n",
    "            #1\n",
    "            gr.Markdown(\n",
    "                value=\"\"\"\n",
    "                # <center>ë¬¸ì„œ ìš”ì•½ë´‡</center>\n",
    "                <center> AI ì¸ê³µì§€ëŠ¥ ë¹„ì„œ DUDE ì…ë‹ˆë‹¤. PDFë¥¼ ì—…ë¡œë“œí•˜ë©´ ë‚´ìš©ì„ ë²ˆì—­í•´ ë“œë¦½ë‹ˆë‹¤.</center>\n",
    "                \"\"\"\n",
    "            )\n",
    "        with gr.Row():\n",
    "            #2\n",
    "            pdf_input=gr.File()\n",
    "        with gr.Row():\n",
    "            #3\n",
    "            summary_btn=gr.Button(value=\"ë¬¸ì„œ ìš”ì•½í•˜ê¸°\")\n",
    "        with gr.Row():\n",
    "            #4\n",
    "            summary=gr.Textbox(\n",
    "                label=\"PDF ìš”ì•½\",\n",
    "                lines=8,\n",
    "                placeholder=\"PDF ìš”ì•½ ë‚´ìš©ì…ë‹ˆë‹¤.\",\n",
    "            )\n",
    "            summary_btn.click(\n",
    "                fn=pdf_bot_chatbot,\n",
    "                inputs=[pdf_input],\n",
    "                outputs=[summary]\n",
    "            )\n",
    "    with gr.Tab(\"ì¼ì • ê´€ë¦¬ë´‡\"):\n",
    "        with gr.Row():\n",
    "            #1\n",
    "            gr.Markdown(\n",
    "                value=\"\"\"\n",
    "                # <center>ì¼ì • ê´€ë¦¬ë´‡</center>\n",
    "                <center> AI ì¸ê³µì§€ëŠ¥ ë¹„ì„œ DUDE ì…ë‹ˆë‹¤. ì¼ì • ê´€ë¦¬ë¥¼ ìœ„í•œ ë´‡ì…ë‹ˆë‹¤.</center>\n",
    "                \"\"\")\n",
    "        with gr.Row():\n",
    "            #2\n",
    "            chatbot_schedule=gr.Chatbot(\n",
    "                value=[\n",
    "                    [None, \"ì•ˆë…•í•˜ì„¸ìš”, ì¼ì • ì´ë¦„, ì‹œê°„, ì¼ì • ì„¤ëª…ìœ¼ë¡œ ì¼ì •ì„ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \\n\\\n",
    "                    ì˜ˆì‹œ: í¬ë¦¬ìŠ¤ë§ˆìŠ¤, 2024ë…„ 12ì›” 25ì¼ 12ì‹œ 00ë¶„, ì˜¬í•´ì˜ í¬ë¦¬ìŠ¤ë§ˆìŠ¤ ì¼ì • ì¶”ê°€í•´ ì¤˜\\n\\\n",
    "                    ì „ì²´ ì¼ì •ì´ ë³´ê³  ì‹¶ë‹¤ë©´ ì „ì²´ì¼ì • ë³´ì—¬ì¤˜ ë¼ê³  ë§í•´ ì£¼ì„¸ìš”.\"],\n",
    "                ],\n",
    "                show_label=False                    \n",
    "            )\n",
    "        with gr.Row():\n",
    "            #3\n",
    "            msg_schedule=gr.Textbox(\n",
    "                label=\"ì±„íŒ…\",\n",
    "                lines=1,\n",
    "                placeholder=\"ì±„íŒ… ì…ë ¥ ì°½\",\n",
    "                scale=8,\n",
    "            )\n",
    "            #4\n",
    "            cb_schedule_submit_btn=gr.Button(\n",
    "                value=\"ë³´ë‚´ê¸°\",\n",
    "                scale=2,\n",
    "                visible=\"primary\",\n",
    "            )\n",
    "            cb_schedule_submit_btn.click(\n",
    "                fn=schedule_bot_chat,\n",
    "                inputs=[msg_schedule, chatbot_schedule],\n",
    "                outputs=[msg_schedule, chatbot_schedule]\n",
    "            )\n",
    "            msg_schedule.submit(\n",
    "                fn=schedule_bot_chat,\n",
    "                inputs=[msg_schedule, chatbot_schedule],\n",
    "                outputs=[msg_schedule, chatbot_schedule]\n",
    "            )\n",
    "            schedule_file.change(\n",
    "                fn=schedule_bot_save,\n",
    "                inputs=[schedule_file]\n",
    "            )\n",
    "        with gr.Row():\n",
    "            #5\n",
    "            schedule_file=gr.File(\n",
    "                label=\"ì¼ì • íŒŒì¼ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.\",\n",
    "                scale=8,\n",
    "                visible=\"primary\",\n",
    "                height=100\n",
    "            )\n",
    "            \n",
    "app.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_jun",
   "language": "python",
   "name": "ai_jun"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
